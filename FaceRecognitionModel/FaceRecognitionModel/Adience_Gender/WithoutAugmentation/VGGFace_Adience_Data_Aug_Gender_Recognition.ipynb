{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHkid32C0hvn",
        "outputId": "507b8408-5f11-470a-c4db-adcbff7134b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xf4sIXafS8-k"
      },
      "outputs": [],
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZzWpot_TlI7"
      },
      "outputs": [],
      "source": [
        "dossier=os.listdir(\"/content/drive/MyDrive/Adience_Gender/Adience_Gender_Data_Aug/Femme\")\n",
        "Femme=np.zeros((len(dossier),64,64,3))\n",
        "Labels_F=[]\n",
        "for i in range(len(dossier)):\n",
        "  nom_image='/content/drive/MyDrive/Adience_Gender/Adience_Gender_Data_Aug/Femme/'+dossier[i]\n",
        "  image = cv2.resize((cv2.imread(nom_image)), (64,64))\n",
        "  Femme[i]=image\n",
        "  Labels_F.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lbjTJTdTnsz"
      },
      "outputs": [],
      "source": [
        "dossier1=os.listdir(\"/content/drive/MyDrive/Adience_Gender/Adience_Gender_Data_Aug/Homme\")\n",
        "Homme=np.zeros((len(dossier1),64,64,3))\n",
        "Labels_H=[]\n",
        "for i in range(len(dossier1)):\n",
        "  nom_image='/content/drive/MyDrive/Adience_Gender/Adience_Gender_Data_Aug/Homme/'+dossier1[i]\n",
        "  image = cv2.resize((cv2.imread(nom_image)), (64,64))\n",
        "  Homme[i]=image\n",
        "  Labels_H.append(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_XdrvuHTs_v"
      },
      "outputs": [],
      "source": [
        "def train (x):\n",
        "  return int(x*0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Arz_M4PDUO2i"
      },
      "outputs": [],
      "source": [
        "images_train_Homme=Homme[:train(len(Homme))]\n",
        "images_test_Homme=Homme[train(len(Homme)):]\n",
        "labels_train_Homme=Labels_H[:train(len(Labels_H))]\n",
        "labels_test_Homme=Labels_H[train(len(Labels_H)):]\n",
        "\n",
        "images_train_Femme=Femme[:train(len(Femme))]\n",
        "images_test_Femme=Femme[train(len(Femme)):]\n",
        "labels_train_Femme=Labels_F[:train(len(Labels_F))]\n",
        "labels_test_Femme=Labels_F[train(len(Labels_F)):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crhyYrFfUTpR"
      },
      "outputs": [],
      "source": [
        "X_train=np.concatenate((images_train_Homme,images_train_Femme),axis=0)\n",
        "Y_train=np.concatenate((labels_train_Homme,labels_train_Femme),axis=0)\n",
        "X_test=np.concatenate((images_test_Homme,images_test_Femme),axis=0)\n",
        "Y_test=np.concatenate((labels_test_Homme,labels_test_Femme),axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6ulRSPcUW9_",
        "outputId": "b9b0b6e5-f207-4497-8b5a-31b5685ae4d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16076\n",
            "16076\n",
            "4020\n",
            "4020\n"
          ]
        }
      ],
      "source": [
        "print(len(X_train))\n",
        "print(len(Y_train))\n",
        "print(len(X_test))\n",
        "print(len(Y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsZRYPhwZjjX",
        "outputId": "0778bfa4-b152-474a-eca2-20ab79920a89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/rcmalli/keras-vggface.git\n",
            "  Cloning https://github.com/rcmalli/keras-vggface.git to /tmp/pip-req-build-atyy51v9\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/rcmalli/keras-vggface.git /tmp/pip-req-build-atyy51v9\n",
            "  Resolved https://github.com/rcmalli/keras-vggface.git to commit bee35376e76e35d00aeec503f2f242611a97b38a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-vggface==0.6) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.10/dist-packages (from keras-vggface==0.6) (1.10.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-vggface==0.6) (3.8.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from keras-vggface==0.6) (8.4.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-vggface==0.6) (2.12.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras-vggface==0.6) (1.16.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from keras-vggface==0.6) (6.0)\n",
            "Building wheels for collected packages: keras-vggface\n",
            "  Building wheel for keras-vggface (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-vggface: filename=keras_vggface-0.6-py3-none-any.whl size=8298 sha256=9d24f33788df179a6fd7b04680a85f82c8453b68023e758f6fb4ce4d48c55ea8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tly13gf2/wheels/62/cd/e0/3a2d2fe84d014324aed54d420cab52df65a774d9b296c63996\n",
            "Successfully built keras-vggface\n",
            "Installing collected packages: keras-vggface\n",
            "Successfully installed keras-vggface-0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/rcmalli/keras-vggface.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLfwQZcHZj7K",
        "outputId": "4a97f38d-0de7-4010-b04d-ea34df2d224d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras_vggface in /usr/local/lib/python3.10/dist-packages (0.6)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (1.10.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (3.8.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (8.4.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (2.12.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (1.16.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_vggface\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNpmmL_zZm_v",
        "outputId": "31701d9b-8989-4a0a-e009-ab507bf5e981"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras_applications\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_applications) (1.22.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras_applications) (3.8.0)\n",
            "Installing collected packages: keras_applications\n",
            "Successfully installed keras_applications-1.0.8\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_applications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngzPzc_HZpKV"
      },
      "outputs": [],
      "source": [
        "from keras_vggface.utils import preprocess_input\n",
        "from keras_vggface.vggface import VGGFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xpx-PyDpaAH5",
        "outputId": "a96325b2-b1b6-411c-81cf-69b4319aa740"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_vgg16.h5\n",
            "580070376/580070376 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "vggface = VGGFace(model='vgg16') # or VGGFace() as default\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkcnaqz4Z3OX",
        "outputId": "ed25c5bf-0e9a-4b4a-fce5-f8f43fbdfe4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_vgg16.h5\n",
            "58909280/58909280 [==============================] - 3s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# importing the libraries\n",
        "from keras.models import Model\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.applications import VGG19\n",
        "from keras.layers import Dropout,Dense,Conv2D,GlobalAveragePooling2D\n",
        "from keras.models import load_model\n",
        "#from keras.preprocessing import image\n",
        "num_classes=1\n",
        "IMAGE_SIZE = [64,64]  # we will keep the image size as (64,64). You can increase the size for better results. \n",
        "\n",
        "VGGFace = VGGFace(input_shape = IMAGE_SIZE + [3],weights='vggface',include_top=False)\n",
        "\n",
        "# this will exclude the initial layers from training phase as there are already been trained.\n",
        "for layer in VGGFace.layers:\n",
        "    layer.trainable = False\n",
        "x = Flatten()(VGGFace.output)\n",
        "\n",
        "x1 = Dense(num_classes, activation = 'sigmoid')(x)  # adding the output layer with softmax function as this is a multi label classification problem.\n",
        "\n",
        "model = Model(inputs = VGGFace.input, outputs = x1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4Z0aakYUhlM",
        "outputId": "59ec425c-233c-4231-f06c-4d3d2fdfe268"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " conv1_1 (Conv2D)            (None, 64, 64, 64)        1792      \n",
            "                                                                 \n",
            " conv1_2 (Conv2D)            (None, 64, 64, 64)        36928     \n",
            "                                                                 \n",
            " pool1 (MaxPooling2D)        (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2_1 (Conv2D)            (None, 32, 32, 128)       73856     \n",
            "                                                                 \n",
            " conv2_2 (Conv2D)            (None, 32, 32, 128)       147584    \n",
            "                                                                 \n",
            " pool2 (MaxPooling2D)        (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv3_1 (Conv2D)            (None, 16, 16, 256)       295168    \n",
            "                                                                 \n",
            " conv3_2 (Conv2D)            (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " conv3_3 (Conv2D)            (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " pool3 (MaxPooling2D)        (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " conv4_1 (Conv2D)            (None, 8, 8, 512)         1180160   \n",
            "                                                                 \n",
            " conv4_2 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " conv4_3 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " pool4 (MaxPooling2D)        (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " conv5_1 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " conv5_2 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " conv5_3 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " pool5 (MaxPooling2D)        (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 2049      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,716,737\n",
            "Trainable params: 2,049\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxQQp_0WUjUq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzIsAOLyUmlC"
      },
      "outputs": [],
      "source": [
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "X_test = np.array(X_test)\n",
        "Y_test = np.array(Y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK3MtjlZUsTT",
        "outputId": "1acde8f0-1fd6-475a-e912-83454e1f17f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "161/161 [==============================] - 23s 70ms/step - loss: 4.0990 - accuracy: 0.5407 - val_loss: 3.6696 - val_accuracy: 0.5438\n",
            "Epoch 2/1000\n",
            "161/161 [==============================] - 9s 56ms/step - loss: 2.6756 - accuracy: 0.6065 - val_loss: 2.8660 - val_accuracy: 0.5826\n",
            "Epoch 3/1000\n",
            "161/161 [==============================] - 8s 51ms/step - loss: 2.1940 - accuracy: 0.6320 - val_loss: 2.4523 - val_accuracy: 0.6047\n",
            "Epoch 4/1000\n",
            "161/161 [==============================] - 9s 56ms/step - loss: 1.8957 - accuracy: 0.6497 - val_loss: 2.2135 - val_accuracy: 0.6100\n",
            "Epoch 5/1000\n",
            "161/161 [==============================] - 8s 50ms/step - loss: 1.6853 - accuracy: 0.6589 - val_loss: 1.9875 - val_accuracy: 0.6192\n",
            "Epoch 6/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 1.5168 - accuracy: 0.6679 - val_loss: 1.8265 - val_accuracy: 0.6246\n",
            "Epoch 7/1000\n",
            "161/161 [==============================] - 9s 57ms/step - loss: 1.3846 - accuracy: 0.6757 - val_loss: 1.6892 - val_accuracy: 0.6318\n",
            "Epoch 8/1000\n",
            "161/161 [==============================] - 8s 51ms/step - loss: 1.2746 - accuracy: 0.6828 - val_loss: 1.5926 - val_accuracy: 0.6361\n",
            "Epoch 9/1000\n",
            "161/161 [==============================] - 8s 51ms/step - loss: 1.1839 - accuracy: 0.6883 - val_loss: 1.5253 - val_accuracy: 0.6323\n",
            "Epoch 10/1000\n",
            "161/161 [==============================] - 9s 57ms/step - loss: 1.1003 - accuracy: 0.6965 - val_loss: 1.4382 - val_accuracy: 0.6351\n",
            "Epoch 11/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 1.0329 - accuracy: 0.7009 - val_loss: 1.3679 - val_accuracy: 0.6378\n",
            "Epoch 12/1000\n",
            "161/161 [==============================] - 9s 57ms/step - loss: 0.9705 - accuracy: 0.7078 - val_loss: 1.3154 - val_accuracy: 0.6368\n",
            "Epoch 13/1000\n",
            "161/161 [==============================] - 9s 57ms/step - loss: 0.9182 - accuracy: 0.7103 - val_loss: 1.2804 - val_accuracy: 0.6400\n",
            "Epoch 14/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.8677 - accuracy: 0.7170 - val_loss: 1.2312 - val_accuracy: 0.6453\n",
            "Epoch 15/1000\n",
            "161/161 [==============================] - 9s 57ms/step - loss: 0.8245 - accuracy: 0.7231 - val_loss: 1.1941 - val_accuracy: 0.6425\n",
            "Epoch 16/1000\n",
            "161/161 [==============================] - 8s 51ms/step - loss: 0.7876 - accuracy: 0.7285 - val_loss: 1.1454 - val_accuracy: 0.6463\n",
            "Epoch 17/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.7509 - accuracy: 0.7297 - val_loss: 1.1156 - val_accuracy: 0.6443\n",
            "Epoch 18/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.7184 - accuracy: 0.7327 - val_loss: 1.1027 - val_accuracy: 0.6460\n",
            "Epoch 19/1000\n",
            "161/161 [==============================] - 9s 57ms/step - loss: 0.6930 - accuracy: 0.7360 - val_loss: 1.0668 - val_accuracy: 0.6470\n",
            "Epoch 20/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.6674 - accuracy: 0.7413 - val_loss: 1.0723 - val_accuracy: 0.6463\n",
            "Epoch 21/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.6466 - accuracy: 0.7448 - val_loss: 1.0438 - val_accuracy: 0.6460\n",
            "Epoch 22/1000\n",
            "161/161 [==============================] - 8s 51ms/step - loss: 0.6262 - accuracy: 0.7471 - val_loss: 0.9971 - val_accuracy: 0.6502\n",
            "Epoch 23/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.6071 - accuracy: 0.7496 - val_loss: 0.9726 - val_accuracy: 0.6577\n",
            "Epoch 24/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.5886 - accuracy: 0.7547 - val_loss: 0.9552 - val_accuracy: 0.6542\n",
            "Epoch 25/1000\n",
            "161/161 [==============================] - 8s 51ms/step - loss: 0.5705 - accuracy: 0.7590 - val_loss: 0.9256 - val_accuracy: 0.6590\n",
            "Epoch 26/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.5616 - accuracy: 0.7602 - val_loss: 0.9279 - val_accuracy: 0.6600\n",
            "Epoch 27/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.5473 - accuracy: 0.7656 - val_loss: 0.8935 - val_accuracy: 0.6617\n",
            "Epoch 28/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.5352 - accuracy: 0.7661 - val_loss: 0.8900 - val_accuracy: 0.6619\n",
            "Epoch 29/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.5236 - accuracy: 0.7700 - val_loss: 0.8810 - val_accuracy: 0.6612\n",
            "Epoch 30/1000\n",
            "161/161 [==============================] - 9s 57ms/step - loss: 0.5152 - accuracy: 0.7736 - val_loss: 0.8680 - val_accuracy: 0.6632\n",
            "Epoch 31/1000\n",
            "161/161 [==============================] - 8s 51ms/step - loss: 0.5075 - accuracy: 0.7743 - val_loss: 0.8667 - val_accuracy: 0.6627\n",
            "Epoch 32/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.5008 - accuracy: 0.7754 - val_loss: 0.9334 - val_accuracy: 0.6428\n",
            "Epoch 33/1000\n",
            "161/161 [==============================] - 9s 57ms/step - loss: 0.4972 - accuracy: 0.7773 - val_loss: 0.8398 - val_accuracy: 0.6657\n",
            "Epoch 34/1000\n",
            "161/161 [==============================] - 9s 57ms/step - loss: 0.4899 - accuracy: 0.7773 - val_loss: 0.8303 - val_accuracy: 0.6669\n",
            "Epoch 35/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4828 - accuracy: 0.7840 - val_loss: 0.8284 - val_accuracy: 0.6677\n",
            "Epoch 36/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4743 - accuracy: 0.7873 - val_loss: 0.8164 - val_accuracy: 0.6659\n",
            "Epoch 37/1000\n",
            "161/161 [==============================] - 9s 57ms/step - loss: 0.4715 - accuracy: 0.7871 - val_loss: 0.8095 - val_accuracy: 0.6711\n",
            "Epoch 38/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4663 - accuracy: 0.7887 - val_loss: 0.8216 - val_accuracy: 0.6604\n",
            "Epoch 39/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4663 - accuracy: 0.7922 - val_loss: 0.8058 - val_accuracy: 0.6697\n",
            "Epoch 40/1000\n",
            "161/161 [==============================] - 9s 57ms/step - loss: 0.4598 - accuracy: 0.7930 - val_loss: 0.7988 - val_accuracy: 0.6709\n",
            "Epoch 41/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4579 - accuracy: 0.7914 - val_loss: 0.7782 - val_accuracy: 0.6744\n",
            "Epoch 42/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4559 - accuracy: 0.7906 - val_loss: 0.7976 - val_accuracy: 0.6716\n",
            "Epoch 43/1000\n",
            "161/161 [==============================] - 8s 51ms/step - loss: 0.4514 - accuracy: 0.7973 - val_loss: 0.7862 - val_accuracy: 0.6697\n",
            "Epoch 44/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4477 - accuracy: 0.7960 - val_loss: 0.7962 - val_accuracy: 0.6739\n",
            "Epoch 45/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4452 - accuracy: 0.7978 - val_loss: 0.7780 - val_accuracy: 0.6716\n",
            "Epoch 46/1000\n",
            "161/161 [==============================] - 8s 51ms/step - loss: 0.4478 - accuracy: 0.7969 - val_loss: 0.7743 - val_accuracy: 0.6704\n",
            "Epoch 47/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4406 - accuracy: 0.8006 - val_loss: 0.7737 - val_accuracy: 0.6741\n",
            "Epoch 48/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4419 - accuracy: 0.8008 - val_loss: 0.7711 - val_accuracy: 0.6749\n",
            "Epoch 49/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4364 - accuracy: 0.8007 - val_loss: 0.7694 - val_accuracy: 0.6714\n",
            "Epoch 50/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4368 - accuracy: 0.8019 - val_loss: 0.7660 - val_accuracy: 0.6729\n",
            "Epoch 51/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4333 - accuracy: 0.8007 - val_loss: 0.7634 - val_accuracy: 0.6716\n",
            "Epoch 52/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4330 - accuracy: 0.8044 - val_loss: 0.7669 - val_accuracy: 0.6731\n",
            "Epoch 53/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4322 - accuracy: 0.8021 - val_loss: 0.7584 - val_accuracy: 0.6756\n",
            "Epoch 54/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4312 - accuracy: 0.8036 - val_loss: 0.7667 - val_accuracy: 0.6761\n",
            "Epoch 55/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4293 - accuracy: 0.8046 - val_loss: 0.7615 - val_accuracy: 0.6716\n",
            "Epoch 56/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4297 - accuracy: 0.8045 - val_loss: 0.7594 - val_accuracy: 0.6721\n",
            "Epoch 57/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4266 - accuracy: 0.8039 - val_loss: 0.7787 - val_accuracy: 0.6629\n",
            "Epoch 58/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4280 - accuracy: 0.8066 - val_loss: 0.7581 - val_accuracy: 0.6684\n",
            "Epoch 59/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4257 - accuracy: 0.8064 - val_loss: 0.7677 - val_accuracy: 0.6764\n",
            "Epoch 60/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4236 - accuracy: 0.8064 - val_loss: 0.7537 - val_accuracy: 0.6781\n",
            "Epoch 61/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4244 - accuracy: 0.8082 - val_loss: 0.7608 - val_accuracy: 0.6776\n",
            "Epoch 62/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4239 - accuracy: 0.8060 - val_loss: 0.7603 - val_accuracy: 0.6759\n",
            "Epoch 63/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4238 - accuracy: 0.8085 - val_loss: 0.7485 - val_accuracy: 0.6774\n",
            "Epoch 64/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4206 - accuracy: 0.8072 - val_loss: 0.7503 - val_accuracy: 0.6786\n",
            "Epoch 65/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4224 - accuracy: 0.8102 - val_loss: 0.7500 - val_accuracy: 0.6791\n",
            "Epoch 66/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4208 - accuracy: 0.8082 - val_loss: 0.7632 - val_accuracy: 0.6781\n",
            "Epoch 67/1000\n",
            "161/161 [==============================] - 8s 51ms/step - loss: 0.4207 - accuracy: 0.8109 - val_loss: 0.7542 - val_accuracy: 0.6791\n",
            "Epoch 68/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4190 - accuracy: 0.8080 - val_loss: 0.7456 - val_accuracy: 0.6811\n",
            "Epoch 69/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4185 - accuracy: 0.8095 - val_loss: 0.7496 - val_accuracy: 0.6799\n",
            "Epoch 70/1000\n",
            "161/161 [==============================] - 9s 57ms/step - loss: 0.4200 - accuracy: 0.8082 - val_loss: 0.7563 - val_accuracy: 0.6721\n",
            "Epoch 71/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4195 - accuracy: 0.8097 - val_loss: 0.7616 - val_accuracy: 0.6706\n",
            "Epoch 72/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4223 - accuracy: 0.8093 - val_loss: 0.7540 - val_accuracy: 0.6761\n",
            "Epoch 73/1000\n",
            "161/161 [==============================] - 8s 51ms/step - loss: 0.4181 - accuracy: 0.8098 - val_loss: 0.7473 - val_accuracy: 0.6799\n",
            "Epoch 74/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4168 - accuracy: 0.8108 - val_loss: 0.7493 - val_accuracy: 0.6776\n",
            "Epoch 75/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4179 - accuracy: 0.8116 - val_loss: 0.7619 - val_accuracy: 0.6694\n",
            "Epoch 76/1000\n",
            "161/161 [==============================] - 8s 51ms/step - loss: 0.4165 - accuracy: 0.8119 - val_loss: 0.7535 - val_accuracy: 0.6771\n",
            "Epoch 77/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4161 - accuracy: 0.8100 - val_loss: 0.7378 - val_accuracy: 0.6843\n",
            "Epoch 78/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4172 - accuracy: 0.8106 - val_loss: 0.7534 - val_accuracy: 0.6766\n",
            "Epoch 79/1000\n",
            "161/161 [==============================] - 9s 57ms/step - loss: 0.4155 - accuracy: 0.8117 - val_loss: 0.7591 - val_accuracy: 0.6774\n",
            "Epoch 80/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4153 - accuracy: 0.8120 - val_loss: 0.7509 - val_accuracy: 0.6746\n",
            "Epoch 81/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4146 - accuracy: 0.8121 - val_loss: 0.7489 - val_accuracy: 0.6769\n",
            "Epoch 82/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4164 - accuracy: 0.8107 - val_loss: 0.7566 - val_accuracy: 0.6766\n",
            "Epoch 83/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4172 - accuracy: 0.8087 - val_loss: 0.7566 - val_accuracy: 0.6769\n",
            "Epoch 84/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4126 - accuracy: 0.8131 - val_loss: 0.7366 - val_accuracy: 0.6868\n",
            "Epoch 85/1000\n",
            "161/161 [==============================] - 8s 51ms/step - loss: 0.4162 - accuracy: 0.8118 - val_loss: 0.7462 - val_accuracy: 0.6806\n",
            "Epoch 86/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4143 - accuracy: 0.8121 - val_loss: 0.7513 - val_accuracy: 0.6789\n",
            "Epoch 87/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4142 - accuracy: 0.8118 - val_loss: 0.7499 - val_accuracy: 0.6796\n",
            "Epoch 88/1000\n",
            "161/161 [==============================] - 8s 51ms/step - loss: 0.4135 - accuracy: 0.8138 - val_loss: 0.7531 - val_accuracy: 0.6749\n",
            "Epoch 89/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4112 - accuracy: 0.8130 - val_loss: 0.7529 - val_accuracy: 0.6806\n",
            "Epoch 90/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4148 - accuracy: 0.8128 - val_loss: 0.7523 - val_accuracy: 0.6801\n",
            "Epoch 91/1000\n",
            "161/161 [==============================] - 8s 51ms/step - loss: 0.4129 - accuracy: 0.8148 - val_loss: 0.7471 - val_accuracy: 0.6781\n",
            "Epoch 92/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4142 - accuracy: 0.8106 - val_loss: 0.7626 - val_accuracy: 0.6697\n",
            "Epoch 93/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4122 - accuracy: 0.8128 - val_loss: 0.7431 - val_accuracy: 0.6823\n",
            "Epoch 94/1000\n",
            "161/161 [==============================] - 9s 57ms/step - loss: 0.4142 - accuracy: 0.8124 - val_loss: 0.7638 - val_accuracy: 0.6774\n",
            "Epoch 95/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4119 - accuracy: 0.8137 - val_loss: 0.7452 - val_accuracy: 0.6826\n",
            "Epoch 96/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4125 - accuracy: 0.8140 - val_loss: 0.7429 - val_accuracy: 0.6851\n",
            "Epoch 97/1000\n",
            "161/161 [==============================] - 8s 51ms/step - loss: 0.4119 - accuracy: 0.8136 - val_loss: 0.7481 - val_accuracy: 0.6801\n",
            "Epoch 98/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4113 - accuracy: 0.8152 - val_loss: 0.7617 - val_accuracy: 0.6719\n",
            "Epoch 99/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4145 - accuracy: 0.8117 - val_loss: 0.7601 - val_accuracy: 0.6774\n",
            "Epoch 100/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4117 - accuracy: 0.8136 - val_loss: 0.7698 - val_accuracy: 0.6756\n",
            "Epoch 101/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4127 - accuracy: 0.8124 - val_loss: 0.7532 - val_accuracy: 0.6794\n",
            "Epoch 102/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4158 - accuracy: 0.8102 - val_loss: 0.7507 - val_accuracy: 0.6818\n",
            "Epoch 103/1000\n",
            "161/161 [==============================] - 8s 51ms/step - loss: 0.4136 - accuracy: 0.8127 - val_loss: 0.7486 - val_accuracy: 0.6811\n",
            "Epoch 104/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4134 - accuracy: 0.8131 - val_loss: 0.7573 - val_accuracy: 0.6751\n",
            "Epoch 105/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4124 - accuracy: 0.8118 - val_loss: 0.7516 - val_accuracy: 0.6794\n",
            "Epoch 106/1000\n",
            "161/161 [==============================] - 9s 57ms/step - loss: 0.4108 - accuracy: 0.8158 - val_loss: 0.7702 - val_accuracy: 0.6741\n",
            "Epoch 107/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4109 - accuracy: 0.8148 - val_loss: 0.7617 - val_accuracy: 0.6799\n",
            "Epoch 108/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4118 - accuracy: 0.8130 - val_loss: 0.7620 - val_accuracy: 0.6734\n",
            "Epoch 109/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4114 - accuracy: 0.8156 - val_loss: 0.7465 - val_accuracy: 0.6818\n",
            "Epoch 110/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4104 - accuracy: 0.8152 - val_loss: 0.7536 - val_accuracy: 0.6856\n",
            "Epoch 111/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4109 - accuracy: 0.8138 - val_loss: 0.7543 - val_accuracy: 0.6771\n",
            "Epoch 112/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4115 - accuracy: 0.8158 - val_loss: 0.7635 - val_accuracy: 0.6808\n",
            "Epoch 113/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4102 - accuracy: 0.8164 - val_loss: 0.7573 - val_accuracy: 0.6779\n",
            "Epoch 114/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4115 - accuracy: 0.8150 - val_loss: 0.7524 - val_accuracy: 0.6791\n",
            "Epoch 115/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4107 - accuracy: 0.8125 - val_loss: 0.7638 - val_accuracy: 0.6786\n",
            "Epoch 116/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4099 - accuracy: 0.8154 - val_loss: 0.7627 - val_accuracy: 0.6781\n",
            "Epoch 117/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4116 - accuracy: 0.8153 - val_loss: 0.7528 - val_accuracy: 0.6759\n",
            "Epoch 118/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4108 - accuracy: 0.8157 - val_loss: 0.7598 - val_accuracy: 0.6779\n",
            "Epoch 119/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4127 - accuracy: 0.8135 - val_loss: 0.7647 - val_accuracy: 0.6754\n",
            "Epoch 120/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4116 - accuracy: 0.8137 - val_loss: 0.7578 - val_accuracy: 0.6776\n",
            "Epoch 121/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4102 - accuracy: 0.8161 - val_loss: 0.7605 - val_accuracy: 0.6761\n",
            "Epoch 122/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4083 - accuracy: 0.8171 - val_loss: 0.7670 - val_accuracy: 0.6754\n",
            "Epoch 123/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4095 - accuracy: 0.8134 - val_loss: 0.7713 - val_accuracy: 0.6759\n",
            "Epoch 124/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4124 - accuracy: 0.8125 - val_loss: 0.7541 - val_accuracy: 0.6794\n",
            "Epoch 125/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4097 - accuracy: 0.8141 - val_loss: 0.7503 - val_accuracy: 0.6769\n",
            "Epoch 126/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4095 - accuracy: 0.8133 - val_loss: 0.7609 - val_accuracy: 0.6771\n",
            "Epoch 127/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4110 - accuracy: 0.8143 - val_loss: 0.7597 - val_accuracy: 0.6786\n",
            "Epoch 128/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4107 - accuracy: 0.8158 - val_loss: 0.7617 - val_accuracy: 0.6806\n",
            "Epoch 129/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4101 - accuracy: 0.8149 - val_loss: 0.7563 - val_accuracy: 0.6774\n",
            "Epoch 130/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4122 - accuracy: 0.8150 - val_loss: 0.7655 - val_accuracy: 0.6759\n",
            "Epoch 131/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4095 - accuracy: 0.8156 - val_loss: 0.7682 - val_accuracy: 0.6764\n",
            "Epoch 132/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4113 - accuracy: 0.8146 - val_loss: 0.7785 - val_accuracy: 0.6719\n",
            "Epoch 133/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4100 - accuracy: 0.8171 - val_loss: 0.7620 - val_accuracy: 0.6769\n",
            "Epoch 134/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4084 - accuracy: 0.8164 - val_loss: 0.7773 - val_accuracy: 0.6734\n",
            "Epoch 135/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4108 - accuracy: 0.8151 - val_loss: 0.7654 - val_accuracy: 0.6744\n",
            "Epoch 136/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4127 - accuracy: 0.8116 - val_loss: 0.7629 - val_accuracy: 0.6769\n",
            "Epoch 137/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4103 - accuracy: 0.8149 - val_loss: 0.7668 - val_accuracy: 0.6736\n",
            "Epoch 138/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4101 - accuracy: 0.8146 - val_loss: 0.7556 - val_accuracy: 0.6784\n",
            "Epoch 139/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4113 - accuracy: 0.8132 - val_loss: 0.7655 - val_accuracy: 0.6731\n",
            "Epoch 140/1000\n",
            "161/161 [==============================] - 8s 51ms/step - loss: 0.4117 - accuracy: 0.8146 - val_loss: 0.7663 - val_accuracy: 0.6746\n",
            "Epoch 141/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4075 - accuracy: 0.8174 - val_loss: 0.7670 - val_accuracy: 0.6721\n",
            "Epoch 142/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4099 - accuracy: 0.8169 - val_loss: 0.7746 - val_accuracy: 0.6724\n",
            "Epoch 143/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4084 - accuracy: 0.8161 - val_loss: 0.7704 - val_accuracy: 0.6754\n",
            "Epoch 144/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4090 - accuracy: 0.8171 - val_loss: 0.7629 - val_accuracy: 0.6741\n",
            "Epoch 145/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4072 - accuracy: 0.8177 - val_loss: 0.7762 - val_accuracy: 0.6746\n",
            "Epoch 146/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4127 - accuracy: 0.8126 - val_loss: 0.7722 - val_accuracy: 0.6736\n",
            "Epoch 147/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4085 - accuracy: 0.8163 - val_loss: 0.7726 - val_accuracy: 0.6741\n",
            "Epoch 148/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4097 - accuracy: 0.8144 - val_loss: 0.7730 - val_accuracy: 0.6759\n",
            "Epoch 149/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4072 - accuracy: 0.8150 - val_loss: 0.7637 - val_accuracy: 0.6756\n",
            "Epoch 150/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4105 - accuracy: 0.8127 - val_loss: 0.7682 - val_accuracy: 0.6739\n",
            "Epoch 151/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4083 - accuracy: 0.8179 - val_loss: 0.7623 - val_accuracy: 0.6774\n",
            "Epoch 152/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4100 - accuracy: 0.8150 - val_loss: 0.7642 - val_accuracy: 0.6739\n",
            "Epoch 153/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4105 - accuracy: 0.8119 - val_loss: 0.7846 - val_accuracy: 0.6697\n",
            "Epoch 154/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4088 - accuracy: 0.8123 - val_loss: 0.7838 - val_accuracy: 0.6744\n",
            "Epoch 155/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4091 - accuracy: 0.8164 - val_loss: 0.7721 - val_accuracy: 0.6754\n",
            "Epoch 156/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4124 - accuracy: 0.8135 - val_loss: 0.7808 - val_accuracy: 0.6754\n",
            "Epoch 157/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4098 - accuracy: 0.8142 - val_loss: 0.7686 - val_accuracy: 0.6821\n",
            "Epoch 158/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4090 - accuracy: 0.8148 - val_loss: 0.7667 - val_accuracy: 0.6821\n",
            "Epoch 159/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4099 - accuracy: 0.8148 - val_loss: 0.7658 - val_accuracy: 0.6771\n",
            "Epoch 160/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4073 - accuracy: 0.8165 - val_loss: 0.7680 - val_accuracy: 0.6774\n",
            "Epoch 161/1000\n",
            "161/161 [==============================] - 8s 51ms/step - loss: 0.4083 - accuracy: 0.8151 - val_loss: 0.7659 - val_accuracy: 0.6774\n",
            "Epoch 162/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4081 - accuracy: 0.8153 - val_loss: 0.7753 - val_accuracy: 0.6746\n",
            "Epoch 163/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4084 - accuracy: 0.8154 - val_loss: 0.7714 - val_accuracy: 0.6761\n",
            "Epoch 164/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4069 - accuracy: 0.8169 - val_loss: 0.7690 - val_accuracy: 0.6808\n",
            "Epoch 165/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4105 - accuracy: 0.8150 - val_loss: 0.7750 - val_accuracy: 0.6744\n",
            "Epoch 166/1000\n",
            "161/161 [==============================] - 8s 51ms/step - loss: 0.4098 - accuracy: 0.8145 - val_loss: 0.7823 - val_accuracy: 0.6736\n",
            "Epoch 167/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4084 - accuracy: 0.8158 - val_loss: 0.7777 - val_accuracy: 0.6761\n",
            "Epoch 168/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4077 - accuracy: 0.8159 - val_loss: 0.7741 - val_accuracy: 0.6726\n",
            "Epoch 169/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4074 - accuracy: 0.8166 - val_loss: 0.7742 - val_accuracy: 0.6736\n",
            "Epoch 170/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4094 - accuracy: 0.8183 - val_loss: 0.7799 - val_accuracy: 0.6731\n",
            "Epoch 171/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4069 - accuracy: 0.8194 - val_loss: 0.7920 - val_accuracy: 0.6774\n",
            "Epoch 172/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4094 - accuracy: 0.8123 - val_loss: 0.7676 - val_accuracy: 0.6731\n",
            "Epoch 173/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4081 - accuracy: 0.8170 - val_loss: 0.7794 - val_accuracy: 0.6759\n",
            "Epoch 174/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4072 - accuracy: 0.8182 - val_loss: 0.7928 - val_accuracy: 0.6724\n",
            "Epoch 175/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4084 - accuracy: 0.8172 - val_loss: 0.7784 - val_accuracy: 0.6754\n",
            "Epoch 176/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4087 - accuracy: 0.8169 - val_loss: 0.7666 - val_accuracy: 0.6736\n",
            "Epoch 177/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4067 - accuracy: 0.8172 - val_loss: 0.7762 - val_accuracy: 0.6726\n",
            "Epoch 178/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4070 - accuracy: 0.8184 - val_loss: 0.7723 - val_accuracy: 0.6784\n",
            "Epoch 179/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4085 - accuracy: 0.8154 - val_loss: 0.7717 - val_accuracy: 0.6749\n",
            "Epoch 180/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4082 - accuracy: 0.8166 - val_loss: 0.7721 - val_accuracy: 0.6739\n",
            "Epoch 181/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4068 - accuracy: 0.8144 - val_loss: 0.7677 - val_accuracy: 0.6749\n",
            "Epoch 182/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4069 - accuracy: 0.8168 - val_loss: 0.7730 - val_accuracy: 0.6736\n",
            "Epoch 183/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4146 - accuracy: 0.8119 - val_loss: 0.7797 - val_accuracy: 0.6756\n",
            "Epoch 184/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4083 - accuracy: 0.8155 - val_loss: 0.7890 - val_accuracy: 0.6714\n",
            "Epoch 185/1000\n",
            "161/161 [==============================] - 8s 51ms/step - loss: 0.4068 - accuracy: 0.8162 - val_loss: 0.7788 - val_accuracy: 0.6756\n",
            "Epoch 186/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4088 - accuracy: 0.8167 - val_loss: 0.7731 - val_accuracy: 0.6739\n",
            "Epoch 187/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4105 - accuracy: 0.8159 - val_loss: 0.7828 - val_accuracy: 0.6761\n",
            "Epoch 188/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4087 - accuracy: 0.8146 - val_loss: 0.7890 - val_accuracy: 0.6729\n",
            "Epoch 189/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4065 - accuracy: 0.8167 - val_loss: 0.7853 - val_accuracy: 0.6756\n",
            "Epoch 190/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4083 - accuracy: 0.8146 - val_loss: 0.7765 - val_accuracy: 0.6756\n",
            "Epoch 191/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4096 - accuracy: 0.8146 - val_loss: 0.7806 - val_accuracy: 0.6784\n",
            "Epoch 192/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4083 - accuracy: 0.8154 - val_loss: 0.7715 - val_accuracy: 0.6744\n",
            "Epoch 193/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4075 - accuracy: 0.8181 - val_loss: 0.7875 - val_accuracy: 0.6711\n",
            "Epoch 194/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4075 - accuracy: 0.8155 - val_loss: 0.7870 - val_accuracy: 0.6697\n",
            "Epoch 195/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4098 - accuracy: 0.8148 - val_loss: 0.7637 - val_accuracy: 0.6766\n",
            "Epoch 196/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4077 - accuracy: 0.8165 - val_loss: 0.7795 - val_accuracy: 0.6741\n",
            "Epoch 197/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4076 - accuracy: 0.8154 - val_loss: 0.7841 - val_accuracy: 0.6726\n",
            "Epoch 198/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4065 - accuracy: 0.8169 - val_loss: 0.7806 - val_accuracy: 0.6761\n",
            "Epoch 199/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4074 - accuracy: 0.8162 - val_loss: 0.7775 - val_accuracy: 0.6784\n",
            "Epoch 200/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4060 - accuracy: 0.8174 - val_loss: 0.7800 - val_accuracy: 0.6711\n",
            "Epoch 201/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4067 - accuracy: 0.8163 - val_loss: 0.7825 - val_accuracy: 0.6776\n",
            "Epoch 202/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4089 - accuracy: 0.8178 - val_loss: 0.7814 - val_accuracy: 0.6734\n",
            "Epoch 203/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4095 - accuracy: 0.8143 - val_loss: 0.7869 - val_accuracy: 0.6759\n",
            "Epoch 204/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4059 - accuracy: 0.8185 - val_loss: 0.7799 - val_accuracy: 0.6781\n",
            "Epoch 205/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4097 - accuracy: 0.8144 - val_loss: 0.7772 - val_accuracy: 0.6766\n",
            "Epoch 206/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4080 - accuracy: 0.8160 - val_loss: 0.7932 - val_accuracy: 0.6721\n",
            "Epoch 207/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4064 - accuracy: 0.8181 - val_loss: 0.7675 - val_accuracy: 0.6756\n",
            "Epoch 208/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4085 - accuracy: 0.8153 - val_loss: 0.7777 - val_accuracy: 0.6786\n",
            "Epoch 209/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4070 - accuracy: 0.8161 - val_loss: 0.7927 - val_accuracy: 0.6764\n",
            "Epoch 210/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4075 - accuracy: 0.8162 - val_loss: 0.7874 - val_accuracy: 0.6719\n",
            "Epoch 211/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4053 - accuracy: 0.8176 - val_loss: 0.7929 - val_accuracy: 0.6766\n",
            "Epoch 212/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4081 - accuracy: 0.8159 - val_loss: 0.7831 - val_accuracy: 0.6739\n",
            "Epoch 213/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4062 - accuracy: 0.8153 - val_loss: 0.7778 - val_accuracy: 0.6749\n",
            "Epoch 214/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4096 - accuracy: 0.8119 - val_loss: 0.7906 - val_accuracy: 0.6711\n",
            "Epoch 215/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4077 - accuracy: 0.8161 - val_loss: 0.7892 - val_accuracy: 0.6759\n",
            "Epoch 216/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4067 - accuracy: 0.8180 - val_loss: 0.7879 - val_accuracy: 0.6749\n",
            "Epoch 217/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4069 - accuracy: 0.8148 - val_loss: 0.7738 - val_accuracy: 0.6764\n",
            "Epoch 218/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4074 - accuracy: 0.8144 - val_loss: 0.7818 - val_accuracy: 0.6769\n",
            "Epoch 219/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4087 - accuracy: 0.8148 - val_loss: 0.7951 - val_accuracy: 0.6741\n",
            "Epoch 220/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4062 - accuracy: 0.8173 - val_loss: 0.7825 - val_accuracy: 0.6749\n",
            "Epoch 221/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4082 - accuracy: 0.8161 - val_loss: 0.7706 - val_accuracy: 0.6769\n",
            "Epoch 222/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4083 - accuracy: 0.8173 - val_loss: 0.7900 - val_accuracy: 0.6721\n",
            "Epoch 223/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4082 - accuracy: 0.8161 - val_loss: 0.7839 - val_accuracy: 0.6771\n",
            "Epoch 224/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4106 - accuracy: 0.8161 - val_loss: 0.7993 - val_accuracy: 0.6759\n",
            "Epoch 225/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4086 - accuracy: 0.8168 - val_loss: 0.7911 - val_accuracy: 0.6731\n",
            "Epoch 226/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4073 - accuracy: 0.8159 - val_loss: 0.7994 - val_accuracy: 0.6736\n",
            "Epoch 227/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4118 - accuracy: 0.8143 - val_loss: 0.8079 - val_accuracy: 0.6719\n",
            "Epoch 228/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4071 - accuracy: 0.8179 - val_loss: 0.7847 - val_accuracy: 0.6761\n",
            "Epoch 229/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4097 - accuracy: 0.8163 - val_loss: 0.7879 - val_accuracy: 0.6701\n",
            "Epoch 230/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4062 - accuracy: 0.8166 - val_loss: 0.7889 - val_accuracy: 0.6739\n",
            "Epoch 231/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4065 - accuracy: 0.8158 - val_loss: 0.7788 - val_accuracy: 0.6751\n",
            "Epoch 232/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4078 - accuracy: 0.8183 - val_loss: 0.7875 - val_accuracy: 0.6719\n",
            "Epoch 233/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4062 - accuracy: 0.8164 - val_loss: 0.7842 - val_accuracy: 0.6716\n",
            "Epoch 234/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4076 - accuracy: 0.8172 - val_loss: 0.8219 - val_accuracy: 0.6629\n",
            "Epoch 235/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4090 - accuracy: 0.8150 - val_loss: 0.7771 - val_accuracy: 0.6791\n",
            "Epoch 236/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4076 - accuracy: 0.8156 - val_loss: 0.7782 - val_accuracy: 0.6766\n",
            "Epoch 237/1000\n",
            "161/161 [==============================] - 8s 51ms/step - loss: 0.4046 - accuracy: 0.8194 - val_loss: 0.7979 - val_accuracy: 0.6734\n",
            "Epoch 238/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4087 - accuracy: 0.8141 - val_loss: 0.7951 - val_accuracy: 0.6706\n",
            "Epoch 239/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4069 - accuracy: 0.8136 - val_loss: 0.7929 - val_accuracy: 0.6739\n",
            "Epoch 240/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4079 - accuracy: 0.8139 - val_loss: 0.7953 - val_accuracy: 0.6771\n",
            "Epoch 241/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4112 - accuracy: 0.8144 - val_loss: 0.7879 - val_accuracy: 0.6761\n",
            "Epoch 242/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4057 - accuracy: 0.8182 - val_loss: 0.7821 - val_accuracy: 0.6751\n",
            "Epoch 243/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4079 - accuracy: 0.8164 - val_loss: 0.7879 - val_accuracy: 0.6769\n",
            "Epoch 244/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4062 - accuracy: 0.8166 - val_loss: 0.7935 - val_accuracy: 0.6751\n",
            "Epoch 245/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4082 - accuracy: 0.8158 - val_loss: 0.7896 - val_accuracy: 0.6736\n",
            "Epoch 246/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4069 - accuracy: 0.8166 - val_loss: 0.7923 - val_accuracy: 0.6704\n",
            "Epoch 247/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4100 - accuracy: 0.8156 - val_loss: 0.7807 - val_accuracy: 0.6749\n",
            "Epoch 248/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4048 - accuracy: 0.8189 - val_loss: 0.8025 - val_accuracy: 0.6692\n",
            "Epoch 249/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4057 - accuracy: 0.8192 - val_loss: 0.7897 - val_accuracy: 0.6684\n",
            "Epoch 250/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4073 - accuracy: 0.8165 - val_loss: 0.7822 - val_accuracy: 0.6769\n",
            "Epoch 251/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4072 - accuracy: 0.8163 - val_loss: 0.7816 - val_accuracy: 0.6826\n",
            "Epoch 252/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4083 - accuracy: 0.8176 - val_loss: 0.7837 - val_accuracy: 0.6766\n",
            "Epoch 253/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4073 - accuracy: 0.8161 - val_loss: 0.7858 - val_accuracy: 0.6744\n",
            "Epoch 254/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4088 - accuracy: 0.8149 - val_loss: 0.7892 - val_accuracy: 0.6771\n",
            "Epoch 255/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4069 - accuracy: 0.8171 - val_loss: 0.7953 - val_accuracy: 0.6709\n",
            "Epoch 256/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4067 - accuracy: 0.8169 - val_loss: 0.8049 - val_accuracy: 0.6701\n",
            "Epoch 257/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4050 - accuracy: 0.8192 - val_loss: 0.7942 - val_accuracy: 0.6756\n",
            "Epoch 258/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4079 - accuracy: 0.8170 - val_loss: 0.7949 - val_accuracy: 0.6761\n",
            "Epoch 259/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4073 - accuracy: 0.8175 - val_loss: 0.7875 - val_accuracy: 0.6769\n",
            "Epoch 260/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4073 - accuracy: 0.8169 - val_loss: 0.7972 - val_accuracy: 0.6744\n",
            "Epoch 261/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4081 - accuracy: 0.8159 - val_loss: 0.7920 - val_accuracy: 0.6766\n",
            "Epoch 262/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4055 - accuracy: 0.8165 - val_loss: 0.8010 - val_accuracy: 0.6734\n",
            "Epoch 263/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4071 - accuracy: 0.8144 - val_loss: 0.7760 - val_accuracy: 0.6774\n",
            "Epoch 264/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4080 - accuracy: 0.8141 - val_loss: 0.8005 - val_accuracy: 0.6771\n",
            "Epoch 265/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4072 - accuracy: 0.8148 - val_loss: 0.7993 - val_accuracy: 0.6684\n",
            "Epoch 266/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4070 - accuracy: 0.8166 - val_loss: 0.8011 - val_accuracy: 0.6714\n",
            "Epoch 267/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4071 - accuracy: 0.8171 - val_loss: 0.7977 - val_accuracy: 0.6716\n",
            "Epoch 268/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4080 - accuracy: 0.8145 - val_loss: 0.7943 - val_accuracy: 0.6701\n",
            "Epoch 269/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4077 - accuracy: 0.8156 - val_loss: 0.7855 - val_accuracy: 0.6796\n",
            "Epoch 270/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4066 - accuracy: 0.8169 - val_loss: 0.7910 - val_accuracy: 0.6736\n",
            "Epoch 271/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4055 - accuracy: 0.8185 - val_loss: 0.7865 - val_accuracy: 0.6706\n",
            "Epoch 272/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4063 - accuracy: 0.8158 - val_loss: 0.8021 - val_accuracy: 0.6669\n",
            "Epoch 273/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4091 - accuracy: 0.8143 - val_loss: 0.7986 - val_accuracy: 0.6716\n",
            "Epoch 274/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4070 - accuracy: 0.8160 - val_loss: 0.7777 - val_accuracy: 0.6766\n",
            "Epoch 275/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4074 - accuracy: 0.8164 - val_loss: 0.8004 - val_accuracy: 0.6689\n",
            "Epoch 276/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4099 - accuracy: 0.8155 - val_loss: 0.8064 - val_accuracy: 0.6739\n",
            "Epoch 277/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4084 - accuracy: 0.8130 - val_loss: 0.7953 - val_accuracy: 0.6749\n",
            "Epoch 278/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4076 - accuracy: 0.8159 - val_loss: 0.7956 - val_accuracy: 0.6706\n",
            "Epoch 279/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4063 - accuracy: 0.8190 - val_loss: 0.7981 - val_accuracy: 0.6726\n",
            "Epoch 280/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4057 - accuracy: 0.8165 - val_loss: 0.7906 - val_accuracy: 0.6739\n",
            "Epoch 281/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4044 - accuracy: 0.8174 - val_loss: 0.7864 - val_accuracy: 0.6776\n",
            "Epoch 282/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4055 - accuracy: 0.8146 - val_loss: 0.7998 - val_accuracy: 0.6706\n",
            "Epoch 283/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4062 - accuracy: 0.8176 - val_loss: 0.7848 - val_accuracy: 0.6766\n",
            "Epoch 284/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4060 - accuracy: 0.8166 - val_loss: 0.7954 - val_accuracy: 0.6731\n",
            "Epoch 285/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4088 - accuracy: 0.8145 - val_loss: 0.7903 - val_accuracy: 0.6789\n",
            "Epoch 286/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4056 - accuracy: 0.8192 - val_loss: 0.7941 - val_accuracy: 0.6774\n",
            "Epoch 287/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4051 - accuracy: 0.8181 - val_loss: 0.8001 - val_accuracy: 0.6706\n",
            "Epoch 288/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4063 - accuracy: 0.8187 - val_loss: 0.7970 - val_accuracy: 0.6714\n",
            "Epoch 289/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4077 - accuracy: 0.8151 - val_loss: 0.7983 - val_accuracy: 0.6744\n",
            "Epoch 290/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4087 - accuracy: 0.8167 - val_loss: 0.7917 - val_accuracy: 0.6726\n",
            "Epoch 291/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4068 - accuracy: 0.8175 - val_loss: 0.7989 - val_accuracy: 0.6726\n",
            "Epoch 292/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4096 - accuracy: 0.8133 - val_loss: 0.8047 - val_accuracy: 0.6724\n",
            "Epoch 293/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4091 - accuracy: 0.8139 - val_loss: 0.8026 - val_accuracy: 0.6699\n",
            "Epoch 294/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4051 - accuracy: 0.8190 - val_loss: 0.8018 - val_accuracy: 0.6736\n",
            "Epoch 295/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4046 - accuracy: 0.8202 - val_loss: 0.7999 - val_accuracy: 0.6774\n",
            "Epoch 296/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4086 - accuracy: 0.8157 - val_loss: 0.8058 - val_accuracy: 0.6721\n",
            "Epoch 297/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4070 - accuracy: 0.8163 - val_loss: 0.8004 - val_accuracy: 0.6714\n",
            "Epoch 298/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4068 - accuracy: 0.8176 - val_loss: 0.7994 - val_accuracy: 0.6739\n",
            "Epoch 299/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4061 - accuracy: 0.8182 - val_loss: 0.8160 - val_accuracy: 0.6709\n",
            "Epoch 300/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4056 - accuracy: 0.8181 - val_loss: 0.8067 - val_accuracy: 0.6734\n",
            "Epoch 301/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4057 - accuracy: 0.8163 - val_loss: 0.8023 - val_accuracy: 0.6731\n",
            "Epoch 302/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4051 - accuracy: 0.8162 - val_loss: 0.8108 - val_accuracy: 0.6669\n",
            "Epoch 303/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4047 - accuracy: 0.8186 - val_loss: 0.8051 - val_accuracy: 0.6719\n",
            "Epoch 304/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4059 - accuracy: 0.8162 - val_loss: 0.7964 - val_accuracy: 0.6739\n",
            "Epoch 305/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4082 - accuracy: 0.8122 - val_loss: 0.8163 - val_accuracy: 0.6704\n",
            "Epoch 306/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4054 - accuracy: 0.8169 - val_loss: 0.8001 - val_accuracy: 0.6724\n",
            "Epoch 307/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4062 - accuracy: 0.8162 - val_loss: 0.8052 - val_accuracy: 0.6694\n",
            "Epoch 308/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4054 - accuracy: 0.8164 - val_loss: 0.8055 - val_accuracy: 0.6719\n",
            "Epoch 309/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4066 - accuracy: 0.8147 - val_loss: 0.7989 - val_accuracy: 0.6714\n",
            "Epoch 310/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4097 - accuracy: 0.8145 - val_loss: 0.8035 - val_accuracy: 0.6699\n",
            "Epoch 311/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4062 - accuracy: 0.8166 - val_loss: 0.7989 - val_accuracy: 0.6754\n",
            "Epoch 312/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4056 - accuracy: 0.8162 - val_loss: 0.7954 - val_accuracy: 0.6774\n",
            "Epoch 313/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4061 - accuracy: 0.8144 - val_loss: 0.8057 - val_accuracy: 0.6734\n",
            "Epoch 314/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4051 - accuracy: 0.8177 - val_loss: 0.7985 - val_accuracy: 0.6704\n",
            "Epoch 315/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4069 - accuracy: 0.8161 - val_loss: 0.8026 - val_accuracy: 0.6721\n",
            "Epoch 316/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4046 - accuracy: 0.8179 - val_loss: 0.8024 - val_accuracy: 0.6734\n",
            "Epoch 317/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4057 - accuracy: 0.8184 - val_loss: 0.8043 - val_accuracy: 0.6716\n",
            "Epoch 318/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4065 - accuracy: 0.8161 - val_loss: 0.8153 - val_accuracy: 0.6654\n",
            "Epoch 319/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4053 - accuracy: 0.8179 - val_loss: 0.7962 - val_accuracy: 0.6744\n",
            "Epoch 320/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4081 - accuracy: 0.8171 - val_loss: 0.7975 - val_accuracy: 0.6759\n",
            "Epoch 321/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4048 - accuracy: 0.8174 - val_loss: 0.8026 - val_accuracy: 0.6774\n",
            "Epoch 322/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4065 - accuracy: 0.8181 - val_loss: 0.7973 - val_accuracy: 0.6716\n",
            "Epoch 323/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4057 - accuracy: 0.8147 - val_loss: 0.8015 - val_accuracy: 0.6766\n",
            "Epoch 324/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4049 - accuracy: 0.8174 - val_loss: 0.7992 - val_accuracy: 0.6749\n",
            "Epoch 325/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4060 - accuracy: 0.8174 - val_loss: 0.8104 - val_accuracy: 0.6734\n",
            "Epoch 326/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4055 - accuracy: 0.8186 - val_loss: 0.7997 - val_accuracy: 0.6786\n",
            "Epoch 327/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4081 - accuracy: 0.8146 - val_loss: 0.8004 - val_accuracy: 0.6729\n",
            "Epoch 328/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4060 - accuracy: 0.8165 - val_loss: 0.8039 - val_accuracy: 0.6746\n",
            "Epoch 329/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4077 - accuracy: 0.8151 - val_loss: 0.7973 - val_accuracy: 0.6726\n",
            "Epoch 330/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4045 - accuracy: 0.8209 - val_loss: 0.8082 - val_accuracy: 0.6689\n",
            "Epoch 331/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4042 - accuracy: 0.8180 - val_loss: 0.8045 - val_accuracy: 0.6761\n",
            "Epoch 332/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4074 - accuracy: 0.8169 - val_loss: 0.8244 - val_accuracy: 0.6706\n",
            "Epoch 333/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4058 - accuracy: 0.8166 - val_loss: 0.8036 - val_accuracy: 0.6677\n",
            "Epoch 334/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4064 - accuracy: 0.8164 - val_loss: 0.8124 - val_accuracy: 0.6679\n",
            "Epoch 335/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4099 - accuracy: 0.8136 - val_loss: 0.8104 - val_accuracy: 0.6687\n",
            "Epoch 336/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4066 - accuracy: 0.8185 - val_loss: 0.8086 - val_accuracy: 0.6759\n",
            "Epoch 337/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4048 - accuracy: 0.8139 - val_loss: 0.8193 - val_accuracy: 0.6726\n",
            "Epoch 338/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4081 - accuracy: 0.8148 - val_loss: 0.8166 - val_accuracy: 0.6689\n",
            "Epoch 339/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4071 - accuracy: 0.8151 - val_loss: 0.8160 - val_accuracy: 0.6746\n",
            "Epoch 340/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4081 - accuracy: 0.8157 - val_loss: 0.8081 - val_accuracy: 0.6724\n",
            "Epoch 341/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4072 - accuracy: 0.8147 - val_loss: 0.8116 - val_accuracy: 0.6746\n",
            "Epoch 342/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4059 - accuracy: 0.8178 - val_loss: 0.7959 - val_accuracy: 0.6726\n",
            "Epoch 343/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4064 - accuracy: 0.8166 - val_loss: 0.8013 - val_accuracy: 0.6714\n",
            "Epoch 344/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4067 - accuracy: 0.8172 - val_loss: 0.8047 - val_accuracy: 0.6726\n",
            "Epoch 345/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4068 - accuracy: 0.8153 - val_loss: 0.7946 - val_accuracy: 0.6751\n",
            "Epoch 346/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4055 - accuracy: 0.8184 - val_loss: 0.8063 - val_accuracy: 0.6716\n",
            "Epoch 347/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4066 - accuracy: 0.8181 - val_loss: 0.7996 - val_accuracy: 0.6749\n",
            "Epoch 348/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4071 - accuracy: 0.8188 - val_loss: 0.8093 - val_accuracy: 0.6761\n",
            "Epoch 349/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4103 - accuracy: 0.8132 - val_loss: 0.8038 - val_accuracy: 0.6721\n",
            "Epoch 350/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4052 - accuracy: 0.8180 - val_loss: 0.8116 - val_accuracy: 0.6662\n",
            "Epoch 351/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4049 - accuracy: 0.8188 - val_loss: 0.8079 - val_accuracy: 0.6744\n",
            "Epoch 352/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4076 - accuracy: 0.8142 - val_loss: 0.8075 - val_accuracy: 0.6709\n",
            "Epoch 353/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4072 - accuracy: 0.8162 - val_loss: 0.8109 - val_accuracy: 0.6704\n",
            "Epoch 354/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4067 - accuracy: 0.8162 - val_loss: 0.7982 - val_accuracy: 0.6699\n",
            "Epoch 355/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4076 - accuracy: 0.8185 - val_loss: 0.8011 - val_accuracy: 0.6679\n",
            "Epoch 356/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4055 - accuracy: 0.8172 - val_loss: 0.8014 - val_accuracy: 0.6736\n",
            "Epoch 357/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4072 - accuracy: 0.8163 - val_loss: 0.8195 - val_accuracy: 0.6697\n",
            "Epoch 358/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4064 - accuracy: 0.8169 - val_loss: 0.8053 - val_accuracy: 0.6751\n",
            "Epoch 359/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4059 - accuracy: 0.8188 - val_loss: 0.8012 - val_accuracy: 0.6687\n",
            "Epoch 360/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4082 - accuracy: 0.8163 - val_loss: 0.8100 - val_accuracy: 0.6746\n",
            "Epoch 361/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4042 - accuracy: 0.8189 - val_loss: 0.8019 - val_accuracy: 0.6749\n",
            "Epoch 362/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4055 - accuracy: 0.8168 - val_loss: 0.8042 - val_accuracy: 0.6709\n",
            "Epoch 363/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4047 - accuracy: 0.8174 - val_loss: 0.8059 - val_accuracy: 0.6724\n",
            "Epoch 364/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4077 - accuracy: 0.8171 - val_loss: 0.8535 - val_accuracy: 0.6647\n",
            "Epoch 365/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4085 - accuracy: 0.8142 - val_loss: 0.8064 - val_accuracy: 0.6731\n",
            "Epoch 366/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4055 - accuracy: 0.8187 - val_loss: 0.7965 - val_accuracy: 0.6771\n",
            "Epoch 367/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4084 - accuracy: 0.8150 - val_loss: 0.8117 - val_accuracy: 0.6706\n",
            "Epoch 368/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4058 - accuracy: 0.8172 - val_loss: 0.8231 - val_accuracy: 0.6754\n",
            "Epoch 369/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4077 - accuracy: 0.8132 - val_loss: 0.8081 - val_accuracy: 0.6721\n",
            "Epoch 370/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4076 - accuracy: 0.8141 - val_loss: 0.8109 - val_accuracy: 0.6692\n",
            "Epoch 371/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4070 - accuracy: 0.8162 - val_loss: 0.8056 - val_accuracy: 0.6744\n",
            "Epoch 372/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4082 - accuracy: 0.8158 - val_loss: 0.8007 - val_accuracy: 0.6706\n",
            "Epoch 373/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4051 - accuracy: 0.8177 - val_loss: 0.8024 - val_accuracy: 0.6789\n",
            "Epoch 374/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4041 - accuracy: 0.8162 - val_loss: 0.8017 - val_accuracy: 0.6704\n",
            "Epoch 375/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4045 - accuracy: 0.8177 - val_loss: 0.8022 - val_accuracy: 0.6736\n",
            "Epoch 376/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4058 - accuracy: 0.8172 - val_loss: 0.7979 - val_accuracy: 0.6726\n",
            "Epoch 377/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4054 - accuracy: 0.8166 - val_loss: 0.8066 - val_accuracy: 0.6716\n",
            "Epoch 378/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4068 - accuracy: 0.8150 - val_loss: 0.8076 - val_accuracy: 0.6724\n",
            "Epoch 379/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4073 - accuracy: 0.8146 - val_loss: 0.8117 - val_accuracy: 0.6684\n",
            "Epoch 380/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4069 - accuracy: 0.8146 - val_loss: 0.7927 - val_accuracy: 0.6789\n",
            "Epoch 381/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4122 - accuracy: 0.8136 - val_loss: 0.8033 - val_accuracy: 0.6711\n",
            "Epoch 382/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4068 - accuracy: 0.8166 - val_loss: 0.8239 - val_accuracy: 0.6679\n",
            "Epoch 383/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4059 - accuracy: 0.8166 - val_loss: 0.8052 - val_accuracy: 0.6731\n",
            "Epoch 384/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4110 - accuracy: 0.8140 - val_loss: 0.8145 - val_accuracy: 0.6741\n",
            "Epoch 385/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4040 - accuracy: 0.8171 - val_loss: 0.8133 - val_accuracy: 0.6724\n",
            "Epoch 386/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4052 - accuracy: 0.8176 - val_loss: 0.8163 - val_accuracy: 0.6694\n",
            "Epoch 387/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4075 - accuracy: 0.8143 - val_loss: 0.8059 - val_accuracy: 0.6721\n",
            "Epoch 388/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4055 - accuracy: 0.8154 - val_loss: 0.8010 - val_accuracy: 0.6719\n",
            "Epoch 389/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4042 - accuracy: 0.8188 - val_loss: 0.8111 - val_accuracy: 0.6726\n",
            "Epoch 390/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4049 - accuracy: 0.8174 - val_loss: 0.8066 - val_accuracy: 0.6756\n",
            "Epoch 391/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4095 - accuracy: 0.8125 - val_loss: 0.8063 - val_accuracy: 0.6746\n",
            "Epoch 392/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4057 - accuracy: 0.8173 - val_loss: 0.8015 - val_accuracy: 0.6731\n",
            "Epoch 393/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4069 - accuracy: 0.8157 - val_loss: 0.8152 - val_accuracy: 0.6724\n",
            "Epoch 394/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4047 - accuracy: 0.8171 - val_loss: 0.8057 - val_accuracy: 0.6749\n",
            "Epoch 395/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4054 - accuracy: 0.8166 - val_loss: 0.8144 - val_accuracy: 0.6731\n",
            "Epoch 396/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4061 - accuracy: 0.8166 - val_loss: 0.8329 - val_accuracy: 0.6704\n",
            "Epoch 397/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4044 - accuracy: 0.8160 - val_loss: 0.8260 - val_accuracy: 0.6694\n",
            "Epoch 398/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4044 - accuracy: 0.8205 - val_loss: 0.8031 - val_accuracy: 0.6719\n",
            "Epoch 399/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4061 - accuracy: 0.8152 - val_loss: 0.8035 - val_accuracy: 0.6726\n",
            "Epoch 400/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4058 - accuracy: 0.8161 - val_loss: 0.8056 - val_accuracy: 0.6706\n",
            "Epoch 401/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4047 - accuracy: 0.8169 - val_loss: 0.8123 - val_accuracy: 0.6629\n",
            "Epoch 402/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4073 - accuracy: 0.8141 - val_loss: 0.8050 - val_accuracy: 0.6697\n",
            "Epoch 403/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4052 - accuracy: 0.8174 - val_loss: 0.8199 - val_accuracy: 0.6672\n",
            "Epoch 404/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4067 - accuracy: 0.8190 - val_loss: 0.8223 - val_accuracy: 0.6699\n",
            "Epoch 405/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4058 - accuracy: 0.8151 - val_loss: 0.8244 - val_accuracy: 0.6664\n",
            "Epoch 406/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4053 - accuracy: 0.8153 - val_loss: 0.8141 - val_accuracy: 0.6687\n",
            "Epoch 407/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4074 - accuracy: 0.8158 - val_loss: 0.8424 - val_accuracy: 0.6711\n",
            "Epoch 408/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4074 - accuracy: 0.8158 - val_loss: 0.8096 - val_accuracy: 0.6719\n",
            "Epoch 409/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4067 - accuracy: 0.8164 - val_loss: 0.8153 - val_accuracy: 0.6659\n",
            "Epoch 410/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4084 - accuracy: 0.8142 - val_loss: 0.8119 - val_accuracy: 0.6731\n",
            "Epoch 411/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4055 - accuracy: 0.8168 - val_loss: 0.7984 - val_accuracy: 0.6769\n",
            "Epoch 412/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4053 - accuracy: 0.8173 - val_loss: 0.8074 - val_accuracy: 0.6657\n",
            "Epoch 413/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4044 - accuracy: 0.8185 - val_loss: 0.8031 - val_accuracy: 0.6754\n",
            "Epoch 414/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4040 - accuracy: 0.8181 - val_loss: 0.8170 - val_accuracy: 0.6716\n",
            "Epoch 415/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4039 - accuracy: 0.8181 - val_loss: 0.8126 - val_accuracy: 0.6726\n",
            "Epoch 416/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4055 - accuracy: 0.8166 - val_loss: 0.8245 - val_accuracy: 0.6739\n",
            "Epoch 417/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4043 - accuracy: 0.8160 - val_loss: 0.8454 - val_accuracy: 0.6711\n",
            "Epoch 418/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4058 - accuracy: 0.8174 - val_loss: 0.8064 - val_accuracy: 0.6739\n",
            "Epoch 419/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4043 - accuracy: 0.8176 - val_loss: 0.8113 - val_accuracy: 0.6709\n",
            "Epoch 420/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4056 - accuracy: 0.8161 - val_loss: 0.8056 - val_accuracy: 0.6741\n",
            "Epoch 421/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4047 - accuracy: 0.8187 - val_loss: 0.8276 - val_accuracy: 0.6694\n",
            "Epoch 422/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4064 - accuracy: 0.8177 - val_loss: 0.8106 - val_accuracy: 0.6721\n",
            "Epoch 423/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4066 - accuracy: 0.8174 - val_loss: 0.8140 - val_accuracy: 0.6749\n",
            "Epoch 424/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4064 - accuracy: 0.8169 - val_loss: 0.8082 - val_accuracy: 0.6749\n",
            "Epoch 425/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4063 - accuracy: 0.8154 - val_loss: 0.8041 - val_accuracy: 0.6739\n",
            "Epoch 426/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4052 - accuracy: 0.8182 - val_loss: 0.8010 - val_accuracy: 0.6751\n",
            "Epoch 427/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4048 - accuracy: 0.8162 - val_loss: 0.8143 - val_accuracy: 0.6687\n",
            "Epoch 428/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4071 - accuracy: 0.8153 - val_loss: 0.8164 - val_accuracy: 0.6721\n",
            "Epoch 429/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4078 - accuracy: 0.8182 - val_loss: 0.8059 - val_accuracy: 0.6754\n",
            "Epoch 430/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4068 - accuracy: 0.8160 - val_loss: 0.8250 - val_accuracy: 0.6692\n",
            "Epoch 431/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4060 - accuracy: 0.8168 - val_loss: 0.8151 - val_accuracy: 0.6726\n",
            "Epoch 432/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4048 - accuracy: 0.8171 - val_loss: 0.8056 - val_accuracy: 0.6769\n",
            "Epoch 433/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4048 - accuracy: 0.8163 - val_loss: 0.8107 - val_accuracy: 0.6741\n",
            "Epoch 434/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4069 - accuracy: 0.8167 - val_loss: 0.8317 - val_accuracy: 0.6697\n",
            "Epoch 435/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4048 - accuracy: 0.8182 - val_loss: 0.8074 - val_accuracy: 0.6726\n",
            "Epoch 436/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4068 - accuracy: 0.8150 - val_loss: 0.8087 - val_accuracy: 0.6769\n",
            "Epoch 437/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4053 - accuracy: 0.8182 - val_loss: 0.8109 - val_accuracy: 0.6739\n",
            "Epoch 438/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4054 - accuracy: 0.8163 - val_loss: 0.8075 - val_accuracy: 0.6761\n",
            "Epoch 439/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4043 - accuracy: 0.8168 - val_loss: 0.8197 - val_accuracy: 0.6759\n",
            "Epoch 440/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4075 - accuracy: 0.8167 - val_loss: 0.8127 - val_accuracy: 0.6689\n",
            "Epoch 441/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4051 - accuracy: 0.8178 - val_loss: 0.8160 - val_accuracy: 0.6704\n",
            "Epoch 442/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4051 - accuracy: 0.8192 - val_loss: 0.8242 - val_accuracy: 0.6679\n",
            "Epoch 443/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4043 - accuracy: 0.8171 - val_loss: 0.8101 - val_accuracy: 0.6741\n",
            "Epoch 444/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4058 - accuracy: 0.8166 - val_loss: 0.8087 - val_accuracy: 0.6699\n",
            "Epoch 445/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4073 - accuracy: 0.8161 - val_loss: 0.8179 - val_accuracy: 0.6709\n",
            "Epoch 446/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4080 - accuracy: 0.8136 - val_loss: 0.8269 - val_accuracy: 0.6699\n",
            "Epoch 447/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4120 - accuracy: 0.8160 - val_loss: 0.8104 - val_accuracy: 0.6721\n",
            "Epoch 448/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4049 - accuracy: 0.8149 - val_loss: 0.8185 - val_accuracy: 0.6729\n",
            "Epoch 449/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4056 - accuracy: 0.8174 - val_loss: 0.8217 - val_accuracy: 0.6756\n",
            "Epoch 450/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4051 - accuracy: 0.8178 - val_loss: 0.8133 - val_accuracy: 0.6754\n",
            "Epoch 451/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4036 - accuracy: 0.8181 - val_loss: 0.8190 - val_accuracy: 0.6719\n",
            "Epoch 452/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4043 - accuracy: 0.8174 - val_loss: 0.8128 - val_accuracy: 0.6699\n",
            "Epoch 453/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4041 - accuracy: 0.8167 - val_loss: 0.8034 - val_accuracy: 0.6744\n",
            "Epoch 454/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4050 - accuracy: 0.8172 - val_loss: 0.8209 - val_accuracy: 0.6694\n",
            "Epoch 455/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4074 - accuracy: 0.8141 - val_loss: 0.8226 - val_accuracy: 0.6719\n",
            "Epoch 456/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4056 - accuracy: 0.8150 - val_loss: 0.8111 - val_accuracy: 0.6739\n",
            "Epoch 457/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4044 - accuracy: 0.8184 - val_loss: 0.8147 - val_accuracy: 0.6739\n",
            "Epoch 458/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4064 - accuracy: 0.8153 - val_loss: 0.8211 - val_accuracy: 0.6684\n",
            "Epoch 459/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4053 - accuracy: 0.8166 - val_loss: 0.8122 - val_accuracy: 0.6692\n",
            "Epoch 460/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4061 - accuracy: 0.8171 - val_loss: 0.8183 - val_accuracy: 0.6724\n",
            "Epoch 461/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4050 - accuracy: 0.8187 - val_loss: 0.8143 - val_accuracy: 0.6741\n",
            "Epoch 462/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4057 - accuracy: 0.8162 - val_loss: 0.8307 - val_accuracy: 0.6724\n",
            "Epoch 463/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4049 - accuracy: 0.8177 - val_loss: 0.8180 - val_accuracy: 0.6714\n",
            "Epoch 464/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4090 - accuracy: 0.8153 - val_loss: 0.8279 - val_accuracy: 0.6677\n",
            "Epoch 465/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4048 - accuracy: 0.8175 - val_loss: 0.8302 - val_accuracy: 0.6692\n",
            "Epoch 466/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4046 - accuracy: 0.8178 - val_loss: 0.8166 - val_accuracy: 0.6741\n",
            "Epoch 467/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4061 - accuracy: 0.8182 - val_loss: 0.8147 - val_accuracy: 0.6734\n",
            "Epoch 468/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4071 - accuracy: 0.8157 - val_loss: 0.8392 - val_accuracy: 0.6682\n",
            "Epoch 469/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4075 - accuracy: 0.8157 - val_loss: 0.8178 - val_accuracy: 0.6724\n",
            "Epoch 470/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4049 - accuracy: 0.8193 - val_loss: 0.8129 - val_accuracy: 0.6724\n",
            "Epoch 471/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4071 - accuracy: 0.8177 - val_loss: 0.8162 - val_accuracy: 0.6736\n",
            "Epoch 472/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4067 - accuracy: 0.8137 - val_loss: 0.8148 - val_accuracy: 0.6721\n",
            "Epoch 473/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4054 - accuracy: 0.8175 - val_loss: 0.8148 - val_accuracy: 0.6706\n",
            "Epoch 474/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4079 - accuracy: 0.8149 - val_loss: 0.8218 - val_accuracy: 0.6706\n",
            "Epoch 475/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4060 - accuracy: 0.8179 - val_loss: 0.8200 - val_accuracy: 0.6719\n",
            "Epoch 476/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4054 - accuracy: 0.8179 - val_loss: 0.8212 - val_accuracy: 0.6701\n",
            "Epoch 477/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4056 - accuracy: 0.8179 - val_loss: 0.8499 - val_accuracy: 0.6699\n",
            "Epoch 478/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4057 - accuracy: 0.8164 - val_loss: 0.8104 - val_accuracy: 0.6726\n",
            "Epoch 479/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4061 - accuracy: 0.8161 - val_loss: 0.8279 - val_accuracy: 0.6709\n",
            "Epoch 480/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4071 - accuracy: 0.8146 - val_loss: 0.8139 - val_accuracy: 0.6701\n",
            "Epoch 481/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4057 - accuracy: 0.8182 - val_loss: 0.8230 - val_accuracy: 0.6719\n",
            "Epoch 482/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4083 - accuracy: 0.8157 - val_loss: 0.8075 - val_accuracy: 0.6754\n",
            "Epoch 483/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4045 - accuracy: 0.8192 - val_loss: 0.8198 - val_accuracy: 0.6719\n",
            "Epoch 484/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4072 - accuracy: 0.8176 - val_loss: 0.8286 - val_accuracy: 0.6716\n",
            "Epoch 485/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4052 - accuracy: 0.8205 - val_loss: 0.8125 - val_accuracy: 0.6724\n",
            "Epoch 486/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4057 - accuracy: 0.8162 - val_loss: 0.8116 - val_accuracy: 0.6751\n",
            "Epoch 487/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4062 - accuracy: 0.8163 - val_loss: 0.8188 - val_accuracy: 0.6682\n",
            "Epoch 488/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4057 - accuracy: 0.8170 - val_loss: 0.8237 - val_accuracy: 0.6694\n",
            "Epoch 489/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4069 - accuracy: 0.8160 - val_loss: 0.8104 - val_accuracy: 0.6744\n",
            "Epoch 490/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4050 - accuracy: 0.8178 - val_loss: 0.8162 - val_accuracy: 0.6721\n",
            "Epoch 491/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4052 - accuracy: 0.8172 - val_loss: 0.8122 - val_accuracy: 0.6706\n",
            "Epoch 492/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4044 - accuracy: 0.8172 - val_loss: 0.8189 - val_accuracy: 0.6692\n",
            "Epoch 493/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4060 - accuracy: 0.8174 - val_loss: 0.8385 - val_accuracy: 0.6699\n",
            "Epoch 494/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4077 - accuracy: 0.8158 - val_loss: 0.8190 - val_accuracy: 0.6719\n",
            "Epoch 495/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4061 - accuracy: 0.8165 - val_loss: 0.8132 - val_accuracy: 0.6721\n",
            "Epoch 496/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4057 - accuracy: 0.8157 - val_loss: 0.8261 - val_accuracy: 0.6726\n",
            "Epoch 497/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4057 - accuracy: 0.8177 - val_loss: 0.8260 - val_accuracy: 0.6674\n",
            "Epoch 498/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4059 - accuracy: 0.8181 - val_loss: 0.8238 - val_accuracy: 0.6729\n",
            "Epoch 499/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4093 - accuracy: 0.8154 - val_loss: 0.8302 - val_accuracy: 0.6714\n",
            "Epoch 500/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4040 - accuracy: 0.8175 - val_loss: 0.8200 - val_accuracy: 0.6694\n",
            "Epoch 501/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4053 - accuracy: 0.8169 - val_loss: 0.8226 - val_accuracy: 0.6734\n",
            "Epoch 502/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4055 - accuracy: 0.8180 - val_loss: 0.8243 - val_accuracy: 0.6674\n",
            "Epoch 503/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4072 - accuracy: 0.8161 - val_loss: 0.8253 - val_accuracy: 0.6734\n",
            "Epoch 504/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4059 - accuracy: 0.8172 - val_loss: 0.8150 - val_accuracy: 0.6746\n",
            "Epoch 505/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4084 - accuracy: 0.8149 - val_loss: 0.8172 - val_accuracy: 0.6692\n",
            "Epoch 506/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4044 - accuracy: 0.8171 - val_loss: 0.8129 - val_accuracy: 0.6714\n",
            "Epoch 507/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4073 - accuracy: 0.8159 - val_loss: 0.8415 - val_accuracy: 0.6637\n",
            "Epoch 508/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4098 - accuracy: 0.8149 - val_loss: 0.8224 - val_accuracy: 0.6662\n",
            "Epoch 509/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4043 - accuracy: 0.8174 - val_loss: 0.8262 - val_accuracy: 0.6761\n",
            "Epoch 510/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4043 - accuracy: 0.8198 - val_loss: 0.8250 - val_accuracy: 0.6692\n",
            "Epoch 511/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4053 - accuracy: 0.8164 - val_loss: 0.8160 - val_accuracy: 0.6746\n",
            "Epoch 512/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4104 - accuracy: 0.8134 - val_loss: 0.8158 - val_accuracy: 0.6711\n",
            "Epoch 513/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4073 - accuracy: 0.8136 - val_loss: 0.8308 - val_accuracy: 0.6689\n",
            "Epoch 514/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4064 - accuracy: 0.8162 - val_loss: 0.8259 - val_accuracy: 0.6711\n",
            "Epoch 515/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4040 - accuracy: 0.8184 - val_loss: 0.8176 - val_accuracy: 0.6759\n",
            "Epoch 516/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4054 - accuracy: 0.8164 - val_loss: 0.8188 - val_accuracy: 0.6736\n",
            "Epoch 517/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4049 - accuracy: 0.8180 - val_loss: 0.8308 - val_accuracy: 0.6682\n",
            "Epoch 518/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4044 - accuracy: 0.8181 - val_loss: 0.8260 - val_accuracy: 0.6694\n",
            "Epoch 519/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4060 - accuracy: 0.8168 - val_loss: 0.8381 - val_accuracy: 0.6687\n",
            "Epoch 520/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4070 - accuracy: 0.8167 - val_loss: 0.8203 - val_accuracy: 0.6714\n",
            "Epoch 521/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4065 - accuracy: 0.8157 - val_loss: 0.8257 - val_accuracy: 0.6699\n",
            "Epoch 522/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4088 - accuracy: 0.8167 - val_loss: 0.8461 - val_accuracy: 0.6697\n",
            "Epoch 523/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4084 - accuracy: 0.8161 - val_loss: 0.8238 - val_accuracy: 0.6692\n",
            "Epoch 524/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4047 - accuracy: 0.8168 - val_loss: 0.8521 - val_accuracy: 0.6704\n",
            "Epoch 525/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4066 - accuracy: 0.8158 - val_loss: 0.8284 - val_accuracy: 0.6716\n",
            "Epoch 526/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4045 - accuracy: 0.8183 - val_loss: 0.8119 - val_accuracy: 0.6751\n",
            "Epoch 527/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4056 - accuracy: 0.8175 - val_loss: 0.8194 - val_accuracy: 0.6741\n",
            "Epoch 528/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4057 - accuracy: 0.8154 - val_loss: 0.8245 - val_accuracy: 0.6724\n",
            "Epoch 529/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4055 - accuracy: 0.8188 - val_loss: 0.8222 - val_accuracy: 0.6699\n",
            "Epoch 530/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4053 - accuracy: 0.8186 - val_loss: 0.8255 - val_accuracy: 0.6766\n",
            "Epoch 531/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4057 - accuracy: 0.8151 - val_loss: 0.8293 - val_accuracy: 0.6682\n",
            "Epoch 532/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4063 - accuracy: 0.8181 - val_loss: 0.8211 - val_accuracy: 0.6731\n",
            "Epoch 533/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4069 - accuracy: 0.8179 - val_loss: 0.8278 - val_accuracy: 0.6706\n",
            "Epoch 534/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4062 - accuracy: 0.8155 - val_loss: 0.8303 - val_accuracy: 0.6716\n",
            "Epoch 535/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4056 - accuracy: 0.8187 - val_loss: 0.8226 - val_accuracy: 0.6692\n",
            "Epoch 536/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4051 - accuracy: 0.8190 - val_loss: 0.8201 - val_accuracy: 0.6749\n",
            "Epoch 537/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4072 - accuracy: 0.8154 - val_loss: 0.8300 - val_accuracy: 0.6721\n",
            "Epoch 538/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4047 - accuracy: 0.8173 - val_loss: 0.8267 - val_accuracy: 0.6674\n",
            "Epoch 539/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4068 - accuracy: 0.8170 - val_loss: 0.8135 - val_accuracy: 0.6746\n",
            "Epoch 540/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4079 - accuracy: 0.8167 - val_loss: 0.8239 - val_accuracy: 0.6709\n",
            "Epoch 541/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4073 - accuracy: 0.8155 - val_loss: 0.8299 - val_accuracy: 0.6709\n",
            "Epoch 542/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4055 - accuracy: 0.8171 - val_loss: 0.8594 - val_accuracy: 0.6667\n",
            "Epoch 543/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4056 - accuracy: 0.8152 - val_loss: 0.8186 - val_accuracy: 0.6739\n",
            "Epoch 544/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4041 - accuracy: 0.8195 - val_loss: 0.8214 - val_accuracy: 0.6701\n",
            "Epoch 545/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4067 - accuracy: 0.8169 - val_loss: 0.8129 - val_accuracy: 0.6766\n",
            "Epoch 546/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4056 - accuracy: 0.8182 - val_loss: 0.8270 - val_accuracy: 0.6706\n",
            "Epoch 547/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4049 - accuracy: 0.8176 - val_loss: 0.8397 - val_accuracy: 0.6667\n",
            "Epoch 548/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4073 - accuracy: 0.8148 - val_loss: 0.8198 - val_accuracy: 0.6759\n",
            "Epoch 549/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4055 - accuracy: 0.8182 - val_loss: 0.8262 - val_accuracy: 0.6764\n",
            "Epoch 550/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4068 - accuracy: 0.8167 - val_loss: 0.8147 - val_accuracy: 0.6754\n",
            "Epoch 551/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4059 - accuracy: 0.8168 - val_loss: 0.8177 - val_accuracy: 0.6706\n",
            "Epoch 552/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4036 - accuracy: 0.8164 - val_loss: 0.8259 - val_accuracy: 0.6734\n",
            "Epoch 553/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4051 - accuracy: 0.8169 - val_loss: 0.8211 - val_accuracy: 0.6759\n",
            "Epoch 554/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4059 - accuracy: 0.8179 - val_loss: 0.8271 - val_accuracy: 0.6711\n",
            "Epoch 555/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4064 - accuracy: 0.8161 - val_loss: 0.8451 - val_accuracy: 0.6664\n",
            "Epoch 556/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4040 - accuracy: 0.8167 - val_loss: 0.8400 - val_accuracy: 0.6662\n",
            "Epoch 557/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4056 - accuracy: 0.8171 - val_loss: 0.8265 - val_accuracy: 0.6719\n",
            "Epoch 558/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4077 - accuracy: 0.8162 - val_loss: 0.8264 - val_accuracy: 0.6689\n",
            "Epoch 559/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4078 - accuracy: 0.8169 - val_loss: 0.8416 - val_accuracy: 0.6704\n",
            "Epoch 560/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4068 - accuracy: 0.8166 - val_loss: 0.8189 - val_accuracy: 0.6749\n",
            "Epoch 561/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4053 - accuracy: 0.8189 - val_loss: 0.8508 - val_accuracy: 0.6669\n",
            "Epoch 562/1000\n",
            "161/161 [==============================] - 10s 59ms/step - loss: 0.4067 - accuracy: 0.8167 - val_loss: 0.8276 - val_accuracy: 0.6739\n",
            "Epoch 563/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4058 - accuracy: 0.8177 - val_loss: 0.8169 - val_accuracy: 0.6729\n",
            "Epoch 564/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4042 - accuracy: 0.8178 - val_loss: 0.8364 - val_accuracy: 0.6657\n",
            "Epoch 565/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4034 - accuracy: 0.8192 - val_loss: 0.8260 - val_accuracy: 0.6726\n",
            "Epoch 566/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4053 - accuracy: 0.8165 - val_loss: 0.8256 - val_accuracy: 0.6682\n",
            "Epoch 567/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4045 - accuracy: 0.8173 - val_loss: 0.8256 - val_accuracy: 0.6692\n",
            "Epoch 568/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4053 - accuracy: 0.8157 - val_loss: 0.8212 - val_accuracy: 0.6726\n",
            "Epoch 569/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4070 - accuracy: 0.8144 - val_loss: 0.8184 - val_accuracy: 0.6729\n",
            "Epoch 570/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4053 - accuracy: 0.8170 - val_loss: 0.8299 - val_accuracy: 0.6682\n",
            "Epoch 571/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4053 - accuracy: 0.8181 - val_loss: 0.8186 - val_accuracy: 0.6754\n",
            "Epoch 572/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4052 - accuracy: 0.8149 - val_loss: 0.8460 - val_accuracy: 0.6664\n",
            "Epoch 573/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4087 - accuracy: 0.8151 - val_loss: 0.8237 - val_accuracy: 0.6736\n",
            "Epoch 574/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4055 - accuracy: 0.8156 - val_loss: 0.8331 - val_accuracy: 0.6694\n",
            "Epoch 575/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4045 - accuracy: 0.8167 - val_loss: 0.8157 - val_accuracy: 0.6721\n",
            "Epoch 576/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4054 - accuracy: 0.8153 - val_loss: 0.8209 - val_accuracy: 0.6689\n",
            "Epoch 577/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4037 - accuracy: 0.8175 - val_loss: 0.8171 - val_accuracy: 0.6731\n",
            "Epoch 578/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4040 - accuracy: 0.8172 - val_loss: 0.8407 - val_accuracy: 0.6644\n",
            "Epoch 579/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4064 - accuracy: 0.8174 - val_loss: 0.8325 - val_accuracy: 0.6714\n",
            "Epoch 580/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4038 - accuracy: 0.8189 - val_loss: 0.8172 - val_accuracy: 0.6774\n",
            "Epoch 581/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4055 - accuracy: 0.8182 - val_loss: 0.8310 - val_accuracy: 0.6736\n",
            "Epoch 582/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4056 - accuracy: 0.8174 - val_loss: 0.8232 - val_accuracy: 0.6701\n",
            "Epoch 583/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4058 - accuracy: 0.8173 - val_loss: 0.8177 - val_accuracy: 0.6731\n",
            "Epoch 584/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4053 - accuracy: 0.8184 - val_loss: 0.8175 - val_accuracy: 0.6803\n",
            "Epoch 585/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4058 - accuracy: 0.8187 - val_loss: 0.8283 - val_accuracy: 0.6711\n",
            "Epoch 586/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4051 - accuracy: 0.8168 - val_loss: 0.8204 - val_accuracy: 0.6726\n",
            "Epoch 587/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4074 - accuracy: 0.8166 - val_loss: 0.8315 - val_accuracy: 0.6716\n",
            "Epoch 588/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4044 - accuracy: 0.8161 - val_loss: 0.8232 - val_accuracy: 0.6709\n",
            "Epoch 589/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4061 - accuracy: 0.8167 - val_loss: 0.8318 - val_accuracy: 0.6729\n",
            "Epoch 590/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4090 - accuracy: 0.8149 - val_loss: 0.8279 - val_accuracy: 0.6721\n",
            "Epoch 591/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4038 - accuracy: 0.8184 - val_loss: 0.8284 - val_accuracy: 0.6739\n",
            "Epoch 592/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4053 - accuracy: 0.8183 - val_loss: 0.8145 - val_accuracy: 0.6761\n",
            "Epoch 593/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4052 - accuracy: 0.8167 - val_loss: 0.8274 - val_accuracy: 0.6704\n",
            "Epoch 594/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4041 - accuracy: 0.8174 - val_loss: 0.8293 - val_accuracy: 0.6741\n",
            "Epoch 595/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4063 - accuracy: 0.8185 - val_loss: 0.8337 - val_accuracy: 0.6726\n",
            "Epoch 596/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4066 - accuracy: 0.8182 - val_loss: 0.8201 - val_accuracy: 0.6734\n",
            "Epoch 597/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4050 - accuracy: 0.8179 - val_loss: 0.8347 - val_accuracy: 0.6716\n",
            "Epoch 598/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4045 - accuracy: 0.8177 - val_loss: 0.8179 - val_accuracy: 0.6724\n",
            "Epoch 599/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4050 - accuracy: 0.8177 - val_loss: 0.8250 - val_accuracy: 0.6729\n",
            "Epoch 600/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4067 - accuracy: 0.8179 - val_loss: 0.8561 - val_accuracy: 0.6709\n",
            "Epoch 601/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4090 - accuracy: 0.8141 - val_loss: 0.8233 - val_accuracy: 0.6716\n",
            "Epoch 602/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4068 - accuracy: 0.8161 - val_loss: 0.8291 - val_accuracy: 0.6684\n",
            "Epoch 603/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4047 - accuracy: 0.8172 - val_loss: 0.8283 - val_accuracy: 0.6734\n",
            "Epoch 604/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4055 - accuracy: 0.8176 - val_loss: 0.8231 - val_accuracy: 0.6739\n",
            "Epoch 605/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4081 - accuracy: 0.8136 - val_loss: 0.8269 - val_accuracy: 0.6739\n",
            "Epoch 606/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4037 - accuracy: 0.8185 - val_loss: 0.8275 - val_accuracy: 0.6726\n",
            "Epoch 607/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4041 - accuracy: 0.8178 - val_loss: 0.8366 - val_accuracy: 0.6716\n",
            "Epoch 608/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4042 - accuracy: 0.8169 - val_loss: 0.8312 - val_accuracy: 0.6692\n",
            "Epoch 609/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4057 - accuracy: 0.8177 - val_loss: 0.8372 - val_accuracy: 0.6729\n",
            "Epoch 610/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4062 - accuracy: 0.8170 - val_loss: 0.8363 - val_accuracy: 0.6692\n",
            "Epoch 611/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4084 - accuracy: 0.8139 - val_loss: 0.8241 - val_accuracy: 0.6754\n",
            "Epoch 612/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4082 - accuracy: 0.8159 - val_loss: 0.8204 - val_accuracy: 0.6761\n",
            "Epoch 613/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4056 - accuracy: 0.8163 - val_loss: 0.8301 - val_accuracy: 0.6741\n",
            "Epoch 614/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4047 - accuracy: 0.8180 - val_loss: 0.8397 - val_accuracy: 0.6674\n",
            "Epoch 615/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4051 - accuracy: 0.8181 - val_loss: 0.8336 - val_accuracy: 0.6709\n",
            "Epoch 616/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4052 - accuracy: 0.8179 - val_loss: 0.8306 - val_accuracy: 0.6764\n",
            "Epoch 617/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4067 - accuracy: 0.8166 - val_loss: 0.8433 - val_accuracy: 0.6667\n",
            "Epoch 618/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4053 - accuracy: 0.8161 - val_loss: 0.8356 - val_accuracy: 0.6731\n",
            "Epoch 619/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4057 - accuracy: 0.8153 - val_loss: 0.8319 - val_accuracy: 0.6729\n",
            "Epoch 620/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4071 - accuracy: 0.8160 - val_loss: 0.8214 - val_accuracy: 0.6749\n",
            "Epoch 621/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4060 - accuracy: 0.8158 - val_loss: 0.8234 - val_accuracy: 0.6746\n",
            "Epoch 622/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4057 - accuracy: 0.8142 - val_loss: 0.8353 - val_accuracy: 0.6736\n",
            "Epoch 623/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4065 - accuracy: 0.8175 - val_loss: 0.8369 - val_accuracy: 0.6684\n",
            "Epoch 624/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4061 - accuracy: 0.8176 - val_loss: 0.8435 - val_accuracy: 0.6682\n",
            "Epoch 625/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4043 - accuracy: 0.8182 - val_loss: 0.8258 - val_accuracy: 0.6741\n",
            "Epoch 626/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4040 - accuracy: 0.8172 - val_loss: 0.8296 - val_accuracy: 0.6689\n",
            "Epoch 627/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4061 - accuracy: 0.8169 - val_loss: 0.8305 - val_accuracy: 0.6692\n",
            "Epoch 628/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4030 - accuracy: 0.8179 - val_loss: 0.8240 - val_accuracy: 0.6741\n",
            "Epoch 629/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4060 - accuracy: 0.8172 - val_loss: 0.8378 - val_accuracy: 0.6719\n",
            "Epoch 630/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4060 - accuracy: 0.8142 - val_loss: 0.8340 - val_accuracy: 0.6736\n",
            "Epoch 631/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4027 - accuracy: 0.8205 - val_loss: 0.8269 - val_accuracy: 0.6709\n",
            "Epoch 632/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4057 - accuracy: 0.8192 - val_loss: 0.8151 - val_accuracy: 0.6719\n",
            "Epoch 633/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4061 - accuracy: 0.8159 - val_loss: 0.8263 - val_accuracy: 0.6721\n",
            "Epoch 634/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4067 - accuracy: 0.8171 - val_loss: 0.8288 - val_accuracy: 0.6724\n",
            "Epoch 635/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4060 - accuracy: 0.8144 - val_loss: 0.8342 - val_accuracy: 0.6706\n",
            "Epoch 636/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4051 - accuracy: 0.8199 - val_loss: 0.8174 - val_accuracy: 0.6759\n",
            "Epoch 637/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4068 - accuracy: 0.8161 - val_loss: 0.8247 - val_accuracy: 0.6736\n",
            "Epoch 638/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4050 - accuracy: 0.8178 - val_loss: 0.8479 - val_accuracy: 0.6669\n",
            "Epoch 639/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4044 - accuracy: 0.8179 - val_loss: 0.8303 - val_accuracy: 0.6726\n",
            "Epoch 640/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4063 - accuracy: 0.8171 - val_loss: 0.8336 - val_accuracy: 0.6719\n",
            "Epoch 641/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4073 - accuracy: 0.8167 - val_loss: 0.8235 - val_accuracy: 0.6761\n",
            "Epoch 642/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4067 - accuracy: 0.8146 - val_loss: 0.8307 - val_accuracy: 0.6704\n",
            "Epoch 643/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4032 - accuracy: 0.8176 - val_loss: 0.8338 - val_accuracy: 0.6687\n",
            "Epoch 644/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4058 - accuracy: 0.8154 - val_loss: 0.8277 - val_accuracy: 0.6749\n",
            "Epoch 645/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4060 - accuracy: 0.8174 - val_loss: 0.8251 - val_accuracy: 0.6729\n",
            "Epoch 646/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4036 - accuracy: 0.8194 - val_loss: 0.8282 - val_accuracy: 0.6711\n",
            "Epoch 647/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4062 - accuracy: 0.8154 - val_loss: 0.8359 - val_accuracy: 0.6734\n",
            "Epoch 648/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4056 - accuracy: 0.8167 - val_loss: 0.8176 - val_accuracy: 0.6736\n",
            "Epoch 649/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4059 - accuracy: 0.8145 - val_loss: 0.8304 - val_accuracy: 0.6687\n",
            "Epoch 650/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4077 - accuracy: 0.8153 - val_loss: 0.8279 - val_accuracy: 0.6739\n",
            "Epoch 651/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4075 - accuracy: 0.8153 - val_loss: 0.8333 - val_accuracy: 0.6692\n",
            "Epoch 652/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4042 - accuracy: 0.8190 - val_loss: 0.8343 - val_accuracy: 0.6674\n",
            "Epoch 653/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4047 - accuracy: 0.8166 - val_loss: 0.8330 - val_accuracy: 0.6689\n",
            "Epoch 654/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4040 - accuracy: 0.8181 - val_loss: 0.8390 - val_accuracy: 0.6731\n",
            "Epoch 655/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4072 - accuracy: 0.8165 - val_loss: 0.8317 - val_accuracy: 0.6697\n",
            "Epoch 656/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4051 - accuracy: 0.8185 - val_loss: 0.8345 - val_accuracy: 0.6687\n",
            "Epoch 657/1000\n",
            "161/161 [==============================] - 8s 51ms/step - loss: 0.4048 - accuracy: 0.8177 - val_loss: 0.8267 - val_accuracy: 0.6724\n",
            "Epoch 658/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4052 - accuracy: 0.8190 - val_loss: 0.8355 - val_accuracy: 0.6694\n",
            "Epoch 659/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4035 - accuracy: 0.8185 - val_loss: 0.8389 - val_accuracy: 0.6679\n",
            "Epoch 660/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4056 - accuracy: 0.8161 - val_loss: 0.8472 - val_accuracy: 0.6649\n",
            "Epoch 661/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4048 - accuracy: 0.8162 - val_loss: 0.8255 - val_accuracy: 0.6754\n",
            "Epoch 662/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4056 - accuracy: 0.8159 - val_loss: 0.8432 - val_accuracy: 0.6679\n",
            "Epoch 663/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4061 - accuracy: 0.8170 - val_loss: 0.8284 - val_accuracy: 0.6756\n",
            "Epoch 664/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4074 - accuracy: 0.8137 - val_loss: 0.8349 - val_accuracy: 0.6701\n",
            "Epoch 665/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4049 - accuracy: 0.8164 - val_loss: 0.8392 - val_accuracy: 0.6697\n",
            "Epoch 666/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4064 - accuracy: 0.8166 - val_loss: 0.8209 - val_accuracy: 0.6754\n",
            "Epoch 667/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4073 - accuracy: 0.8178 - val_loss: 0.8350 - val_accuracy: 0.6667\n",
            "Epoch 668/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4040 - accuracy: 0.8177 - val_loss: 0.8362 - val_accuracy: 0.6687\n",
            "Epoch 669/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4075 - accuracy: 0.8183 - val_loss: 0.8340 - val_accuracy: 0.6724\n",
            "Epoch 670/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4051 - accuracy: 0.8180 - val_loss: 0.8624 - val_accuracy: 0.6664\n",
            "Epoch 671/1000\n",
            "161/161 [==============================] - 10s 59ms/step - loss: 0.4084 - accuracy: 0.8147 - val_loss: 0.8509 - val_accuracy: 0.6706\n",
            "Epoch 672/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4094 - accuracy: 0.8141 - val_loss: 0.8305 - val_accuracy: 0.6714\n",
            "Epoch 673/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4043 - accuracy: 0.8182 - val_loss: 0.8206 - val_accuracy: 0.6729\n",
            "Epoch 674/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4041 - accuracy: 0.8191 - val_loss: 0.8273 - val_accuracy: 0.6744\n",
            "Epoch 675/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4059 - accuracy: 0.8178 - val_loss: 0.8347 - val_accuracy: 0.6701\n",
            "Epoch 676/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4063 - accuracy: 0.8178 - val_loss: 0.8286 - val_accuracy: 0.6699\n",
            "Epoch 677/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4053 - accuracy: 0.8196 - val_loss: 0.8440 - val_accuracy: 0.6716\n",
            "Epoch 678/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4032 - accuracy: 0.8172 - val_loss: 0.8320 - val_accuracy: 0.6726\n",
            "Epoch 679/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4053 - accuracy: 0.8181 - val_loss: 0.8330 - val_accuracy: 0.6706\n",
            "Epoch 680/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4053 - accuracy: 0.8160 - val_loss: 0.8545 - val_accuracy: 0.6689\n",
            "Epoch 681/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4041 - accuracy: 0.8191 - val_loss: 0.8420 - val_accuracy: 0.6699\n",
            "Epoch 682/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4053 - accuracy: 0.8166 - val_loss: 0.8429 - val_accuracy: 0.6677\n",
            "Epoch 683/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4049 - accuracy: 0.8182 - val_loss: 0.8436 - val_accuracy: 0.6697\n",
            "Epoch 684/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4044 - accuracy: 0.8172 - val_loss: 0.8332 - val_accuracy: 0.6761\n",
            "Epoch 685/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4035 - accuracy: 0.8182 - val_loss: 0.8235 - val_accuracy: 0.6769\n",
            "Epoch 686/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4058 - accuracy: 0.8184 - val_loss: 0.8399 - val_accuracy: 0.6714\n",
            "Epoch 687/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4043 - accuracy: 0.8184 - val_loss: 0.8419 - val_accuracy: 0.6709\n",
            "Epoch 688/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4064 - accuracy: 0.8192 - val_loss: 0.8323 - val_accuracy: 0.6764\n",
            "Epoch 689/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4046 - accuracy: 0.8174 - val_loss: 0.8255 - val_accuracy: 0.6726\n",
            "Epoch 690/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4088 - accuracy: 0.8168 - val_loss: 0.8415 - val_accuracy: 0.6714\n",
            "Epoch 691/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4051 - accuracy: 0.8186 - val_loss: 0.8478 - val_accuracy: 0.6677\n",
            "Epoch 692/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4041 - accuracy: 0.8177 - val_loss: 0.8347 - val_accuracy: 0.6726\n",
            "Epoch 693/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4034 - accuracy: 0.8159 - val_loss: 0.8462 - val_accuracy: 0.6672\n",
            "Epoch 694/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4058 - accuracy: 0.8157 - val_loss: 0.8224 - val_accuracy: 0.6719\n",
            "Epoch 695/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4082 - accuracy: 0.8141 - val_loss: 0.8254 - val_accuracy: 0.6784\n",
            "Epoch 696/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4064 - accuracy: 0.8165 - val_loss: 0.8390 - val_accuracy: 0.6736\n",
            "Epoch 697/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4047 - accuracy: 0.8169 - val_loss: 0.8184 - val_accuracy: 0.6729\n",
            "Epoch 698/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4080 - accuracy: 0.8155 - val_loss: 0.8398 - val_accuracy: 0.6704\n",
            "Epoch 699/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4055 - accuracy: 0.8176 - val_loss: 0.8344 - val_accuracy: 0.6706\n",
            "Epoch 700/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4056 - accuracy: 0.8168 - val_loss: 0.8323 - val_accuracy: 0.6706\n",
            "Epoch 701/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4044 - accuracy: 0.8174 - val_loss: 0.8528 - val_accuracy: 0.6647\n",
            "Epoch 702/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4091 - accuracy: 0.8149 - val_loss: 0.8355 - val_accuracy: 0.6716\n",
            "Epoch 703/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4057 - accuracy: 0.8189 - val_loss: 0.8355 - val_accuracy: 0.6689\n",
            "Epoch 704/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4072 - accuracy: 0.8157 - val_loss: 0.8613 - val_accuracy: 0.6667\n",
            "Epoch 705/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4069 - accuracy: 0.8167 - val_loss: 0.8239 - val_accuracy: 0.6724\n",
            "Epoch 706/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4060 - accuracy: 0.8168 - val_loss: 0.8395 - val_accuracy: 0.6706\n",
            "Epoch 707/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4043 - accuracy: 0.8191 - val_loss: 0.8386 - val_accuracy: 0.6711\n",
            "Epoch 708/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4042 - accuracy: 0.8175 - val_loss: 0.8430 - val_accuracy: 0.6664\n",
            "Epoch 709/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4063 - accuracy: 0.8181 - val_loss: 0.8370 - val_accuracy: 0.6719\n",
            "Epoch 710/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4061 - accuracy: 0.8178 - val_loss: 0.8463 - val_accuracy: 0.6699\n",
            "Epoch 711/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4050 - accuracy: 0.8175 - val_loss: 0.8343 - val_accuracy: 0.6724\n",
            "Epoch 712/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4047 - accuracy: 0.8185 - val_loss: 0.8345 - val_accuracy: 0.6741\n",
            "Epoch 713/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4056 - accuracy: 0.8144 - val_loss: 0.8303 - val_accuracy: 0.6741\n",
            "Epoch 714/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4088 - accuracy: 0.8136 - val_loss: 0.8381 - val_accuracy: 0.6756\n",
            "Epoch 715/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4063 - accuracy: 0.8173 - val_loss: 0.8315 - val_accuracy: 0.6714\n",
            "Epoch 716/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4034 - accuracy: 0.8174 - val_loss: 0.8238 - val_accuracy: 0.6729\n",
            "Epoch 717/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4037 - accuracy: 0.8194 - val_loss: 0.8467 - val_accuracy: 0.6714\n",
            "Epoch 718/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4053 - accuracy: 0.8165 - val_loss: 0.8397 - val_accuracy: 0.6734\n",
            "Epoch 719/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4090 - accuracy: 0.8136 - val_loss: 0.8428 - val_accuracy: 0.6692\n",
            "Epoch 720/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4034 - accuracy: 0.8199 - val_loss: 0.8372 - val_accuracy: 0.6714\n",
            "Epoch 721/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4042 - accuracy: 0.8172 - val_loss: 0.8396 - val_accuracy: 0.6709\n",
            "Epoch 722/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4051 - accuracy: 0.8169 - val_loss: 0.8375 - val_accuracy: 0.6697\n",
            "Epoch 723/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4044 - accuracy: 0.8173 - val_loss: 0.8507 - val_accuracy: 0.6756\n",
            "Epoch 724/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4060 - accuracy: 0.8162 - val_loss: 0.8293 - val_accuracy: 0.6734\n",
            "Epoch 725/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4072 - accuracy: 0.8170 - val_loss: 0.8321 - val_accuracy: 0.6726\n",
            "Epoch 726/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4041 - accuracy: 0.8162 - val_loss: 0.8366 - val_accuracy: 0.6674\n",
            "Epoch 727/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4046 - accuracy: 0.8192 - val_loss: 0.8181 - val_accuracy: 0.6761\n",
            "Epoch 728/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4069 - accuracy: 0.8154 - val_loss: 0.8423 - val_accuracy: 0.6771\n",
            "Epoch 729/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4045 - accuracy: 0.8184 - val_loss: 0.8400 - val_accuracy: 0.6714\n",
            "Epoch 730/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4059 - accuracy: 0.8166 - val_loss: 0.8312 - val_accuracy: 0.6701\n",
            "Epoch 731/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4053 - accuracy: 0.8179 - val_loss: 0.8358 - val_accuracy: 0.6729\n",
            "Epoch 732/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4063 - accuracy: 0.8156 - val_loss: 0.8417 - val_accuracy: 0.6736\n",
            "Epoch 733/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4040 - accuracy: 0.8189 - val_loss: 0.8303 - val_accuracy: 0.6701\n",
            "Epoch 734/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4040 - accuracy: 0.8167 - val_loss: 0.8273 - val_accuracy: 0.6794\n",
            "Epoch 735/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4061 - accuracy: 0.8178 - val_loss: 0.8451 - val_accuracy: 0.6699\n",
            "Epoch 736/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4052 - accuracy: 0.8150 - val_loss: 0.8512 - val_accuracy: 0.6699\n",
            "Epoch 737/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4068 - accuracy: 0.8179 - val_loss: 0.8471 - val_accuracy: 0.6637\n",
            "Epoch 738/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4054 - accuracy: 0.8178 - val_loss: 0.8358 - val_accuracy: 0.6692\n",
            "Epoch 739/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4075 - accuracy: 0.8145 - val_loss: 0.8353 - val_accuracy: 0.6704\n",
            "Epoch 740/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4069 - accuracy: 0.8161 - val_loss: 0.8374 - val_accuracy: 0.6709\n",
            "Epoch 741/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4062 - accuracy: 0.8203 - val_loss: 0.8491 - val_accuracy: 0.6704\n",
            "Epoch 742/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4059 - accuracy: 0.8163 - val_loss: 0.8494 - val_accuracy: 0.6684\n",
            "Epoch 743/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4049 - accuracy: 0.8181 - val_loss: 0.8423 - val_accuracy: 0.6694\n",
            "Epoch 744/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4041 - accuracy: 0.8164 - val_loss: 0.8450 - val_accuracy: 0.6694\n",
            "Epoch 745/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4052 - accuracy: 0.8185 - val_loss: 0.8340 - val_accuracy: 0.6734\n",
            "Epoch 746/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4063 - accuracy: 0.8167 - val_loss: 0.8276 - val_accuracy: 0.6746\n",
            "Epoch 747/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4064 - accuracy: 0.8155 - val_loss: 0.8331 - val_accuracy: 0.6739\n",
            "Epoch 748/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4059 - accuracy: 0.8171 - val_loss: 0.8324 - val_accuracy: 0.6679\n",
            "Epoch 749/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4063 - accuracy: 0.8164 - val_loss: 0.8904 - val_accuracy: 0.6662\n",
            "Epoch 750/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4069 - accuracy: 0.8154 - val_loss: 0.8350 - val_accuracy: 0.6746\n",
            "Epoch 751/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4042 - accuracy: 0.8190 - val_loss: 0.8503 - val_accuracy: 0.6677\n",
            "Epoch 752/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4020 - accuracy: 0.8190 - val_loss: 0.8377 - val_accuracy: 0.6687\n",
            "Epoch 753/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4052 - accuracy: 0.8183 - val_loss: 0.8340 - val_accuracy: 0.6692\n",
            "Epoch 754/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4079 - accuracy: 0.8156 - val_loss: 0.8419 - val_accuracy: 0.6726\n",
            "Epoch 755/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4068 - accuracy: 0.8129 - val_loss: 0.8413 - val_accuracy: 0.6697\n",
            "Epoch 756/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4045 - accuracy: 0.8175 - val_loss: 0.8452 - val_accuracy: 0.6736\n",
            "Epoch 757/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4065 - accuracy: 0.8144 - val_loss: 0.8433 - val_accuracy: 0.6716\n",
            "Epoch 758/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4075 - accuracy: 0.8175 - val_loss: 0.8277 - val_accuracy: 0.6786\n",
            "Epoch 759/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4051 - accuracy: 0.8162 - val_loss: 0.8408 - val_accuracy: 0.6754\n",
            "Epoch 760/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4039 - accuracy: 0.8167 - val_loss: 0.8453 - val_accuracy: 0.6692\n",
            "Epoch 761/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4069 - accuracy: 0.8156 - val_loss: 0.8392 - val_accuracy: 0.6704\n",
            "Epoch 762/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4075 - accuracy: 0.8162 - val_loss: 0.8386 - val_accuracy: 0.6749\n",
            "Epoch 763/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4052 - accuracy: 0.8153 - val_loss: 0.8460 - val_accuracy: 0.6669\n",
            "Epoch 764/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4058 - accuracy: 0.8162 - val_loss: 0.8479 - val_accuracy: 0.6692\n",
            "Epoch 765/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4054 - accuracy: 0.8189 - val_loss: 0.8503 - val_accuracy: 0.6701\n",
            "Epoch 766/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4097 - accuracy: 0.8162 - val_loss: 0.8346 - val_accuracy: 0.6741\n",
            "Epoch 767/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4048 - accuracy: 0.8179 - val_loss: 0.8411 - val_accuracy: 0.6694\n",
            "Epoch 768/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4046 - accuracy: 0.8161 - val_loss: 0.8439 - val_accuracy: 0.6709\n",
            "Epoch 769/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4044 - accuracy: 0.8199 - val_loss: 0.8527 - val_accuracy: 0.6692\n",
            "Epoch 770/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4080 - accuracy: 0.8155 - val_loss: 0.8381 - val_accuracy: 0.6719\n",
            "Epoch 771/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4073 - accuracy: 0.8174 - val_loss: 0.8426 - val_accuracy: 0.6674\n",
            "Epoch 772/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4052 - accuracy: 0.8169 - val_loss: 0.8546 - val_accuracy: 0.6706\n",
            "Epoch 773/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4060 - accuracy: 0.8179 - val_loss: 0.8371 - val_accuracy: 0.6692\n",
            "Epoch 774/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4056 - accuracy: 0.8169 - val_loss: 0.8274 - val_accuracy: 0.6714\n",
            "Epoch 775/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4044 - accuracy: 0.8170 - val_loss: 0.8451 - val_accuracy: 0.6751\n",
            "Epoch 776/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4061 - accuracy: 0.8174 - val_loss: 0.8343 - val_accuracy: 0.6704\n",
            "Epoch 777/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4059 - accuracy: 0.8168 - val_loss: 0.8474 - val_accuracy: 0.6699\n",
            "Epoch 778/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4054 - accuracy: 0.8183 - val_loss: 0.8309 - val_accuracy: 0.6679\n",
            "Epoch 779/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4057 - accuracy: 0.8164 - val_loss: 0.8334 - val_accuracy: 0.6709\n",
            "Epoch 780/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4067 - accuracy: 0.8145 - val_loss: 0.8464 - val_accuracy: 0.6684\n",
            "Epoch 781/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4040 - accuracy: 0.8188 - val_loss: 0.8336 - val_accuracy: 0.6711\n",
            "Epoch 782/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4047 - accuracy: 0.8171 - val_loss: 0.8356 - val_accuracy: 0.6706\n",
            "Epoch 783/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4039 - accuracy: 0.8179 - val_loss: 0.8454 - val_accuracy: 0.6669\n",
            "Epoch 784/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4090 - accuracy: 0.8128 - val_loss: 0.8401 - val_accuracy: 0.6716\n",
            "Epoch 785/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4050 - accuracy: 0.8182 - val_loss: 0.8599 - val_accuracy: 0.6674\n",
            "Epoch 786/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4059 - accuracy: 0.8179 - val_loss: 0.8476 - val_accuracy: 0.6731\n",
            "Epoch 787/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4053 - accuracy: 0.8187 - val_loss: 0.8490 - val_accuracy: 0.6679\n",
            "Epoch 788/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4085 - accuracy: 0.8146 - val_loss: 0.8506 - val_accuracy: 0.6721\n",
            "Epoch 789/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4066 - accuracy: 0.8159 - val_loss: 0.8415 - val_accuracy: 0.6716\n",
            "Epoch 790/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4048 - accuracy: 0.8176 - val_loss: 0.8483 - val_accuracy: 0.6689\n",
            "Epoch 791/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4048 - accuracy: 0.8166 - val_loss: 0.8448 - val_accuracy: 0.6746\n",
            "Epoch 792/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4056 - accuracy: 0.8161 - val_loss: 0.8353 - val_accuracy: 0.6749\n",
            "Epoch 793/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4057 - accuracy: 0.8172 - val_loss: 0.8393 - val_accuracy: 0.6674\n",
            "Epoch 794/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4052 - accuracy: 0.8149 - val_loss: 0.8338 - val_accuracy: 0.6731\n",
            "Epoch 795/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4074 - accuracy: 0.8151 - val_loss: 0.8447 - val_accuracy: 0.6706\n",
            "Epoch 796/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4041 - accuracy: 0.8164 - val_loss: 0.8364 - val_accuracy: 0.6701\n",
            "Epoch 797/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4041 - accuracy: 0.8163 - val_loss: 0.8491 - val_accuracy: 0.6669\n",
            "Epoch 798/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4057 - accuracy: 0.8155 - val_loss: 0.8365 - val_accuracy: 0.6704\n",
            "Epoch 799/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4049 - accuracy: 0.8175 - val_loss: 0.8324 - val_accuracy: 0.6764\n",
            "Epoch 800/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4077 - accuracy: 0.8164 - val_loss: 0.8439 - val_accuracy: 0.6684\n",
            "Epoch 801/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4051 - accuracy: 0.8164 - val_loss: 0.8447 - val_accuracy: 0.6709\n",
            "Epoch 802/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4057 - accuracy: 0.8189 - val_loss: 0.8535 - val_accuracy: 0.6679\n",
            "Epoch 803/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4053 - accuracy: 0.8199 - val_loss: 0.8441 - val_accuracy: 0.6674\n",
            "Epoch 804/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4067 - accuracy: 0.8155 - val_loss: 0.8461 - val_accuracy: 0.6677\n",
            "Epoch 805/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4042 - accuracy: 0.8176 - val_loss: 0.8292 - val_accuracy: 0.6731\n",
            "Epoch 806/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4060 - accuracy: 0.8169 - val_loss: 0.8360 - val_accuracy: 0.6689\n",
            "Epoch 807/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4033 - accuracy: 0.8184 - val_loss: 0.8373 - val_accuracy: 0.6734\n",
            "Epoch 808/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4066 - accuracy: 0.8161 - val_loss: 0.8488 - val_accuracy: 0.6667\n",
            "Epoch 809/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4072 - accuracy: 0.8149 - val_loss: 0.8509 - val_accuracy: 0.6721\n",
            "Epoch 810/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4063 - accuracy: 0.8155 - val_loss: 0.8521 - val_accuracy: 0.6699\n",
            "Epoch 811/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4049 - accuracy: 0.8179 - val_loss: 0.8417 - val_accuracy: 0.6674\n",
            "Epoch 812/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4053 - accuracy: 0.8171 - val_loss: 0.8511 - val_accuracy: 0.6669\n",
            "Epoch 813/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4044 - accuracy: 0.8177 - val_loss: 0.8478 - val_accuracy: 0.6687\n",
            "Epoch 814/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4041 - accuracy: 0.8179 - val_loss: 0.8441 - val_accuracy: 0.6736\n",
            "Epoch 815/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4084 - accuracy: 0.8173 - val_loss: 0.8411 - val_accuracy: 0.6697\n",
            "Epoch 816/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4027 - accuracy: 0.8180 - val_loss: 0.8440 - val_accuracy: 0.6659\n",
            "Epoch 817/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4079 - accuracy: 0.8157 - val_loss: 0.8483 - val_accuracy: 0.6689\n",
            "Epoch 818/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4071 - accuracy: 0.8166 - val_loss: 0.8574 - val_accuracy: 0.6697\n",
            "Epoch 819/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4049 - accuracy: 0.8166 - val_loss: 0.8351 - val_accuracy: 0.6729\n",
            "Epoch 820/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4066 - accuracy: 0.8126 - val_loss: 0.8615 - val_accuracy: 0.6701\n",
            "Epoch 821/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4061 - accuracy: 0.8172 - val_loss: 0.8504 - val_accuracy: 0.6689\n",
            "Epoch 822/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4055 - accuracy: 0.8164 - val_loss: 0.8444 - val_accuracy: 0.6699\n",
            "Epoch 823/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4056 - accuracy: 0.8159 - val_loss: 0.8398 - val_accuracy: 0.6726\n",
            "Epoch 824/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4059 - accuracy: 0.8171 - val_loss: 0.8444 - val_accuracy: 0.6697\n",
            "Epoch 825/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4054 - accuracy: 0.8166 - val_loss: 0.8242 - val_accuracy: 0.6754\n",
            "Epoch 826/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4053 - accuracy: 0.8182 - val_loss: 0.8460 - val_accuracy: 0.6709\n",
            "Epoch 827/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4051 - accuracy: 0.8152 - val_loss: 0.8384 - val_accuracy: 0.6726\n",
            "Epoch 828/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4066 - accuracy: 0.8175 - val_loss: 0.8351 - val_accuracy: 0.6746\n",
            "Epoch 829/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4040 - accuracy: 0.8159 - val_loss: 0.8439 - val_accuracy: 0.6706\n",
            "Epoch 830/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4052 - accuracy: 0.8153 - val_loss: 0.8359 - val_accuracy: 0.6744\n",
            "Epoch 831/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4061 - accuracy: 0.8167 - val_loss: 0.8618 - val_accuracy: 0.6751\n",
            "Epoch 832/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4053 - accuracy: 0.8175 - val_loss: 0.8556 - val_accuracy: 0.6754\n",
            "Epoch 833/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4086 - accuracy: 0.8156 - val_loss: 0.8460 - val_accuracy: 0.6699\n",
            "Epoch 834/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4066 - accuracy: 0.8148 - val_loss: 0.8405 - val_accuracy: 0.6682\n",
            "Epoch 835/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4050 - accuracy: 0.8167 - val_loss: 0.8432 - val_accuracy: 0.6682\n",
            "Epoch 836/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4048 - accuracy: 0.8185 - val_loss: 0.8594 - val_accuracy: 0.6761\n",
            "Epoch 837/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4063 - accuracy: 0.8160 - val_loss: 0.8468 - val_accuracy: 0.6704\n",
            "Epoch 838/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4053 - accuracy: 0.8170 - val_loss: 0.8352 - val_accuracy: 0.6754\n",
            "Epoch 839/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4038 - accuracy: 0.8168 - val_loss: 0.8446 - val_accuracy: 0.6657\n",
            "Epoch 840/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4041 - accuracy: 0.8169 - val_loss: 0.8329 - val_accuracy: 0.6724\n",
            "Epoch 841/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4044 - accuracy: 0.8189 - val_loss: 0.8314 - val_accuracy: 0.6726\n",
            "Epoch 842/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4053 - accuracy: 0.8182 - val_loss: 0.8342 - val_accuracy: 0.6749\n",
            "Epoch 843/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4056 - accuracy: 0.8153 - val_loss: 0.8407 - val_accuracy: 0.6764\n",
            "Epoch 844/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4055 - accuracy: 0.8156 - val_loss: 0.8277 - val_accuracy: 0.6749\n",
            "Epoch 845/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4094 - accuracy: 0.8145 - val_loss: 0.8431 - val_accuracy: 0.6716\n",
            "Epoch 846/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4042 - accuracy: 0.8189 - val_loss: 0.8384 - val_accuracy: 0.6711\n",
            "Epoch 847/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4068 - accuracy: 0.8182 - val_loss: 0.8387 - val_accuracy: 0.6716\n",
            "Epoch 848/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4036 - accuracy: 0.8176 - val_loss: 0.8452 - val_accuracy: 0.6711\n",
            "Epoch 849/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4061 - accuracy: 0.8173 - val_loss: 0.8387 - val_accuracy: 0.6771\n",
            "Epoch 850/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4041 - accuracy: 0.8198 - val_loss: 0.8367 - val_accuracy: 0.6719\n",
            "Epoch 851/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4061 - accuracy: 0.8154 - val_loss: 0.8298 - val_accuracy: 0.6776\n",
            "Epoch 852/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4045 - accuracy: 0.8162 - val_loss: 0.8405 - val_accuracy: 0.6699\n",
            "Epoch 853/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4039 - accuracy: 0.8190 - val_loss: 0.8483 - val_accuracy: 0.6734\n",
            "Epoch 854/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4054 - accuracy: 0.8182 - val_loss: 0.8349 - val_accuracy: 0.6759\n",
            "Epoch 855/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4070 - accuracy: 0.8161 - val_loss: 0.8536 - val_accuracy: 0.6704\n",
            "Epoch 856/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4055 - accuracy: 0.8159 - val_loss: 0.8385 - val_accuracy: 0.6729\n",
            "Epoch 857/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4043 - accuracy: 0.8174 - val_loss: 0.8471 - val_accuracy: 0.6739\n",
            "Epoch 858/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4066 - accuracy: 0.8180 - val_loss: 0.8514 - val_accuracy: 0.6699\n",
            "Epoch 859/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4034 - accuracy: 0.8175 - val_loss: 0.8396 - val_accuracy: 0.6759\n",
            "Epoch 860/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4087 - accuracy: 0.8157 - val_loss: 0.8435 - val_accuracy: 0.6714\n",
            "Epoch 861/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4047 - accuracy: 0.8185 - val_loss: 0.8380 - val_accuracy: 0.6746\n",
            "Epoch 862/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4059 - accuracy: 0.8185 - val_loss: 0.8592 - val_accuracy: 0.6729\n",
            "Epoch 863/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4040 - accuracy: 0.8174 - val_loss: 0.8588 - val_accuracy: 0.6699\n",
            "Epoch 864/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4065 - accuracy: 0.8158 - val_loss: 0.8474 - val_accuracy: 0.6697\n",
            "Epoch 865/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4056 - accuracy: 0.8184 - val_loss: 0.8366 - val_accuracy: 0.6701\n",
            "Epoch 866/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4029 - accuracy: 0.8175 - val_loss: 0.8401 - val_accuracy: 0.6746\n",
            "Epoch 867/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4070 - accuracy: 0.8144 - val_loss: 0.8539 - val_accuracy: 0.6682\n",
            "Epoch 868/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4057 - accuracy: 0.8186 - val_loss: 0.8646 - val_accuracy: 0.6706\n",
            "Epoch 869/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4077 - accuracy: 0.8167 - val_loss: 0.8518 - val_accuracy: 0.6759\n",
            "Epoch 870/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4033 - accuracy: 0.8181 - val_loss: 0.8491 - val_accuracy: 0.6739\n",
            "Epoch 871/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4044 - accuracy: 0.8168 - val_loss: 0.8555 - val_accuracy: 0.6704\n",
            "Epoch 872/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4072 - accuracy: 0.8157 - val_loss: 0.8463 - val_accuracy: 0.6766\n",
            "Epoch 873/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4047 - accuracy: 0.8182 - val_loss: 0.8343 - val_accuracy: 0.6749\n",
            "Epoch 874/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4045 - accuracy: 0.8194 - val_loss: 0.8598 - val_accuracy: 0.6731\n",
            "Epoch 875/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4069 - accuracy: 0.8167 - val_loss: 0.8525 - val_accuracy: 0.6729\n",
            "Epoch 876/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4057 - accuracy: 0.8170 - val_loss: 0.8474 - val_accuracy: 0.6736\n",
            "Epoch 877/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4066 - accuracy: 0.8148 - val_loss: 0.8446 - val_accuracy: 0.6706\n",
            "Epoch 878/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4049 - accuracy: 0.8185 - val_loss: 0.8414 - val_accuracy: 0.6786\n",
            "Epoch 879/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4065 - accuracy: 0.8172 - val_loss: 0.8449 - val_accuracy: 0.6716\n",
            "Epoch 880/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4042 - accuracy: 0.8193 - val_loss: 0.8458 - val_accuracy: 0.6749\n",
            "Epoch 881/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4046 - accuracy: 0.8194 - val_loss: 0.8496 - val_accuracy: 0.6687\n",
            "Epoch 882/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4038 - accuracy: 0.8183 - val_loss: 0.8349 - val_accuracy: 0.6706\n",
            "Epoch 883/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4054 - accuracy: 0.8167 - val_loss: 0.8539 - val_accuracy: 0.6711\n",
            "Epoch 884/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4055 - accuracy: 0.8173 - val_loss: 0.8597 - val_accuracy: 0.6662\n",
            "Epoch 885/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4052 - accuracy: 0.8160 - val_loss: 0.8569 - val_accuracy: 0.6679\n",
            "Epoch 886/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4088 - accuracy: 0.8130 - val_loss: 0.8632 - val_accuracy: 0.6694\n",
            "Epoch 887/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4066 - accuracy: 0.8175 - val_loss: 0.8499 - val_accuracy: 0.6714\n",
            "Epoch 888/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4050 - accuracy: 0.8184 - val_loss: 0.8411 - val_accuracy: 0.6756\n",
            "Epoch 889/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4074 - accuracy: 0.8173 - val_loss: 0.8879 - val_accuracy: 0.6644\n",
            "Epoch 890/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4073 - accuracy: 0.8158 - val_loss: 0.8476 - val_accuracy: 0.6669\n",
            "Epoch 891/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4054 - accuracy: 0.8185 - val_loss: 0.8491 - val_accuracy: 0.6741\n",
            "Epoch 892/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4060 - accuracy: 0.8154 - val_loss: 0.8495 - val_accuracy: 0.6721\n",
            "Epoch 893/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4081 - accuracy: 0.8179 - val_loss: 0.8547 - val_accuracy: 0.6689\n",
            "Epoch 894/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4051 - accuracy: 0.8169 - val_loss: 0.8462 - val_accuracy: 0.6706\n",
            "Epoch 895/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4038 - accuracy: 0.8205 - val_loss: 0.8414 - val_accuracy: 0.6734\n",
            "Epoch 896/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4029 - accuracy: 0.8215 - val_loss: 0.8468 - val_accuracy: 0.6734\n",
            "Epoch 897/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4051 - accuracy: 0.8172 - val_loss: 0.8523 - val_accuracy: 0.6697\n",
            "Epoch 898/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4052 - accuracy: 0.8193 - val_loss: 0.8574 - val_accuracy: 0.6719\n",
            "Epoch 899/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4050 - accuracy: 0.8153 - val_loss: 0.8557 - val_accuracy: 0.6674\n",
            "Epoch 900/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4080 - accuracy: 0.8141 - val_loss: 0.8521 - val_accuracy: 0.6672\n",
            "Epoch 901/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4042 - accuracy: 0.8154 - val_loss: 0.8599 - val_accuracy: 0.6684\n",
            "Epoch 902/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4040 - accuracy: 0.8172 - val_loss: 0.8453 - val_accuracy: 0.6679\n",
            "Epoch 903/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4054 - accuracy: 0.8161 - val_loss: 0.8545 - val_accuracy: 0.6642\n",
            "Epoch 904/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4059 - accuracy: 0.8160 - val_loss: 0.8477 - val_accuracy: 0.6731\n",
            "Epoch 905/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4057 - accuracy: 0.8184 - val_loss: 0.8549 - val_accuracy: 0.6729\n",
            "Epoch 906/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4066 - accuracy: 0.8169 - val_loss: 0.8629 - val_accuracy: 0.6689\n",
            "Epoch 907/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4054 - accuracy: 0.8196 - val_loss: 0.8428 - val_accuracy: 0.6739\n",
            "Epoch 908/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4063 - accuracy: 0.8197 - val_loss: 0.8547 - val_accuracy: 0.6704\n",
            "Epoch 909/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4031 - accuracy: 0.8207 - val_loss: 0.8487 - val_accuracy: 0.6682\n",
            "Epoch 910/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4049 - accuracy: 0.8184 - val_loss: 0.8449 - val_accuracy: 0.6692\n",
            "Epoch 911/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4061 - accuracy: 0.8156 - val_loss: 0.8544 - val_accuracy: 0.6699\n",
            "Epoch 912/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4062 - accuracy: 0.8163 - val_loss: 0.8552 - val_accuracy: 0.6714\n",
            "Epoch 913/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4056 - accuracy: 0.8156 - val_loss: 0.8423 - val_accuracy: 0.6711\n",
            "Epoch 914/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4043 - accuracy: 0.8164 - val_loss: 0.8430 - val_accuracy: 0.6734\n",
            "Epoch 915/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4042 - accuracy: 0.8163 - val_loss: 0.8658 - val_accuracy: 0.6704\n",
            "Epoch 916/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4049 - accuracy: 0.8183 - val_loss: 0.8439 - val_accuracy: 0.6694\n",
            "Epoch 917/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4052 - accuracy: 0.8178 - val_loss: 0.8698 - val_accuracy: 0.6704\n",
            "Epoch 918/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4054 - accuracy: 0.8163 - val_loss: 0.8391 - val_accuracy: 0.6724\n",
            "Epoch 919/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4105 - accuracy: 0.8139 - val_loss: 0.8373 - val_accuracy: 0.6791\n",
            "Epoch 920/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4045 - accuracy: 0.8199 - val_loss: 0.8377 - val_accuracy: 0.6709\n",
            "Epoch 921/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4051 - accuracy: 0.8175 - val_loss: 0.8447 - val_accuracy: 0.6729\n",
            "Epoch 922/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4063 - accuracy: 0.8176 - val_loss: 0.8512 - val_accuracy: 0.6694\n",
            "Epoch 923/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4051 - accuracy: 0.8188 - val_loss: 0.8534 - val_accuracy: 0.6682\n",
            "Epoch 924/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4053 - accuracy: 0.8184 - val_loss: 0.8531 - val_accuracy: 0.6749\n",
            "Epoch 925/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4089 - accuracy: 0.8142 - val_loss: 0.8631 - val_accuracy: 0.6684\n",
            "Epoch 926/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4072 - accuracy: 0.8151 - val_loss: 0.8491 - val_accuracy: 0.6689\n",
            "Epoch 927/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4047 - accuracy: 0.8195 - val_loss: 0.8400 - val_accuracy: 0.6714\n",
            "Epoch 928/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4036 - accuracy: 0.8201 - val_loss: 0.8583 - val_accuracy: 0.6697\n",
            "Epoch 929/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4052 - accuracy: 0.8161 - val_loss: 0.8447 - val_accuracy: 0.6734\n",
            "Epoch 930/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4047 - accuracy: 0.8174 - val_loss: 0.8549 - val_accuracy: 0.6667\n",
            "Epoch 931/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4064 - accuracy: 0.8164 - val_loss: 0.8397 - val_accuracy: 0.6716\n",
            "Epoch 932/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4059 - accuracy: 0.8166 - val_loss: 0.8533 - val_accuracy: 0.6699\n",
            "Epoch 933/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4046 - accuracy: 0.8170 - val_loss: 0.8497 - val_accuracy: 0.6672\n",
            "Epoch 934/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4041 - accuracy: 0.8179 - val_loss: 0.8454 - val_accuracy: 0.6709\n",
            "Epoch 935/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4036 - accuracy: 0.8174 - val_loss: 0.8455 - val_accuracy: 0.6719\n",
            "Epoch 936/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4043 - accuracy: 0.8167 - val_loss: 0.8498 - val_accuracy: 0.6674\n",
            "Epoch 937/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4038 - accuracy: 0.8173 - val_loss: 0.8625 - val_accuracy: 0.6652\n",
            "Epoch 938/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4064 - accuracy: 0.8151 - val_loss: 0.8498 - val_accuracy: 0.6764\n",
            "Epoch 939/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4063 - accuracy: 0.8161 - val_loss: 0.8492 - val_accuracy: 0.6694\n",
            "Epoch 940/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4073 - accuracy: 0.8172 - val_loss: 0.8461 - val_accuracy: 0.6721\n",
            "Epoch 941/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4047 - accuracy: 0.8177 - val_loss: 0.8471 - val_accuracy: 0.6699\n",
            "Epoch 942/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4039 - accuracy: 0.8183 - val_loss: 0.8469 - val_accuracy: 0.6754\n",
            "Epoch 943/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4056 - accuracy: 0.8184 - val_loss: 0.8474 - val_accuracy: 0.6679\n",
            "Epoch 944/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4061 - accuracy: 0.8161 - val_loss: 0.8559 - val_accuracy: 0.6697\n",
            "Epoch 945/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4053 - accuracy: 0.8184 - val_loss: 0.8391 - val_accuracy: 0.6711\n",
            "Epoch 946/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4046 - accuracy: 0.8176 - val_loss: 0.8472 - val_accuracy: 0.6704\n",
            "Epoch 947/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4048 - accuracy: 0.8170 - val_loss: 0.8434 - val_accuracy: 0.6711\n",
            "Epoch 948/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4059 - accuracy: 0.8181 - val_loss: 0.8559 - val_accuracy: 0.6662\n",
            "Epoch 949/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4038 - accuracy: 0.8176 - val_loss: 0.8535 - val_accuracy: 0.6726\n",
            "Epoch 950/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4076 - accuracy: 0.8145 - val_loss: 0.8415 - val_accuracy: 0.6726\n",
            "Epoch 951/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4072 - accuracy: 0.8166 - val_loss: 0.8589 - val_accuracy: 0.6697\n",
            "Epoch 952/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4060 - accuracy: 0.8162 - val_loss: 0.8580 - val_accuracy: 0.6704\n",
            "Epoch 953/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4040 - accuracy: 0.8172 - val_loss: 0.8474 - val_accuracy: 0.6726\n",
            "Epoch 954/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4063 - accuracy: 0.8164 - val_loss: 0.8486 - val_accuracy: 0.6692\n",
            "Epoch 955/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4033 - accuracy: 0.8181 - val_loss: 0.8388 - val_accuracy: 0.6761\n",
            "Epoch 956/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4041 - accuracy: 0.8187 - val_loss: 0.8582 - val_accuracy: 0.6649\n",
            "Epoch 957/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4053 - accuracy: 0.8184 - val_loss: 0.8372 - val_accuracy: 0.6746\n",
            "Epoch 958/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4052 - accuracy: 0.8165 - val_loss: 0.8477 - val_accuracy: 0.6719\n",
            "Epoch 959/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4053 - accuracy: 0.8184 - val_loss: 0.8438 - val_accuracy: 0.6739\n",
            "Epoch 960/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4052 - accuracy: 0.8167 - val_loss: 0.8485 - val_accuracy: 0.6721\n",
            "Epoch 961/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4088 - accuracy: 0.8138 - val_loss: 0.8506 - val_accuracy: 0.6744\n",
            "Epoch 962/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4056 - accuracy: 0.8158 - val_loss: 0.8436 - val_accuracy: 0.6714\n",
            "Epoch 963/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4043 - accuracy: 0.8180 - val_loss: 0.8490 - val_accuracy: 0.6729\n",
            "Epoch 964/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4035 - accuracy: 0.8194 - val_loss: 0.8425 - val_accuracy: 0.6719\n",
            "Epoch 965/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4056 - accuracy: 0.8181 - val_loss: 0.8488 - val_accuracy: 0.6744\n",
            "Epoch 966/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4033 - accuracy: 0.8171 - val_loss: 0.8517 - val_accuracy: 0.6724\n",
            "Epoch 967/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4039 - accuracy: 0.8190 - val_loss: 0.8539 - val_accuracy: 0.6719\n",
            "Epoch 968/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4055 - accuracy: 0.8179 - val_loss: 0.8480 - val_accuracy: 0.6706\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4055 - accuracy: 0.8179 - val_loss: 0.8480 - val_accuracy: 0.6706\n",
            "Epoch 969/1000\n",
            "Epoch 969/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4050 - accuracy: 0.8200 - val_loss: 0.8470 - val_accuracy: 0.6684\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4050 - accuracy: 0.8200 - val_loss: 0.8470 - val_accuracy: 0.6684\n",
            "Epoch 970/1000\n",
            "Epoch 970/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4062 - accuracy: 0.8182 - val_loss: 0.8717 - val_accuracy: 0.6697\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4062 - accuracy: 0.8182 - val_loss: 0.8717 - val_accuracy: 0.6697\n",
            "Epoch 971/1000\n",
            "Epoch 971/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4060 - accuracy: 0.8182 - val_loss: 0.8432 - val_accuracy: 0.6739\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4060 - accuracy: 0.8182 - val_loss: 0.8432 - val_accuracy: 0.6739\n",
            "Epoch 972/1000\n",
            "Epoch 972/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4056 - accuracy: 0.8187 - val_loss: 0.8597 - val_accuracy: 0.6704\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4056 - accuracy: 0.8187 - val_loss: 0.8597 - val_accuracy: 0.6704\n",
            "Epoch 973/1000\n",
            "Epoch 973/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4039 - accuracy: 0.8188 - val_loss: 0.8445 - val_accuracy: 0.6677\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4039 - accuracy: 0.8188 - val_loss: 0.8445 - val_accuracy: 0.6677\n",
            "Epoch 974/1000\n",
            "Epoch 974/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4062 - accuracy: 0.8167 - val_loss: 0.8353 - val_accuracy: 0.6726\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4062 - accuracy: 0.8167 - val_loss: 0.8353 - val_accuracy: 0.6726\n",
            "Epoch 975/1000\n",
            "Epoch 975/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4034 - accuracy: 0.8157 - val_loss: 0.8580 - val_accuracy: 0.6697\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4034 - accuracy: 0.8157 - val_loss: 0.8580 - val_accuracy: 0.6697\n",
            "Epoch 976/1000\n",
            "Epoch 976/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4048 - accuracy: 0.8171 - val_loss: 0.8537 - val_accuracy: 0.6709\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4048 - accuracy: 0.8171 - val_loss: 0.8537 - val_accuracy: 0.6709\n",
            "Epoch 977/1000\n",
            "Epoch 977/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4043 - accuracy: 0.8191 - val_loss: 0.8433 - val_accuracy: 0.6741\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4043 - accuracy: 0.8191 - val_loss: 0.8433 - val_accuracy: 0.6741\n",
            "Epoch 978/1000\n",
            "Epoch 978/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4055 - accuracy: 0.8175 - val_loss: 0.8513 - val_accuracy: 0.6694\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4055 - accuracy: 0.8175 - val_loss: 0.8513 - val_accuracy: 0.6694\n",
            "Epoch 979/1000\n",
            "Epoch 979/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4067 - accuracy: 0.8189 - val_loss: 0.8546 - val_accuracy: 0.6734\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4067 - accuracy: 0.8189 - val_loss: 0.8546 - val_accuracy: 0.6734\n",
            "Epoch 980/1000\n",
            "Epoch 980/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4070 - accuracy: 0.8162 - val_loss: 0.8420 - val_accuracy: 0.6716\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4070 - accuracy: 0.8162 - val_loss: 0.8420 - val_accuracy: 0.6716\n",
            "Epoch 981/1000\n",
            "Epoch 981/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4057 - accuracy: 0.8160 - val_loss: 0.8388 - val_accuracy: 0.6692\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4057 - accuracy: 0.8160 - val_loss: 0.8388 - val_accuracy: 0.6692\n",
            "Epoch 982/1000\n",
            "Epoch 982/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4079 - accuracy: 0.8153 - val_loss: 0.8576 - val_accuracy: 0.6669\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4079 - accuracy: 0.8153 - val_loss: 0.8576 - val_accuracy: 0.6669\n",
            "Epoch 983/1000\n",
            "Epoch 983/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4095 - accuracy: 0.8143 - val_loss: 0.8642 - val_accuracy: 0.6679\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4095 - accuracy: 0.8143 - val_loss: 0.8642 - val_accuracy: 0.6679\n",
            "Epoch 984/1000\n",
            "Epoch 984/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4031 - accuracy: 0.8179 - val_loss: 0.8517 - val_accuracy: 0.6672\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4031 - accuracy: 0.8179 - val_loss: 0.8517 - val_accuracy: 0.6672\n",
            "Epoch 985/1000\n",
            "Epoch 985/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4041 - accuracy: 0.8186 - val_loss: 0.8621 - val_accuracy: 0.6699\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4041 - accuracy: 0.8186 - val_loss: 0.8621 - val_accuracy: 0.6699\n",
            "Epoch 986/1000\n",
            "Epoch 986/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4067 - accuracy: 0.8175 - val_loss: 0.8417 - val_accuracy: 0.6687\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4067 - accuracy: 0.8175 - val_loss: 0.8417 - val_accuracy: 0.6687\n",
            "Epoch 987/1000\n",
            "Epoch 987/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4047 - accuracy: 0.8158 - val_loss: 0.8499 - val_accuracy: 0.6739\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4047 - accuracy: 0.8158 - val_loss: 0.8499 - val_accuracy: 0.6739\n",
            "Epoch 988/1000\n",
            "Epoch 988/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4043 - accuracy: 0.8169 - val_loss: 0.8466 - val_accuracy: 0.6704\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4043 - accuracy: 0.8169 - val_loss: 0.8466 - val_accuracy: 0.6704\n",
            "Epoch 989/1000\n",
            "Epoch 989/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4050 - accuracy: 0.8173 - val_loss: 0.8394 - val_accuracy: 0.6776\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4050 - accuracy: 0.8173 - val_loss: 0.8394 - val_accuracy: 0.6776\n",
            "Epoch 990/1000\n",
            "Epoch 990/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4073 - accuracy: 0.8154 - val_loss: 0.8569 - val_accuracy: 0.6679\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4073 - accuracy: 0.8154 - val_loss: 0.8569 - val_accuracy: 0.6679\n",
            "Epoch 991/1000\n",
            "Epoch 991/1000\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4037 - accuracy: 0.8175 - val_loss: 0.8463 - val_accuracy: 0.6714\n",
            "161/161 [==============================] - 8s 52ms/step - loss: 0.4037 - accuracy: 0.8175 - val_loss: 0.8463 - val_accuracy: 0.6714\n",
            "Epoch 992/1000\n",
            "Epoch 992/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4085 - accuracy: 0.8143 - val_loss: 0.8555 - val_accuracy: 0.6714\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4085 - accuracy: 0.8143 - val_loss: 0.8555 - val_accuracy: 0.6714\n",
            "Epoch 993/1000\n",
            "Epoch 993/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4039 - accuracy: 0.8188 - val_loss: 0.8544 - val_accuracy: 0.6687\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4039 - accuracy: 0.8188 - val_loss: 0.8544 - val_accuracy: 0.6687\n",
            "Epoch 994/1000\n",
            "Epoch 994/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4048 - accuracy: 0.8182 - val_loss: 0.8518 - val_accuracy: 0.6729\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4048 - accuracy: 0.8182 - val_loss: 0.8518 - val_accuracy: 0.6729\n",
            "Epoch 995/1000\n",
            "Epoch 995/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4047 - accuracy: 0.8165 - val_loss: 0.8484 - val_accuracy: 0.6711\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4047 - accuracy: 0.8165 - val_loss: 0.8484 - val_accuracy: 0.6711\n",
            "Epoch 996/1000\n",
            "Epoch 996/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4087 - accuracy: 0.8138 - val_loss: 0.8447 - val_accuracy: 0.6709\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4087 - accuracy: 0.8138 - val_loss: 0.8447 - val_accuracy: 0.6709\n",
            "Epoch 997/1000\n",
            "Epoch 997/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4068 - accuracy: 0.8153 - val_loss: 0.8642 - val_accuracy: 0.6699\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 0.4068 - accuracy: 0.8153 - val_loss: 0.8642 - val_accuracy: 0.6699\n",
            "Epoch 998/1000\n",
            "Epoch 998/1000\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4049 - accuracy: 0.8170 - val_loss: 0.8444 - val_accuracy: 0.6746\n",
            "161/161 [==============================] - 8s 53ms/step - loss: 0.4049 - accuracy: 0.8170 - val_loss: 0.8444 - val_accuracy: 0.6746\n",
            "Epoch 999/1000\n",
            "Epoch 999/1000\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4059 - accuracy: 0.8166 - val_loss: 0.8450 - val_accuracy: 0.6701\n",
            "161/161 [==============================] - 9s 53ms/step - loss: 0.4059 - accuracy: 0.8166 - val_loss: 0.8450 - val_accuracy: 0.6701\n",
            "Epoch 1000/1000\n",
            "Epoch 1000/1000\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4064 - accuracy: 0.8155 - val_loss: 0.8656 - val_accuracy: 0.6729\n",
            "161/161 [==============================] - 9s 58ms/step - loss: 0.4064 - accuracy: 0.8155 - val_loss: 0.8656 - val_accuracy: 0.6729\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f65001fb1c0>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f65001fb1c0>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train,Y_train, batch_size=100, epochs=1000, validation_data=(X_test,Y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSaKEH9KUz5N",
        "outputId": "2fce5778-1279-4ee0-e23c-9930d2512a72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 - 2s - loss: 0.8656 - accuracy: 0.6729 - 2s/epoch - 20ms/step\n",
            "126/126 - 2s - loss: 0.8656 - accuracy: 0.6729 - 2s/epoch - 20ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.8655543327331543, 0.6728855967521667]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "[0.8655543327331543, 0.6728855967521667]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(X_test,Y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wsLO-f9U2jI"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/Adience_Gender/VGGFace_Adience_Data_Aug_Gender_Recognition.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzsROBuLaf2E"
      },
      "source": [
        "# SVM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ikrPfh7V6Z-",
        "outputId": "e8534922-b77c-4fda-f6d1-48bfacd81fae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keract\n",
            "  Downloading keract-4.5.1-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: keract\n",
            "Successfully installed keract-4.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install keract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "031CNBtVV_S2"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "model=keras.models.load_model('/content/drive/MyDrive/Adience_Gender/VGGFace_Adience_Data_Aug_Gender_Recognition.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_dUtsi9WDbc",
        "outputId": "62a91c2e-8fbf-48f1-d8f5-58aed43d952a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " conv1_1 (Conv2D)            (None, 64, 64, 64)        1792      \n",
            "                                                                 \n",
            " conv1_2 (Conv2D)            (None, 64, 64, 64)        36928     \n",
            "                                                                 \n",
            " pool1 (MaxPooling2D)        (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2_1 (Conv2D)            (None, 32, 32, 128)       73856     \n",
            "                                                                 \n",
            " conv2_2 (Conv2D)            (None, 32, 32, 128)       147584    \n",
            "                                                                 \n",
            " pool2 (MaxPooling2D)        (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv3_1 (Conv2D)            (None, 16, 16, 256)       295168    \n",
            "                                                                 \n",
            " conv3_2 (Conv2D)            (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " conv3_3 (Conv2D)            (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " pool3 (MaxPooling2D)        (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " conv4_1 (Conv2D)            (None, 8, 8, 512)         1180160   \n",
            "                                                                 \n",
            " conv4_2 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " conv4_3 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " pool4 (MaxPooling2D)        (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " conv5_1 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " conv5_2 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " conv5_3 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " pool5 (MaxPooling2D)        (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 2049      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,716,737\n",
            "Trainable params: 2,049\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keract import get_activations\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3d5sos_mWHDC"
      },
      "outputs": [],
      "source": [
        "activations1 = get_activations(model,X_train[:1000],layer_names='flatten')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvN7_kEYWNX-"
      },
      "outputs": [],
      "source": [
        "activations2 = get_activations(model,X_train[1000:2000],layer_names='flatten')\n",
        "activations3 = get_activations(model,X_train[2000:3000],layer_names='flatten')\n",
        "activations4 = get_activations(model,X_train[3000:4000],layer_names='flatten')\n",
        "activations5 = get_activations(model,X_train[4000:5000],layer_names='flatten')\n",
        "activations6 = get_activations(model,X_train[5000:6000],layer_names='flatten')\n",
        "activations7 = get_activations(model,X_train[6000:7000],layer_names='flatten')\n",
        "activations8 = get_activations(model,X_train[7000:8000],layer_names='flatten')\n",
        "activations9 = get_activations(model,X_train[8000:9000],layer_names='flatten')\n",
        "activations10 = get_activations(model,X_train[9000:10000],layer_names='flatten')\n",
        "activations11= get_activations(model,X_train[10000:11000],layer_names='flatten')\n",
        "activations12= get_activations(model,X_train[11000:12000],layer_names='flatten')\n",
        "activations13= get_activations(model,X_train[12000:13000],layer_names='flatten')\n",
        "activations14= get_activations(model,X_train[13000:14000],layer_names='flatten')\n",
        "activations15= get_activations(model,X_train[14000:],layer_names='flatten')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJe6Nr1jWR8b"
      },
      "outputs": [],
      "source": [
        "X_train1= activations1\n",
        "X_train1= X_train1[\"flatten\"]\n",
        "X_train2= activations2\n",
        "X_train2= X_train2[\"flatten\"]\n",
        "X_train3= activations3\n",
        "X_train3= X_train3[\"flatten\"]\n",
        "X_train4= activations4\n",
        "X_train4= X_train4[\"flatten\"]\n",
        "X_train5= activations5\n",
        "X_train5= X_train5[\"flatten\"]\n",
        "X_train6= activations6\n",
        "X_train6= X_train6[\"flatten\"]\n",
        "X_train7= activations7\n",
        "X_train7= X_train7[\"flatten\"]\n",
        "X_train8= activations8\n",
        "X_train8= X_train8[\"flatten\"]\n",
        "X_train9= activations9\n",
        "X_train9= X_train9[\"flatten\"]\n",
        "X_train10= activations10\n",
        "X_train10= X_train10[\"flatten\"]\n",
        "X_train11= activations11\n",
        "X_train11= X_train11[\"flatten\"]\n",
        "X_train12= activations12\n",
        "X_train12= X_train12[\"flatten\"]\n",
        "X_train13= activations13\n",
        "X_train13= X_train13[\"flatten\"]\n",
        "X_train14= activations14\n",
        "X_train14= X_train14[\"flatten\"]\n",
        "X_train15= activations15\n",
        "X_train15= X_train15[\"flatten\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwaXqRjZWVpY"
      },
      "outputs": [],
      "source": [
        "X_train =np.concatenate((X_train1,X_train2,X_train3,X_train4,X_train5,X_train6,X_train7,X_train8,X_train9,X_train10,X_train11,X_train12,X_train13,X_train14,X_train15), axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAZ2ZEyUWvhx"
      },
      "outputs": [],
      "source": [
        "activations17 = get_activations(model,X_test[:1000],layer_names='flatten')\n",
        "activations18 = get_activations(model,X_test[1000:2000],layer_names='flatten')\n",
        "activations19 = get_activations(model,X_test[2000:3000],layer_names='flatten')\n",
        "activations20 = get_activations(model,X_test[3000:],layer_names='flatten')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YCt3sxNWzSI"
      },
      "outputs": [],
      "source": [
        "X_test1= activations17\n",
        "X_test1= X_test1['flatten']\n",
        "X_test2= activations18\n",
        "X_test2= X_test2['flatten']\n",
        "X_test3= activations19\n",
        "X_test3= X_test3['flatten']\n",
        "X_test4= activations20\n",
        "X_test4= X_test4['flatten']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WH_SFAICW4Dp"
      },
      "outputs": [],
      "source": [
        "X_test =np.concatenate((X_test1,X_test2,X_test3,X_test4), axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQBC5QKCW7fk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3R6pJSOXAmC"
      },
      "outputs": [],
      "source": [
        "model1 = SVC(kernel='rbf',probability=True, C=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vs7uByXO4u0q"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import Normalizer\n",
        "normalizer = Normalizer()\n",
        "X_train= normalizer.transform(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ShRaQKdCXE0-",
        "outputId": "c34849d9-f93c-4f02-aacf-90efbf693b40"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=100, probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=100, probability=True)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "SVC(C=100, probability=True)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tM68Mo_iXHdq"
      },
      "outputs": [],
      "source": [
        "predictions1 = model1.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6tRuPRnuYDii"
      },
      "outputs": [],
      "source": [
        "predictions2 = model1.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2xGgfZ9SYJRg"
      },
      "outputs": [],
      "source": [
        "percentage = model1.score(X_test,Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NeyvdutVYS3b",
        "outputId": "b457773b-2bdc-41cd-d9e9-d8e037c44c4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: train=16076, test=4020\n",
            "Accuracy: train=99.994, test=50.149\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Dataset: train=%d, test=%d\" % (X_train.shape[0], Y_test.shape[0]))\n",
        "score_train = accuracy_score(Y_train, predictions1)\n",
        "score_test = accuracy_score(Y_test, predictions2)\n",
        "\n",
        "print('Accuracy: train=%.3f, test=%.3f' % (score_train*100, score_test*100))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_ka-_sNXYarm",
        "outputId": "f2132e37-afda-4784-b552-96951dc46a2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[   0 2004]\n",
            "[   0 2016]\n",
            "Confusion Matrix\n",
            "[[   0 2004]\n",
            " [   0 2016]]\n",
            "Test Set: 4020\n",
            "Accuracy = 50.14925373134328 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      2004\n",
            "           1       0.50      1.00      0.67      2016\n",
            "\n",
            "    accuracy                           0.50      4020\n",
            "   macro avg       0.25      0.50      0.33      4020\n",
            "weighted avg       0.25      0.50      0.33      4020\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "res = confusion_matrix(Y_test, predictions2)\n",
        "for i in range(0,len(res)):\n",
        "  print(res[i])\n",
        "print(\"Confusion Matrix\")\n",
        "print(res)\n",
        "print(f\"Test Set: {len(X_test)}\")\n",
        "print(f\"Accuracy = {score_test*100} %\")\n",
        "print(classification_report(Y_test, predictions2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8-kQHPJsFrk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}