{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0G21QGBHU1W",
        "outputId": "2474759a-71b7-49e8-bbbe-98a2d9ba384c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4hZ1yZN_3Nd"
      },
      "outputs": [],
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dossier=os.listdir(\"/content/drive/MyDrive/PFE_Oumaima/Adience/Adience_Data_Aug1/Femme\")\n",
        "Femme=np.zeros((len(dossier),64,64,3))\n",
        "Labels_F=[]\n",
        "for i in range(len(dossier)):\n",
        "  nom_image='/content/drive/MyDrive/PFE_Oumaima/Adience/Adience_Data_Aug1/Femme/'+dossier[i]\n",
        "  image = cv2.resize((cv2.imread(nom_image)), (64,64))\n",
        "  Femme[i]=image\n",
        "  Labels_F.append(0)"
      ],
      "metadata": {
        "id": "fvX42iRIFf4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dossier1=os.listdir(\"/content/drive/MyDrive/PFE_Oumaima/Adience/Adience_Data_Aug1/Homme\")\n",
        "Homme=np.zeros((len(dossier1),64,64,3))\n",
        "Labels_H=[]\n",
        "for i in range(len(dossier1)):\n",
        "  nom_image='/content/drive/MyDrive/PFE_Oumaima/Adience/Adience_Data_Aug1/Homme/'+dossier1[i]\n",
        "  image = cv2.resize((cv2.imread(nom_image)), (64,64))\n",
        "  Homme[i]=image\n",
        "  Labels_H.append(1)"
      ],
      "metadata": {
        "id": "PbTM0fcnFhyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train (x):\n",
        "  return int(x*0.8)"
      ],
      "metadata": {
        "id": "76rDYDBjFj-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_train_Homme=Homme[:train(len(Homme))]\n",
        "images_test_Homme=Homme[train(len(Homme)):]\n",
        "labels_train_Homme=Labels_H[:train(len(Labels_H))]\n",
        "labels_test_Homme=Labels_H[train(len(Labels_H)):]\n",
        "\n",
        "images_train_Femme=Femme[:train(len(Femme))]\n",
        "images_test_Femme=Femme[train(len(Femme)):]\n",
        "labels_train_Femme=Labels_F[:train(len(Labels_F))]\n",
        "labels_test_Femme=Labels_F[train(len(Labels_F)):]"
      ],
      "metadata": {
        "id": "L2jYktAzFl1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=np.concatenate((images_train_Homme,images_train_Femme),axis=0)\n",
        "Y_train=np.concatenate((labels_train_Homme,labels_train_Femme),axis=0)\n",
        "X_test=np.concatenate((images_test_Homme,images_test_Femme),axis=0)\n",
        "Y_test=np.concatenate((labels_test_Homme,labels_test_Femme),axis=0)"
      ],
      "metadata": {
        "id": "xiidCEIwFnr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train))\n",
        "print(len(Y_train))\n",
        "print(len(X_test))\n",
        "print(len(Y_test))"
      ],
      "metadata": {
        "id": "yMWqX-c6FpaS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cb22e17-18ba-4cfa-ec68-ef4356126782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16002\n",
            "16002\n",
            "4002\n",
            "4002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the libraries\n",
        "from keras.models import Model\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.applications import vgg19\n",
        "from keras.layers import Dropout,Dense,Conv2D,GlobalAveragePooling2D\n",
        "#from keras.preprocessing import image\n",
        "\n",
        "num_classes=1\n",
        "IMAGE_SIZE = [64,64]  \n",
        "\n",
        "# loading the weights of VGG16 without the top layer. These weights are trained on Imagenet dataset.\n",
        "vgg19 = vgg19.VGG19(input_shape = IMAGE_SIZE + [3],weights='imagenet',include_top=False)\n",
        "\n",
        "# this will exclude the initial layers from training phase as there are already been trained.\n",
        "for layer in vgg19.layers:\n",
        "    layer.trainable = False\n",
        "x = Flatten()(vgg19.output)\n",
        "#x2= Dense(1024, activation = 'relu')(x) # adding the output layer with softmax function as this is a multi label classification problem.\n",
        "#x1= Dense(512, activation = 'relu')(x)   # we can add a new fully connected layer but it will increase the execution time.\n",
        "output_layer = Dense(num_classes, activation = 'sigmoid')(x)  # adding the output layer with softmax function as this is a multi label classification problem.\n",
        "\n",
        "model = Model(inputs = vgg19.input, outputs = output_layer)"
      ],
      "metadata": {
        "id": "Z8umxhP4GOot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9efe22c8-0625-4fad-ed84-71cb023830b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "csqaP0RCFroT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0895524-9d9e-432d-9f02-8b1cf6367c61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 64, 64, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 64, 64, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 32, 32, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 32, 32, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 16, 16, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 8, 8, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 2049      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,026,433\n",
            "Trainable params: 2,049\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ysRjPFnNFtvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "X_test = np.array(X_test)\n",
        "Y_test = np.array(Y_test)\n"
      ],
      "metadata": {
        "id": "eBvGllbHFvil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,Y_train, batch_size=100, epochs=1000, validation_data=(X_test,Y_test))"
      ],
      "metadata": {
        "id": "_hkHtBxuFxTi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "902e328f-7ca1-458d-e9bb-b930e3d8a57b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "161/161 [==============================] - 21s 68ms/step - loss: 4.5894 - accuracy: 0.6133 - val_loss: 3.4953 - val_accuracy: 0.6484\n",
            "Epoch 2/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 2.9005 - accuracy: 0.6717 - val_loss: 2.5844 - val_accuracy: 0.6789\n",
            "Epoch 3/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 2.3290 - accuracy: 0.6941 - val_loss: 2.1048 - val_accuracy: 0.6979\n",
            "Epoch 4/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 2.0038 - accuracy: 0.7024 - val_loss: 1.8944 - val_accuracy: 0.7041\n",
            "Epoch 5/1000\n",
            "161/161 [==============================] - 9s 59ms/step - loss: 1.7798 - accuracy: 0.7128 - val_loss: 1.7229 - val_accuracy: 0.7134\n",
            "Epoch 6/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 1.6112 - accuracy: 0.7237 - val_loss: 1.7267 - val_accuracy: 0.7074\n",
            "Epoch 7/1000\n",
            "161/161 [==============================] - 10s 61ms/step - loss: 1.4705 - accuracy: 0.7318 - val_loss: 1.5521 - val_accuracy: 0.7196\n",
            "Epoch 8/1000\n",
            "161/161 [==============================] - 10s 62ms/step - loss: 1.3585 - accuracy: 0.7367 - val_loss: 1.5216 - val_accuracy: 0.7106\n",
            "Epoch 9/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 1.2616 - accuracy: 0.7400 - val_loss: 1.4489 - val_accuracy: 0.7099\n",
            "Epoch 10/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 1.1752 - accuracy: 0.7455 - val_loss: 1.4115 - val_accuracy: 0.7114\n",
            "Epoch 11/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 1.0998 - accuracy: 0.7493 - val_loss: 1.3546 - val_accuracy: 0.7099\n",
            "Epoch 12/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 1.0334 - accuracy: 0.7520 - val_loss: 1.2532 - val_accuracy: 0.7196\n",
            "Epoch 13/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.9744 - accuracy: 0.7577 - val_loss: 1.2418 - val_accuracy: 0.7181\n",
            "Epoch 14/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.9287 - accuracy: 0.7611 - val_loss: 1.1879 - val_accuracy: 0.7199\n",
            "Epoch 15/1000\n",
            "161/161 [==============================] - 10s 62ms/step - loss: 0.8733 - accuracy: 0.7655 - val_loss: 1.1286 - val_accuracy: 0.7224\n",
            "Epoch 16/1000\n",
            "161/161 [==============================] - 10s 62ms/step - loss: 0.8386 - accuracy: 0.7678 - val_loss: 1.1294 - val_accuracy: 0.7194\n",
            "Epoch 17/1000\n",
            "161/161 [==============================] - 10s 62ms/step - loss: 0.7952 - accuracy: 0.7738 - val_loss: 1.1294 - val_accuracy: 0.7129\n",
            "Epoch 18/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.7574 - accuracy: 0.7770 - val_loss: 1.0486 - val_accuracy: 0.7209\n",
            "Epoch 19/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.7560 - accuracy: 0.7747 - val_loss: 1.0468 - val_accuracy: 0.7189\n",
            "Epoch 20/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.6986 - accuracy: 0.7829 - val_loss: 1.0366 - val_accuracy: 0.7166\n",
            "Epoch 21/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.6737 - accuracy: 0.7867 - val_loss: 1.0170 - val_accuracy: 0.7139\n",
            "Epoch 22/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.6491 - accuracy: 0.7882 - val_loss: 1.0718 - val_accuracy: 0.7026\n",
            "Epoch 23/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.6413 - accuracy: 0.7896 - val_loss: 0.9897 - val_accuracy: 0.7106\n",
            "Epoch 24/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.6087 - accuracy: 0.7952 - val_loss: 0.9838 - val_accuracy: 0.7091\n",
            "Epoch 25/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.5892 - accuracy: 0.7966 - val_loss: 0.9521 - val_accuracy: 0.7146\n",
            "Epoch 26/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.5767 - accuracy: 0.7953 - val_loss: 0.9200 - val_accuracy: 0.7196\n",
            "Epoch 27/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.5605 - accuracy: 0.7990 - val_loss: 0.9671 - val_accuracy: 0.7029\n",
            "Epoch 28/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.5430 - accuracy: 0.8026 - val_loss: 0.9021 - val_accuracy: 0.7151\n",
            "Epoch 29/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.5311 - accuracy: 0.8025 - val_loss: 0.9295 - val_accuracy: 0.7064\n",
            "Epoch 30/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.5155 - accuracy: 0.8077 - val_loss: 0.8912 - val_accuracy: 0.7071\n",
            "Epoch 31/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.5086 - accuracy: 0.8064 - val_loss: 0.9266 - val_accuracy: 0.6962\n",
            "Epoch 32/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.4947 - accuracy: 0.8099 - val_loss: 0.9163 - val_accuracy: 0.6964\n",
            "Epoch 33/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.4850 - accuracy: 0.8132 - val_loss: 0.8696 - val_accuracy: 0.7074\n",
            "Epoch 34/1000\n",
            "161/161 [==============================] - 10s 62ms/step - loss: 0.4772 - accuracy: 0.8139 - val_loss: 0.9025 - val_accuracy: 0.6964\n",
            "Epoch 35/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.4723 - accuracy: 0.8140 - val_loss: 0.8882 - val_accuracy: 0.7034\n",
            "Epoch 36/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.4649 - accuracy: 0.8160 - val_loss: 0.8288 - val_accuracy: 0.7119\n",
            "Epoch 37/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.4518 - accuracy: 0.8169 - val_loss: 0.8140 - val_accuracy: 0.7141\n",
            "Epoch 38/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.4452 - accuracy: 0.8220 - val_loss: 0.8140 - val_accuracy: 0.7129\n",
            "Epoch 39/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.4399 - accuracy: 0.8221 - val_loss: 0.8759 - val_accuracy: 0.6929\n",
            "Epoch 40/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.4484 - accuracy: 0.8183 - val_loss: 0.7961 - val_accuracy: 0.7171\n",
            "Epoch 41/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.4279 - accuracy: 0.8260 - val_loss: 0.8600 - val_accuracy: 0.6939\n",
            "Epoch 42/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.4235 - accuracy: 0.8260 - val_loss: 0.8262 - val_accuracy: 0.7034\n",
            "Epoch 43/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.4162 - accuracy: 0.8297 - val_loss: 0.8068 - val_accuracy: 0.7081\n",
            "Epoch 44/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.4125 - accuracy: 0.8295 - val_loss: 0.7511 - val_accuracy: 0.7221\n",
            "Epoch 45/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.4104 - accuracy: 0.8296 - val_loss: 0.7997 - val_accuracy: 0.7104\n",
            "Epoch 46/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.4057 - accuracy: 0.8297 - val_loss: 0.8122 - val_accuracy: 0.7076\n",
            "Epoch 47/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.4055 - accuracy: 0.8320 - val_loss: 0.7616 - val_accuracy: 0.7199\n",
            "Epoch 48/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.4027 - accuracy: 0.8302 - val_loss: 0.7616 - val_accuracy: 0.7144\n",
            "Epoch 49/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.4062 - accuracy: 0.8298 - val_loss: 0.7489 - val_accuracy: 0.7184\n",
            "Epoch 50/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3943 - accuracy: 0.8346 - val_loss: 0.7918 - val_accuracy: 0.7074\n",
            "Epoch 51/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3895 - accuracy: 0.8366 - val_loss: 0.8073 - val_accuracy: 0.7051\n",
            "Epoch 52/1000\n",
            "161/161 [==============================] - 10s 62ms/step - loss: 0.3942 - accuracy: 0.8318 - val_loss: 0.7450 - val_accuracy: 0.7219\n",
            "Epoch 53/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3883 - accuracy: 0.8353 - val_loss: 0.7734 - val_accuracy: 0.7079\n",
            "Epoch 54/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3838 - accuracy: 0.8376 - val_loss: 0.7586 - val_accuracy: 0.7134\n",
            "Epoch 55/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3817 - accuracy: 0.8375 - val_loss: 0.7434 - val_accuracy: 0.7149\n",
            "Epoch 56/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3811 - accuracy: 0.8363 - val_loss: 0.7500 - val_accuracy: 0.7111\n",
            "Epoch 57/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3846 - accuracy: 0.8356 - val_loss: 0.7500 - val_accuracy: 0.7151\n",
            "Epoch 58/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3760 - accuracy: 0.8411 - val_loss: 0.7465 - val_accuracy: 0.7101\n",
            "Epoch 59/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3744 - accuracy: 0.8409 - val_loss: 0.7887 - val_accuracy: 0.7024\n",
            "Epoch 60/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3758 - accuracy: 0.8411 - val_loss: 0.7642 - val_accuracy: 0.7064\n",
            "Epoch 61/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3726 - accuracy: 0.8405 - val_loss: 0.7270 - val_accuracy: 0.7154\n",
            "Epoch 62/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3718 - accuracy: 0.8426 - val_loss: 0.7336 - val_accuracy: 0.7164\n",
            "Epoch 63/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3695 - accuracy: 0.8430 - val_loss: 0.7510 - val_accuracy: 0.7069\n",
            "Epoch 64/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3794 - accuracy: 0.8386 - val_loss: 0.7405 - val_accuracy: 0.7189\n",
            "Epoch 65/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3655 - accuracy: 0.8458 - val_loss: 0.7140 - val_accuracy: 0.7191\n",
            "Epoch 66/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3662 - accuracy: 0.8423 - val_loss: 0.7140 - val_accuracy: 0.7224\n",
            "Epoch 67/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3665 - accuracy: 0.8426 - val_loss: 0.7581 - val_accuracy: 0.7084\n",
            "Epoch 68/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3657 - accuracy: 0.8436 - val_loss: 0.7446 - val_accuracy: 0.7111\n",
            "Epoch 69/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3617 - accuracy: 0.8451 - val_loss: 0.7371 - val_accuracy: 0.7129\n",
            "Epoch 70/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3635 - accuracy: 0.8452 - val_loss: 0.7621 - val_accuracy: 0.7024\n",
            "Epoch 71/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3593 - accuracy: 0.8458 - val_loss: 0.7454 - val_accuracy: 0.7064\n",
            "Epoch 72/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3628 - accuracy: 0.8460 - val_loss: 0.7881 - val_accuracy: 0.6932\n",
            "Epoch 73/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3587 - accuracy: 0.8476 - val_loss: 0.7419 - val_accuracy: 0.7139\n",
            "Epoch 74/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3661 - accuracy: 0.8420 - val_loss: 0.7255 - val_accuracy: 0.7109\n",
            "Epoch 75/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3575 - accuracy: 0.8461 - val_loss: 0.7590 - val_accuracy: 0.7021\n",
            "Epoch 76/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3563 - accuracy: 0.8475 - val_loss: 0.6954 - val_accuracy: 0.7206\n",
            "Epoch 77/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3581 - accuracy: 0.8467 - val_loss: 0.6943 - val_accuracy: 0.7241\n",
            "Epoch 78/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3606 - accuracy: 0.8427 - val_loss: 0.7003 - val_accuracy: 0.7194\n",
            "Epoch 79/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3554 - accuracy: 0.8480 - val_loss: 0.7169 - val_accuracy: 0.7146\n",
            "Epoch 80/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3542 - accuracy: 0.8467 - val_loss: 0.7418 - val_accuracy: 0.7041\n",
            "Epoch 81/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3516 - accuracy: 0.8505 - val_loss: 0.7133 - val_accuracy: 0.7164\n",
            "Epoch 82/1000\n",
            "161/161 [==============================] - 10s 62ms/step - loss: 0.3545 - accuracy: 0.8477 - val_loss: 0.7392 - val_accuracy: 0.7101\n",
            "Epoch 83/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3538 - accuracy: 0.8482 - val_loss: 0.7171 - val_accuracy: 0.7141\n",
            "Epoch 84/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3546 - accuracy: 0.8491 - val_loss: 0.7627 - val_accuracy: 0.7016\n",
            "Epoch 85/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3531 - accuracy: 0.8482 - val_loss: 0.7453 - val_accuracy: 0.6987\n",
            "Epoch 86/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3552 - accuracy: 0.8464 - val_loss: 0.7669 - val_accuracy: 0.6967\n",
            "Epoch 87/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3547 - accuracy: 0.8488 - val_loss: 0.7326 - val_accuracy: 0.7076\n",
            "Epoch 88/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3540 - accuracy: 0.8470 - val_loss: 0.7056 - val_accuracy: 0.7156\n",
            "Epoch 89/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3524 - accuracy: 0.8503 - val_loss: 0.6983 - val_accuracy: 0.7219\n",
            "Epoch 90/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3513 - accuracy: 0.8486 - val_loss: 0.7169 - val_accuracy: 0.7106\n",
            "Epoch 91/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3519 - accuracy: 0.8496 - val_loss: 0.7107 - val_accuracy: 0.7136\n",
            "Epoch 92/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3525 - accuracy: 0.8494 - val_loss: 0.7134 - val_accuracy: 0.7151\n",
            "Epoch 93/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3649 - accuracy: 0.8428 - val_loss: 0.7210 - val_accuracy: 0.7076\n",
            "Epoch 94/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3544 - accuracy: 0.8465 - val_loss: 0.7268 - val_accuracy: 0.7069\n",
            "Epoch 95/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3495 - accuracy: 0.8512 - val_loss: 0.7241 - val_accuracy: 0.7091\n",
            "Epoch 96/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3508 - accuracy: 0.8491 - val_loss: 0.7302 - val_accuracy: 0.7074\n",
            "Epoch 97/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3496 - accuracy: 0.8501 - val_loss: 0.7242 - val_accuracy: 0.7079\n",
            "Epoch 98/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3468 - accuracy: 0.8500 - val_loss: 0.7074 - val_accuracy: 0.7134\n",
            "Epoch 99/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3506 - accuracy: 0.8466 - val_loss: 0.7301 - val_accuracy: 0.7079\n",
            "Epoch 100/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3492 - accuracy: 0.8513 - val_loss: 0.7514 - val_accuracy: 0.7001\n",
            "Epoch 101/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3470 - accuracy: 0.8520 - val_loss: 0.7041 - val_accuracy: 0.7089\n",
            "Epoch 102/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3486 - accuracy: 0.8490 - val_loss: 0.7155 - val_accuracy: 0.7114\n",
            "Epoch 103/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3499 - accuracy: 0.8476 - val_loss: 0.7382 - val_accuracy: 0.7134\n",
            "Epoch 104/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3596 - accuracy: 0.8471 - val_loss: 0.6906 - val_accuracy: 0.7201\n",
            "Epoch 105/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3488 - accuracy: 0.8501 - val_loss: 0.7137 - val_accuracy: 0.7159\n",
            "Epoch 106/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3463 - accuracy: 0.8520 - val_loss: 0.7365 - val_accuracy: 0.7039\n",
            "Epoch 107/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3500 - accuracy: 0.8495 - val_loss: 0.7260 - val_accuracy: 0.7109\n",
            "Epoch 108/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3471 - accuracy: 0.8518 - val_loss: 0.7459 - val_accuracy: 0.7084\n",
            "Epoch 109/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3458 - accuracy: 0.8513 - val_loss: 0.7219 - val_accuracy: 0.7074\n",
            "Epoch 110/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3476 - accuracy: 0.8528 - val_loss: 0.7237 - val_accuracy: 0.7096\n",
            "Epoch 111/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3479 - accuracy: 0.8495 - val_loss: 0.7155 - val_accuracy: 0.7134\n",
            "Epoch 112/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3474 - accuracy: 0.8498 - val_loss: 0.7021 - val_accuracy: 0.7179\n",
            "Epoch 113/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3469 - accuracy: 0.8495 - val_loss: 0.7133 - val_accuracy: 0.7119\n",
            "Epoch 114/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3480 - accuracy: 0.8493 - val_loss: 0.7476 - val_accuracy: 0.7059\n",
            "Epoch 115/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3475 - accuracy: 0.8491 - val_loss: 0.7657 - val_accuracy: 0.6912\n",
            "Epoch 116/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3467 - accuracy: 0.8511 - val_loss: 0.7375 - val_accuracy: 0.7114\n",
            "Epoch 117/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3489 - accuracy: 0.8494 - val_loss: 0.7389 - val_accuracy: 0.7049\n",
            "Epoch 118/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3473 - accuracy: 0.8505 - val_loss: 0.7356 - val_accuracy: 0.7061\n",
            "Epoch 119/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3449 - accuracy: 0.8521 - val_loss: 0.7500 - val_accuracy: 0.7011\n",
            "Epoch 120/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3499 - accuracy: 0.8501 - val_loss: 0.7263 - val_accuracy: 0.7081\n",
            "Epoch 121/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3459 - accuracy: 0.8515 - val_loss: 0.7351 - val_accuracy: 0.7039\n",
            "Epoch 122/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3490 - accuracy: 0.8498 - val_loss: 0.7240 - val_accuracy: 0.7074\n",
            "Epoch 123/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3485 - accuracy: 0.8492 - val_loss: 0.7638 - val_accuracy: 0.7009\n",
            "Epoch 124/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3529 - accuracy: 0.8469 - val_loss: 0.7599 - val_accuracy: 0.7004\n",
            "Epoch 125/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3446 - accuracy: 0.8515 - val_loss: 0.7379 - val_accuracy: 0.7066\n",
            "Epoch 126/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3486 - accuracy: 0.8485 - val_loss: 0.7330 - val_accuracy: 0.7186\n",
            "Epoch 127/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3441 - accuracy: 0.8525 - val_loss: 0.7604 - val_accuracy: 0.7039\n",
            "Epoch 128/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3500 - accuracy: 0.8477 - val_loss: 0.7300 - val_accuracy: 0.7149\n",
            "Epoch 129/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3481 - accuracy: 0.8496 - val_loss: 0.7583 - val_accuracy: 0.7036\n",
            "Epoch 130/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3471 - accuracy: 0.8520 - val_loss: 0.7554 - val_accuracy: 0.6997\n",
            "Epoch 131/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3434 - accuracy: 0.8518 - val_loss: 0.7087 - val_accuracy: 0.7099\n",
            "Epoch 132/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3455 - accuracy: 0.8532 - val_loss: 0.6842 - val_accuracy: 0.7209\n",
            "Epoch 133/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3452 - accuracy: 0.8525 - val_loss: 0.7546 - val_accuracy: 0.7059\n",
            "Epoch 134/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3429 - accuracy: 0.8524 - val_loss: 0.7168 - val_accuracy: 0.7114\n",
            "Epoch 135/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3435 - accuracy: 0.8529 - val_loss: 0.7357 - val_accuracy: 0.7041\n",
            "Epoch 136/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3437 - accuracy: 0.8520 - val_loss: 0.7148 - val_accuracy: 0.7161\n",
            "Epoch 137/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3487 - accuracy: 0.8494 - val_loss: 0.7001 - val_accuracy: 0.7176\n",
            "Epoch 138/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3440 - accuracy: 0.8534 - val_loss: 0.7394 - val_accuracy: 0.7039\n",
            "Epoch 139/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3444 - accuracy: 0.8503 - val_loss: 0.7599 - val_accuracy: 0.7021\n",
            "Epoch 140/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3520 - accuracy: 0.8480 - val_loss: 0.6995 - val_accuracy: 0.7206\n",
            "Epoch 141/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3422 - accuracy: 0.8543 - val_loss: 0.7361 - val_accuracy: 0.7081\n",
            "Epoch 142/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3459 - accuracy: 0.8506 - val_loss: 0.7109 - val_accuracy: 0.7116\n",
            "Epoch 143/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3437 - accuracy: 0.8525 - val_loss: 0.7052 - val_accuracy: 0.7206\n",
            "Epoch 144/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3432 - accuracy: 0.8513 - val_loss: 0.7531 - val_accuracy: 0.7036\n",
            "Epoch 145/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3453 - accuracy: 0.8505 - val_loss: 0.7179 - val_accuracy: 0.7186\n",
            "Epoch 146/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3437 - accuracy: 0.8520 - val_loss: 0.7653 - val_accuracy: 0.6994\n",
            "Epoch 147/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3469 - accuracy: 0.8496 - val_loss: 0.7517 - val_accuracy: 0.7116\n",
            "Epoch 148/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3423 - accuracy: 0.8528 - val_loss: 0.7283 - val_accuracy: 0.7121\n",
            "Epoch 149/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3452 - accuracy: 0.8515 - val_loss: 0.7279 - val_accuracy: 0.7044\n",
            "Epoch 150/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3431 - accuracy: 0.8516 - val_loss: 0.7501 - val_accuracy: 0.7071\n",
            "Epoch 151/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3428 - accuracy: 0.8530 - val_loss: 0.7204 - val_accuracy: 0.7106\n",
            "Epoch 152/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3430 - accuracy: 0.8508 - val_loss: 0.7258 - val_accuracy: 0.7039\n",
            "Epoch 153/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3427 - accuracy: 0.8522 - val_loss: 0.6937 - val_accuracy: 0.7241\n",
            "Epoch 154/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3427 - accuracy: 0.8504 - val_loss: 0.7292 - val_accuracy: 0.7094\n",
            "Epoch 155/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3443 - accuracy: 0.8513 - val_loss: 0.7480 - val_accuracy: 0.7076\n",
            "Epoch 156/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3447 - accuracy: 0.8514 - val_loss: 0.7213 - val_accuracy: 0.7151\n",
            "Epoch 157/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3420 - accuracy: 0.8540 - val_loss: 0.7211 - val_accuracy: 0.7146\n",
            "Epoch 158/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3436 - accuracy: 0.8508 - val_loss: 0.7292 - val_accuracy: 0.7124\n",
            "Epoch 159/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3446 - accuracy: 0.8500 - val_loss: 0.7594 - val_accuracy: 0.7031\n",
            "Epoch 160/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3451 - accuracy: 0.8535 - val_loss: 0.7543 - val_accuracy: 0.7029\n",
            "Epoch 161/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3470 - accuracy: 0.8510 - val_loss: 0.6958 - val_accuracy: 0.7204\n",
            "Epoch 162/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3490 - accuracy: 0.8513 - val_loss: 0.7530 - val_accuracy: 0.6999\n",
            "Epoch 163/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3427 - accuracy: 0.8520 - val_loss: 0.7328 - val_accuracy: 0.7124\n",
            "Epoch 164/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3409 - accuracy: 0.8536 - val_loss: 0.7344 - val_accuracy: 0.7026\n",
            "Epoch 165/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3478 - accuracy: 0.8487 - val_loss: 0.7393 - val_accuracy: 0.7061\n",
            "Epoch 166/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3421 - accuracy: 0.8528 - val_loss: 0.6877 - val_accuracy: 0.7269\n",
            "Epoch 167/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3429 - accuracy: 0.8536 - val_loss: 0.7573 - val_accuracy: 0.7016\n",
            "Epoch 168/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3427 - accuracy: 0.8521 - val_loss: 0.7660 - val_accuracy: 0.7001\n",
            "Epoch 169/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3452 - accuracy: 0.8524 - val_loss: 0.6812 - val_accuracy: 0.7256\n",
            "Epoch 170/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3448 - accuracy: 0.8512 - val_loss: 0.7417 - val_accuracy: 0.7114\n",
            "Epoch 171/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3504 - accuracy: 0.8492 - val_loss: 0.7391 - val_accuracy: 0.7136\n",
            "Epoch 172/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3507 - accuracy: 0.8472 - val_loss: 0.6744 - val_accuracy: 0.7284\n",
            "Epoch 173/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3415 - accuracy: 0.8536 - val_loss: 0.6820 - val_accuracy: 0.7284\n",
            "Epoch 174/1000\n",
            "161/161 [==============================] - 10s 62ms/step - loss: 0.3466 - accuracy: 0.8515 - val_loss: 0.7374 - val_accuracy: 0.7134\n",
            "Epoch 175/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3424 - accuracy: 0.8536 - val_loss: 0.7195 - val_accuracy: 0.7181\n",
            "Epoch 176/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3483 - accuracy: 0.8506 - val_loss: 0.7120 - val_accuracy: 0.7211\n",
            "Epoch 177/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3439 - accuracy: 0.8523 - val_loss: 0.6916 - val_accuracy: 0.7274\n",
            "Epoch 178/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3484 - accuracy: 0.8501 - val_loss: 0.7460 - val_accuracy: 0.7049\n",
            "Epoch 179/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3548 - accuracy: 0.8470 - val_loss: 0.7093 - val_accuracy: 0.7206\n",
            "Epoch 180/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3412 - accuracy: 0.8531 - val_loss: 0.7308 - val_accuracy: 0.7181\n",
            "Epoch 181/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3468 - accuracy: 0.8499 - val_loss: 0.7451 - val_accuracy: 0.7059\n",
            "Epoch 182/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3425 - accuracy: 0.8541 - val_loss: 0.7262 - val_accuracy: 0.7126\n",
            "Epoch 183/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3429 - accuracy: 0.8527 - val_loss: 0.7209 - val_accuracy: 0.7111\n",
            "Epoch 184/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3450 - accuracy: 0.8511 - val_loss: 0.7177 - val_accuracy: 0.7181\n",
            "Epoch 185/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3402 - accuracy: 0.8534 - val_loss: 0.7234 - val_accuracy: 0.7134\n",
            "Epoch 186/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3407 - accuracy: 0.8548 - val_loss: 0.7282 - val_accuracy: 0.7091\n",
            "Epoch 187/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3455 - accuracy: 0.8492 - val_loss: 0.7037 - val_accuracy: 0.7169\n",
            "Epoch 188/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3409 - accuracy: 0.8539 - val_loss: 0.7125 - val_accuracy: 0.7176\n",
            "Epoch 189/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3517 - accuracy: 0.8488 - val_loss: 0.7084 - val_accuracy: 0.7191\n",
            "Epoch 190/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3414 - accuracy: 0.8550 - val_loss: 0.7361 - val_accuracy: 0.7086\n",
            "Epoch 191/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3426 - accuracy: 0.8525 - val_loss: 0.7223 - val_accuracy: 0.7146\n",
            "Epoch 192/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3439 - accuracy: 0.8514 - val_loss: 0.7088 - val_accuracy: 0.7166\n",
            "Epoch 193/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3426 - accuracy: 0.8538 - val_loss: 0.7454 - val_accuracy: 0.7036\n",
            "Epoch 194/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3453 - accuracy: 0.8513 - val_loss: 0.7366 - val_accuracy: 0.7064\n",
            "Epoch 195/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3426 - accuracy: 0.8515 - val_loss: 0.7496 - val_accuracy: 0.7074\n",
            "Epoch 196/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3433 - accuracy: 0.8506 - val_loss: 0.7065 - val_accuracy: 0.7166\n",
            "Epoch 197/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3512 - accuracy: 0.8469 - val_loss: 0.7772 - val_accuracy: 0.7016\n",
            "Epoch 198/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3480 - accuracy: 0.8465 - val_loss: 0.7326 - val_accuracy: 0.7151\n",
            "Epoch 199/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3418 - accuracy: 0.8530 - val_loss: 0.7378 - val_accuracy: 0.7076\n",
            "Epoch 200/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3413 - accuracy: 0.8524 - val_loss: 0.7525 - val_accuracy: 0.7104\n",
            "Epoch 201/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3412 - accuracy: 0.8545 - val_loss: 0.7266 - val_accuracy: 0.7111\n",
            "Epoch 202/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3412 - accuracy: 0.8543 - val_loss: 0.7173 - val_accuracy: 0.7171\n",
            "Epoch 203/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3465 - accuracy: 0.8484 - val_loss: 0.7419 - val_accuracy: 0.7071\n",
            "Epoch 204/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3444 - accuracy: 0.8516 - val_loss: 0.7318 - val_accuracy: 0.7089\n",
            "Epoch 205/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3419 - accuracy: 0.8534 - val_loss: 0.7266 - val_accuracy: 0.7139\n",
            "Epoch 206/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3425 - accuracy: 0.8539 - val_loss: 0.7240 - val_accuracy: 0.7139\n",
            "Epoch 207/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3421 - accuracy: 0.8519 - val_loss: 0.7161 - val_accuracy: 0.7169\n",
            "Epoch 208/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3438 - accuracy: 0.8518 - val_loss: 0.7192 - val_accuracy: 0.7149\n",
            "Epoch 209/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3413 - accuracy: 0.8543 - val_loss: 0.7268 - val_accuracy: 0.7191\n",
            "Epoch 210/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3409 - accuracy: 0.8545 - val_loss: 0.7038 - val_accuracy: 0.7204\n",
            "Epoch 211/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3416 - accuracy: 0.8520 - val_loss: 0.7407 - val_accuracy: 0.7111\n",
            "Epoch 212/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3426 - accuracy: 0.8519 - val_loss: 0.7137 - val_accuracy: 0.7214\n",
            "Epoch 213/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3455 - accuracy: 0.8497 - val_loss: 0.6666 - val_accuracy: 0.7364\n",
            "Epoch 214/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3473 - accuracy: 0.8503 - val_loss: 0.7268 - val_accuracy: 0.7189\n",
            "Epoch 215/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3416 - accuracy: 0.8546 - val_loss: 0.7644 - val_accuracy: 0.7021\n",
            "Epoch 216/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3412 - accuracy: 0.8533 - val_loss: 0.7350 - val_accuracy: 0.7149\n",
            "Epoch 217/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3439 - accuracy: 0.8512 - val_loss: 0.7464 - val_accuracy: 0.7089\n",
            "Epoch 218/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3480 - accuracy: 0.8513 - val_loss: 0.7188 - val_accuracy: 0.7124\n",
            "Epoch 219/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3423 - accuracy: 0.8530 - val_loss: 0.6926 - val_accuracy: 0.7256\n",
            "Epoch 220/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3432 - accuracy: 0.8510 - val_loss: 0.7484 - val_accuracy: 0.7131\n",
            "Epoch 221/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3427 - accuracy: 0.8529 - val_loss: 0.7392 - val_accuracy: 0.7039\n",
            "Epoch 222/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3436 - accuracy: 0.8506 - val_loss: 0.7018 - val_accuracy: 0.7224\n",
            "Epoch 223/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3416 - accuracy: 0.8545 - val_loss: 0.7006 - val_accuracy: 0.7221\n",
            "Epoch 224/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3436 - accuracy: 0.8494 - val_loss: 0.7291 - val_accuracy: 0.7121\n",
            "Epoch 225/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3441 - accuracy: 0.8515 - val_loss: 0.7352 - val_accuracy: 0.7161\n",
            "Epoch 226/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3439 - accuracy: 0.8498 - val_loss: 0.7236 - val_accuracy: 0.7154\n",
            "Epoch 227/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3441 - accuracy: 0.8525 - val_loss: 0.7672 - val_accuracy: 0.7069\n",
            "Epoch 228/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3468 - accuracy: 0.8521 - val_loss: 0.7188 - val_accuracy: 0.7124\n",
            "Epoch 229/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3411 - accuracy: 0.8540 - val_loss: 0.7768 - val_accuracy: 0.6994\n",
            "Epoch 230/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3416 - accuracy: 0.8528 - val_loss: 0.7785 - val_accuracy: 0.6972\n",
            "Epoch 231/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3443 - accuracy: 0.8501 - val_loss: 0.8203 - val_accuracy: 0.6927\n",
            "Epoch 232/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3492 - accuracy: 0.8490 - val_loss: 0.7223 - val_accuracy: 0.7104\n",
            "Epoch 233/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3454 - accuracy: 0.8512 - val_loss: 0.7381 - val_accuracy: 0.7116\n",
            "Epoch 234/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3418 - accuracy: 0.8530 - val_loss: 0.6995 - val_accuracy: 0.7241\n",
            "Epoch 235/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3428 - accuracy: 0.8505 - val_loss: 0.7239 - val_accuracy: 0.7216\n",
            "Epoch 236/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3460 - accuracy: 0.8485 - val_loss: 0.7434 - val_accuracy: 0.7171\n",
            "Epoch 237/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3404 - accuracy: 0.8527 - val_loss: 0.7184 - val_accuracy: 0.7176\n",
            "Epoch 238/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3424 - accuracy: 0.8526 - val_loss: 0.7310 - val_accuracy: 0.7111\n",
            "Epoch 239/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3410 - accuracy: 0.8545 - val_loss: 0.7272 - val_accuracy: 0.7164\n",
            "Epoch 240/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3530 - accuracy: 0.8476 - val_loss: 0.7352 - val_accuracy: 0.7039\n",
            "Epoch 241/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3463 - accuracy: 0.8506 - val_loss: 0.7276 - val_accuracy: 0.7131\n",
            "Epoch 242/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3428 - accuracy: 0.8508 - val_loss: 0.7123 - val_accuracy: 0.7169\n",
            "Epoch 243/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3402 - accuracy: 0.8558 - val_loss: 0.7343 - val_accuracy: 0.7086\n",
            "Epoch 244/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3401 - accuracy: 0.8555 - val_loss: 0.7263 - val_accuracy: 0.7071\n",
            "Epoch 245/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3409 - accuracy: 0.8501 - val_loss: 0.6922 - val_accuracy: 0.7246\n",
            "Epoch 246/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3455 - accuracy: 0.8501 - val_loss: 0.7015 - val_accuracy: 0.7251\n",
            "Epoch 247/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3433 - accuracy: 0.8532 - val_loss: 0.7355 - val_accuracy: 0.7139\n",
            "Epoch 248/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3412 - accuracy: 0.8526 - val_loss: 0.6795 - val_accuracy: 0.7251\n",
            "Epoch 249/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3409 - accuracy: 0.8528 - val_loss: 0.7655 - val_accuracy: 0.7016\n",
            "Epoch 250/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3426 - accuracy: 0.8525 - val_loss: 0.7053 - val_accuracy: 0.7216\n",
            "Epoch 251/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3492 - accuracy: 0.8504 - val_loss: 0.7140 - val_accuracy: 0.7199\n",
            "Epoch 252/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3419 - accuracy: 0.8555 - val_loss: 0.7330 - val_accuracy: 0.7099\n",
            "Epoch 253/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3425 - accuracy: 0.8520 - val_loss: 0.7425 - val_accuracy: 0.7116\n",
            "Epoch 254/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3530 - accuracy: 0.8483 - val_loss: 0.7340 - val_accuracy: 0.7156\n",
            "Epoch 255/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3455 - accuracy: 0.8509 - val_loss: 0.7310 - val_accuracy: 0.7144\n",
            "Epoch 256/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3448 - accuracy: 0.8504 - val_loss: 0.7558 - val_accuracy: 0.7099\n",
            "Epoch 257/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3430 - accuracy: 0.8516 - val_loss: 0.7179 - val_accuracy: 0.7159\n",
            "Epoch 258/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3437 - accuracy: 0.8515 - val_loss: 0.7762 - val_accuracy: 0.6964\n",
            "Epoch 259/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3433 - accuracy: 0.8533 - val_loss: 0.7367 - val_accuracy: 0.7131\n",
            "Epoch 260/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3461 - accuracy: 0.8506 - val_loss: 0.7440 - val_accuracy: 0.7061\n",
            "Epoch 261/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3402 - accuracy: 0.8553 - val_loss: 0.7528 - val_accuracy: 0.7149\n",
            "Epoch 262/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3428 - accuracy: 0.8533 - val_loss: 0.7710 - val_accuracy: 0.7049\n",
            "Epoch 263/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3426 - accuracy: 0.8553 - val_loss: 0.7457 - val_accuracy: 0.7064\n",
            "Epoch 264/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3441 - accuracy: 0.8516 - val_loss: 0.7187 - val_accuracy: 0.7164\n",
            "Epoch 265/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3421 - accuracy: 0.8510 - val_loss: 0.7345 - val_accuracy: 0.7154\n",
            "Epoch 266/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3440 - accuracy: 0.8513 - val_loss: 0.7339 - val_accuracy: 0.7136\n",
            "Epoch 267/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3421 - accuracy: 0.8543 - val_loss: 0.7330 - val_accuracy: 0.7109\n",
            "Epoch 268/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3438 - accuracy: 0.8516 - val_loss: 0.7346 - val_accuracy: 0.7151\n",
            "Epoch 269/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3499 - accuracy: 0.8483 - val_loss: 0.7466 - val_accuracy: 0.7059\n",
            "Epoch 270/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3434 - accuracy: 0.8521 - val_loss: 0.7852 - val_accuracy: 0.7091\n",
            "Epoch 271/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3571 - accuracy: 0.8460 - val_loss: 0.7432 - val_accuracy: 0.7081\n",
            "Epoch 272/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3534 - accuracy: 0.8463 - val_loss: 0.7383 - val_accuracy: 0.7106\n",
            "Epoch 273/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3425 - accuracy: 0.8541 - val_loss: 0.7158 - val_accuracy: 0.7176\n",
            "Epoch 274/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3399 - accuracy: 0.8541 - val_loss: 0.7073 - val_accuracy: 0.7239\n",
            "Epoch 275/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3406 - accuracy: 0.8533 - val_loss: 0.7747 - val_accuracy: 0.6999\n",
            "Epoch 276/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3456 - accuracy: 0.8515 - val_loss: 0.6961 - val_accuracy: 0.7296\n",
            "Epoch 277/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3426 - accuracy: 0.8547 - val_loss: 0.6811 - val_accuracy: 0.7284\n",
            "Epoch 278/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3405 - accuracy: 0.8536 - val_loss: 0.7165 - val_accuracy: 0.7161\n",
            "Epoch 279/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3427 - accuracy: 0.8515 - val_loss: 0.7413 - val_accuracy: 0.7084\n",
            "Epoch 280/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3529 - accuracy: 0.8462 - val_loss: 0.7446 - val_accuracy: 0.7084\n",
            "Epoch 281/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3425 - accuracy: 0.8529 - val_loss: 0.6855 - val_accuracy: 0.7229\n",
            "Epoch 282/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3425 - accuracy: 0.8525 - val_loss: 0.7675 - val_accuracy: 0.7036\n",
            "Epoch 283/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3435 - accuracy: 0.8526 - val_loss: 0.7414 - val_accuracy: 0.7124\n",
            "Epoch 284/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3386 - accuracy: 0.8545 - val_loss: 0.7335 - val_accuracy: 0.7124\n",
            "Epoch 285/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3404 - accuracy: 0.8535 - val_loss: 0.7641 - val_accuracy: 0.7004\n",
            "Epoch 286/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3445 - accuracy: 0.8515 - val_loss: 0.7402 - val_accuracy: 0.7156\n",
            "Epoch 287/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3498 - accuracy: 0.8490 - val_loss: 0.7307 - val_accuracy: 0.7146\n",
            "Epoch 288/1000\n",
            "161/161 [==============================] - 11s 69ms/step - loss: 0.3418 - accuracy: 0.8543 - val_loss: 0.7197 - val_accuracy: 0.7189\n",
            "Epoch 289/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3402 - accuracy: 0.8526 - val_loss: 0.7783 - val_accuracy: 0.6999\n",
            "Epoch 290/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3429 - accuracy: 0.8525 - val_loss: 0.7325 - val_accuracy: 0.7134\n",
            "Epoch 291/1000\n",
            "161/161 [==============================] - 11s 69ms/step - loss: 0.3424 - accuracy: 0.8530 - val_loss: 0.7208 - val_accuracy: 0.7191\n",
            "Epoch 292/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3421 - accuracy: 0.8506 - val_loss: 0.7007 - val_accuracy: 0.7231\n",
            "Epoch 293/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3453 - accuracy: 0.8521 - val_loss: 0.6977 - val_accuracy: 0.7261\n",
            "Epoch 294/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3449 - accuracy: 0.8516 - val_loss: 0.7433 - val_accuracy: 0.7061\n",
            "Epoch 295/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3399 - accuracy: 0.8558 - val_loss: 0.7646 - val_accuracy: 0.7086\n",
            "Epoch 296/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3478 - accuracy: 0.8529 - val_loss: 0.7407 - val_accuracy: 0.7054\n",
            "Epoch 297/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3461 - accuracy: 0.8529 - val_loss: 0.7279 - val_accuracy: 0.7141\n",
            "Epoch 298/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3479 - accuracy: 0.8492 - val_loss: 0.7689 - val_accuracy: 0.6982\n",
            "Epoch 299/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3447 - accuracy: 0.8508 - val_loss: 0.7490 - val_accuracy: 0.7101\n",
            "Epoch 300/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3421 - accuracy: 0.8533 - val_loss: 0.7384 - val_accuracy: 0.7089\n",
            "Epoch 301/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3408 - accuracy: 0.8550 - val_loss: 0.7111 - val_accuracy: 0.7176\n",
            "Epoch 302/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3448 - accuracy: 0.8530 - val_loss: 0.7535 - val_accuracy: 0.7071\n",
            "Epoch 303/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3454 - accuracy: 0.8506 - val_loss: 0.7710 - val_accuracy: 0.7006\n",
            "Epoch 304/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3473 - accuracy: 0.8506 - val_loss: 0.7002 - val_accuracy: 0.7261\n",
            "Epoch 305/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3404 - accuracy: 0.8525 - val_loss: 0.7772 - val_accuracy: 0.7036\n",
            "Epoch 306/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3424 - accuracy: 0.8513 - val_loss: 0.7480 - val_accuracy: 0.7046\n",
            "Epoch 307/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3408 - accuracy: 0.8536 - val_loss: 0.7331 - val_accuracy: 0.7141\n",
            "Epoch 308/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3483 - accuracy: 0.8488 - val_loss: 0.7535 - val_accuracy: 0.7079\n",
            "Epoch 309/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3439 - accuracy: 0.8528 - val_loss: 0.7318 - val_accuracy: 0.7091\n",
            "Epoch 310/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3417 - accuracy: 0.8524 - val_loss: 0.7941 - val_accuracy: 0.7009\n",
            "Epoch 311/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3455 - accuracy: 0.8504 - val_loss: 0.7714 - val_accuracy: 0.7026\n",
            "Epoch 312/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3445 - accuracy: 0.8506 - val_loss: 0.7658 - val_accuracy: 0.7016\n",
            "Epoch 313/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3409 - accuracy: 0.8526 - val_loss: 0.7663 - val_accuracy: 0.7021\n",
            "Epoch 314/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3405 - accuracy: 0.8535 - val_loss: 0.7653 - val_accuracy: 0.7061\n",
            "Epoch 315/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3418 - accuracy: 0.8516 - val_loss: 0.7206 - val_accuracy: 0.7151\n",
            "Epoch 316/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3420 - accuracy: 0.8523 - val_loss: 0.7345 - val_accuracy: 0.7114\n",
            "Epoch 317/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3469 - accuracy: 0.8521 - val_loss: 0.7301 - val_accuracy: 0.7114\n",
            "Epoch 318/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3423 - accuracy: 0.8534 - val_loss: 0.7363 - val_accuracy: 0.7114\n",
            "Epoch 319/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3415 - accuracy: 0.8512 - val_loss: 0.7260 - val_accuracy: 0.7166\n",
            "Epoch 320/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3452 - accuracy: 0.8511 - val_loss: 0.7227 - val_accuracy: 0.7184\n",
            "Epoch 321/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3443 - accuracy: 0.8509 - val_loss: 0.7921 - val_accuracy: 0.6979\n",
            "Epoch 322/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3448 - accuracy: 0.8520 - val_loss: 0.7627 - val_accuracy: 0.7009\n",
            "Epoch 323/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3469 - accuracy: 0.8500 - val_loss: 0.7279 - val_accuracy: 0.7119\n",
            "Epoch 324/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3412 - accuracy: 0.8521 - val_loss: 0.7273 - val_accuracy: 0.7184\n",
            "Epoch 325/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3437 - accuracy: 0.8525 - val_loss: 0.6930 - val_accuracy: 0.7234\n",
            "Epoch 326/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3391 - accuracy: 0.8530 - val_loss: 0.7393 - val_accuracy: 0.7119\n",
            "Epoch 327/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3396 - accuracy: 0.8556 - val_loss: 0.7244 - val_accuracy: 0.7154\n",
            "Epoch 328/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3452 - accuracy: 0.8502 - val_loss: 0.7590 - val_accuracy: 0.7136\n",
            "Epoch 329/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3469 - accuracy: 0.8498 - val_loss: 0.7272 - val_accuracy: 0.7159\n",
            "Epoch 330/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3428 - accuracy: 0.8523 - val_loss: 0.7110 - val_accuracy: 0.7216\n",
            "Epoch 331/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3403 - accuracy: 0.8538 - val_loss: 0.7471 - val_accuracy: 0.7056\n",
            "Epoch 332/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3497 - accuracy: 0.8496 - val_loss: 0.7434 - val_accuracy: 0.7106\n",
            "Epoch 333/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3449 - accuracy: 0.8509 - val_loss: 0.6934 - val_accuracy: 0.7256\n",
            "Epoch 334/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3421 - accuracy: 0.8530 - val_loss: 0.7408 - val_accuracy: 0.7154\n",
            "Epoch 335/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3398 - accuracy: 0.8531 - val_loss: 0.7430 - val_accuracy: 0.7129\n",
            "Epoch 336/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3513 - accuracy: 0.8491 - val_loss: 0.7258 - val_accuracy: 0.7164\n",
            "Epoch 337/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3399 - accuracy: 0.8540 - val_loss: 0.7437 - val_accuracy: 0.7139\n",
            "Epoch 338/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3504 - accuracy: 0.8450 - val_loss: 0.7246 - val_accuracy: 0.7209\n",
            "Epoch 339/1000\n",
            "161/161 [==============================] - 11s 69ms/step - loss: 0.3404 - accuracy: 0.8526 - val_loss: 0.7587 - val_accuracy: 0.7074\n",
            "Epoch 340/1000\n",
            "161/161 [==============================] - 11s 69ms/step - loss: 0.3407 - accuracy: 0.8523 - val_loss: 0.7081 - val_accuracy: 0.7239\n",
            "Epoch 341/1000\n",
            "161/161 [==============================] - 11s 69ms/step - loss: 0.3418 - accuracy: 0.8529 - val_loss: 0.7542 - val_accuracy: 0.7119\n",
            "Epoch 342/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3472 - accuracy: 0.8508 - val_loss: 0.7540 - val_accuracy: 0.7104\n",
            "Epoch 343/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3434 - accuracy: 0.8531 - val_loss: 0.7476 - val_accuracy: 0.7081\n",
            "Epoch 344/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3403 - accuracy: 0.8530 - val_loss: 0.7527 - val_accuracy: 0.7074\n",
            "Epoch 345/1000\n",
            "161/161 [==============================] - 11s 69ms/step - loss: 0.3425 - accuracy: 0.8536 - val_loss: 0.7319 - val_accuracy: 0.7084\n",
            "Epoch 346/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3392 - accuracy: 0.8554 - val_loss: 0.7001 - val_accuracy: 0.7246\n",
            "Epoch 347/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3415 - accuracy: 0.8531 - val_loss: 0.7025 - val_accuracy: 0.7209\n",
            "Epoch 348/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3449 - accuracy: 0.8543 - val_loss: 0.7932 - val_accuracy: 0.6937\n",
            "Epoch 349/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3501 - accuracy: 0.8493 - val_loss: 0.7829 - val_accuracy: 0.7004\n",
            "Epoch 350/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3395 - accuracy: 0.8551 - val_loss: 0.7614 - val_accuracy: 0.7001\n",
            "Epoch 351/1000\n",
            "161/161 [==============================] - 11s 69ms/step - loss: 0.3412 - accuracy: 0.8533 - val_loss: 0.7533 - val_accuracy: 0.7079\n",
            "Epoch 352/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3411 - accuracy: 0.8533 - val_loss: 0.7828 - val_accuracy: 0.7046\n",
            "Epoch 353/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3462 - accuracy: 0.8498 - val_loss: 0.7283 - val_accuracy: 0.7149\n",
            "Epoch 354/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3415 - accuracy: 0.8528 - val_loss: 0.7417 - val_accuracy: 0.7139\n",
            "Epoch 355/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3410 - accuracy: 0.8537 - val_loss: 0.7877 - val_accuracy: 0.6979\n",
            "Epoch 356/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3427 - accuracy: 0.8512 - val_loss: 0.7167 - val_accuracy: 0.7134\n",
            "Epoch 357/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3409 - accuracy: 0.8551 - val_loss: 0.7695 - val_accuracy: 0.7029\n",
            "Epoch 358/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3453 - accuracy: 0.8513 - val_loss: 0.7151 - val_accuracy: 0.7189\n",
            "Epoch 359/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3406 - accuracy: 0.8540 - val_loss: 0.7376 - val_accuracy: 0.7159\n",
            "Epoch 360/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3473 - accuracy: 0.8519 - val_loss: 0.7749 - val_accuracy: 0.7064\n",
            "Epoch 361/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3425 - accuracy: 0.8507 - val_loss: 0.7289 - val_accuracy: 0.7196\n",
            "Epoch 362/1000\n",
            "161/161 [==============================] - 11s 69ms/step - loss: 0.3404 - accuracy: 0.8551 - val_loss: 0.7229 - val_accuracy: 0.7164\n",
            "Epoch 363/1000\n",
            "161/161 [==============================] - 11s 65ms/step - loss: 0.3417 - accuracy: 0.8523 - val_loss: 0.7362 - val_accuracy: 0.7086\n",
            "Epoch 364/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3470 - accuracy: 0.8516 - val_loss: 0.7659 - val_accuracy: 0.7066\n",
            "Epoch 365/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3505 - accuracy: 0.8465 - val_loss: 0.7320 - val_accuracy: 0.7149\n",
            "Epoch 366/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3430 - accuracy: 0.8531 - val_loss: 0.7636 - val_accuracy: 0.7049\n",
            "Epoch 367/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3532 - accuracy: 0.8470 - val_loss: 0.7165 - val_accuracy: 0.7249\n",
            "Epoch 368/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3423 - accuracy: 0.8525 - val_loss: 0.7242 - val_accuracy: 0.7189\n",
            "Epoch 369/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3435 - accuracy: 0.8510 - val_loss: 0.7035 - val_accuracy: 0.7224\n",
            "Epoch 370/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3388 - accuracy: 0.8528 - val_loss: 0.7702 - val_accuracy: 0.7024\n",
            "Epoch 371/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3413 - accuracy: 0.8516 - val_loss: 0.7310 - val_accuracy: 0.7134\n",
            "Epoch 372/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3422 - accuracy: 0.8529 - val_loss: 0.7614 - val_accuracy: 0.7014\n",
            "Epoch 373/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3412 - accuracy: 0.8530 - val_loss: 0.7433 - val_accuracy: 0.7146\n",
            "Epoch 374/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3438 - accuracy: 0.8503 - val_loss: 0.7371 - val_accuracy: 0.7104\n",
            "Epoch 375/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3400 - accuracy: 0.8548 - val_loss: 0.7319 - val_accuracy: 0.7174\n",
            "Epoch 376/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3400 - accuracy: 0.8533 - val_loss: 0.7825 - val_accuracy: 0.6987\n",
            "Epoch 377/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3436 - accuracy: 0.8543 - val_loss: 0.7695 - val_accuracy: 0.7014\n",
            "Epoch 378/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3457 - accuracy: 0.8505 - val_loss: 0.6741 - val_accuracy: 0.7329\n",
            "Epoch 379/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3409 - accuracy: 0.8516 - val_loss: 0.7162 - val_accuracy: 0.7196\n",
            "Epoch 380/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3464 - accuracy: 0.8480 - val_loss: 0.7189 - val_accuracy: 0.7164\n",
            "Epoch 381/1000\n",
            "161/161 [==============================] - 11s 69ms/step - loss: 0.3467 - accuracy: 0.8486 - val_loss: 0.7870 - val_accuracy: 0.6954\n",
            "Epoch 382/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3475 - accuracy: 0.8502 - val_loss: 0.7266 - val_accuracy: 0.7174\n",
            "Epoch 383/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3406 - accuracy: 0.8531 - val_loss: 0.7898 - val_accuracy: 0.6992\n",
            "Epoch 384/1000\n",
            "161/161 [==============================] - 11s 69ms/step - loss: 0.3426 - accuracy: 0.8502 - val_loss: 0.7243 - val_accuracy: 0.7186\n",
            "Epoch 385/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3416 - accuracy: 0.8525 - val_loss: 0.7982 - val_accuracy: 0.6899\n",
            "Epoch 386/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3440 - accuracy: 0.8510 - val_loss: 0.7405 - val_accuracy: 0.7121\n",
            "Epoch 387/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3399 - accuracy: 0.8551 - val_loss: 0.7113 - val_accuracy: 0.7201\n",
            "Epoch 388/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3406 - accuracy: 0.8536 - val_loss: 0.7715 - val_accuracy: 0.6989\n",
            "Epoch 389/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3409 - accuracy: 0.8535 - val_loss: 0.7330 - val_accuracy: 0.7131\n",
            "Epoch 390/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3453 - accuracy: 0.8508 - val_loss: 0.6743 - val_accuracy: 0.7366\n",
            "Epoch 391/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3412 - accuracy: 0.8539 - val_loss: 0.7406 - val_accuracy: 0.7134\n",
            "Epoch 392/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3416 - accuracy: 0.8541 - val_loss: 0.7381 - val_accuracy: 0.7139\n",
            "Epoch 393/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3408 - accuracy: 0.8540 - val_loss: 0.7639 - val_accuracy: 0.7069\n",
            "Epoch 394/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3440 - accuracy: 0.8524 - val_loss: 0.7253 - val_accuracy: 0.7179\n",
            "Epoch 395/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3409 - accuracy: 0.8527 - val_loss: 0.7422 - val_accuracy: 0.7139\n",
            "Epoch 396/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3438 - accuracy: 0.8518 - val_loss: 0.6946 - val_accuracy: 0.7309\n",
            "Epoch 397/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3496 - accuracy: 0.8478 - val_loss: 0.7406 - val_accuracy: 0.7114\n",
            "Epoch 398/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3424 - accuracy: 0.8531 - val_loss: 0.7811 - val_accuracy: 0.6979\n",
            "Epoch 399/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3423 - accuracy: 0.8540 - val_loss: 0.7563 - val_accuracy: 0.7069\n",
            "Epoch 400/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3418 - accuracy: 0.8515 - val_loss: 0.7394 - val_accuracy: 0.7104\n",
            "Epoch 401/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3413 - accuracy: 0.8544 - val_loss: 0.7624 - val_accuracy: 0.7034\n",
            "Epoch 402/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3447 - accuracy: 0.8512 - val_loss: 0.7576 - val_accuracy: 0.7046\n",
            "Epoch 403/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3436 - accuracy: 0.8502 - val_loss: 0.7391 - val_accuracy: 0.7109\n",
            "Epoch 404/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3465 - accuracy: 0.8515 - val_loss: 0.7115 - val_accuracy: 0.7236\n",
            "Epoch 405/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3417 - accuracy: 0.8534 - val_loss: 0.7330 - val_accuracy: 0.7131\n",
            "Epoch 406/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3409 - accuracy: 0.8529 - val_loss: 0.7507 - val_accuracy: 0.7139\n",
            "Epoch 407/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3434 - accuracy: 0.8514 - val_loss: 0.7299 - val_accuracy: 0.7189\n",
            "Epoch 408/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3463 - accuracy: 0.8517 - val_loss: 0.7713 - val_accuracy: 0.7076\n",
            "Epoch 409/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3486 - accuracy: 0.8495 - val_loss: 0.7550 - val_accuracy: 0.7059\n",
            "Epoch 410/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3428 - accuracy: 0.8508 - val_loss: 0.7382 - val_accuracy: 0.7151\n",
            "Epoch 411/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3429 - accuracy: 0.8525 - val_loss: 0.7807 - val_accuracy: 0.6982\n",
            "Epoch 412/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3428 - accuracy: 0.8528 - val_loss: 0.7506 - val_accuracy: 0.7066\n",
            "Epoch 413/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3421 - accuracy: 0.8508 - val_loss: 0.7594 - val_accuracy: 0.7149\n",
            "Epoch 414/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3503 - accuracy: 0.8480 - val_loss: 0.7642 - val_accuracy: 0.7051\n",
            "Epoch 415/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3424 - accuracy: 0.8521 - val_loss: 0.7410 - val_accuracy: 0.7144\n",
            "Epoch 416/1000\n",
            "161/161 [==============================] - 11s 65ms/step - loss: 0.3400 - accuracy: 0.8537 - val_loss: 0.7441 - val_accuracy: 0.7099\n",
            "Epoch 417/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3423 - accuracy: 0.8529 - val_loss: 0.7524 - val_accuracy: 0.7081\n",
            "Epoch 418/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3407 - accuracy: 0.8516 - val_loss: 0.7191 - val_accuracy: 0.7159\n",
            "Epoch 419/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3406 - accuracy: 0.8541 - val_loss: 0.7248 - val_accuracy: 0.7141\n",
            "Epoch 420/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3435 - accuracy: 0.8530 - val_loss: 0.7274 - val_accuracy: 0.7151\n",
            "Epoch 421/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3436 - accuracy: 0.8527 - val_loss: 0.7850 - val_accuracy: 0.7014\n",
            "Epoch 422/1000\n",
            "161/161 [==============================] - 11s 69ms/step - loss: 0.3464 - accuracy: 0.8500 - val_loss: 0.7192 - val_accuracy: 0.7189\n",
            "Epoch 423/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3443 - accuracy: 0.8501 - val_loss: 0.7666 - val_accuracy: 0.7031\n",
            "Epoch 424/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3421 - accuracy: 0.8525 - val_loss: 0.7332 - val_accuracy: 0.7141\n",
            "Epoch 425/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3447 - accuracy: 0.8517 - val_loss: 0.7781 - val_accuracy: 0.7021\n",
            "Epoch 426/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3419 - accuracy: 0.8517 - val_loss: 0.7367 - val_accuracy: 0.7181\n",
            "Epoch 427/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3403 - accuracy: 0.8534 - val_loss: 0.7497 - val_accuracy: 0.7094\n",
            "Epoch 428/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3438 - accuracy: 0.8508 - val_loss: 0.8015 - val_accuracy: 0.6902\n",
            "Epoch 429/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3429 - accuracy: 0.8536 - val_loss: 0.7487 - val_accuracy: 0.7086\n",
            "Epoch 430/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3448 - accuracy: 0.8513 - val_loss: 0.7339 - val_accuracy: 0.7181\n",
            "Epoch 431/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3431 - accuracy: 0.8499 - val_loss: 0.7215 - val_accuracy: 0.7214\n",
            "Epoch 432/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3415 - accuracy: 0.8539 - val_loss: 0.7688 - val_accuracy: 0.7021\n",
            "Epoch 433/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3423 - accuracy: 0.8523 - val_loss: 0.7685 - val_accuracy: 0.7016\n",
            "Epoch 434/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3414 - accuracy: 0.8530 - val_loss: 0.7287 - val_accuracy: 0.7179\n",
            "Epoch 435/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3419 - accuracy: 0.8521 - val_loss: 0.7603 - val_accuracy: 0.7104\n",
            "Epoch 436/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3432 - accuracy: 0.8534 - val_loss: 0.7304 - val_accuracy: 0.7139\n",
            "Epoch 437/1000\n",
            "161/161 [==============================] - 11s 69ms/step - loss: 0.3438 - accuracy: 0.8531 - val_loss: 0.7834 - val_accuracy: 0.6979\n",
            "Epoch 438/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3416 - accuracy: 0.8503 - val_loss: 0.7102 - val_accuracy: 0.7201\n",
            "Epoch 439/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3421 - accuracy: 0.8511 - val_loss: 0.8136 - val_accuracy: 0.6944\n",
            "Epoch 440/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3522 - accuracy: 0.8486 - val_loss: 0.7433 - val_accuracy: 0.7161\n",
            "Epoch 441/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3418 - accuracy: 0.8515 - val_loss: 0.7296 - val_accuracy: 0.7204\n",
            "Epoch 442/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3447 - accuracy: 0.8528 - val_loss: 0.7441 - val_accuracy: 0.7129\n",
            "Epoch 443/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3525 - accuracy: 0.8435 - val_loss: 0.7392 - val_accuracy: 0.7141\n",
            "Epoch 444/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3420 - accuracy: 0.8514 - val_loss: 0.7783 - val_accuracy: 0.6989\n",
            "Epoch 445/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3430 - accuracy: 0.8536 - val_loss: 0.7583 - val_accuracy: 0.7074\n",
            "Epoch 446/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3406 - accuracy: 0.8498 - val_loss: 0.7504 - val_accuracy: 0.7106\n",
            "Epoch 447/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3431 - accuracy: 0.8538 - val_loss: 0.7170 - val_accuracy: 0.7181\n",
            "Epoch 448/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3406 - accuracy: 0.8526 - val_loss: 0.7469 - val_accuracy: 0.7114\n",
            "Epoch 449/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3397 - accuracy: 0.8531 - val_loss: 0.7422 - val_accuracy: 0.7071\n",
            "Epoch 450/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3436 - accuracy: 0.8510 - val_loss: 0.7398 - val_accuracy: 0.7081\n",
            "Epoch 451/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3431 - accuracy: 0.8511 - val_loss: 0.7390 - val_accuracy: 0.7136\n",
            "Epoch 452/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3404 - accuracy: 0.8523 - val_loss: 0.7953 - val_accuracy: 0.6947\n",
            "Epoch 453/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3408 - accuracy: 0.8546 - val_loss: 0.7775 - val_accuracy: 0.7011\n",
            "Epoch 454/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3406 - accuracy: 0.8521 - val_loss: 0.7368 - val_accuracy: 0.7121\n",
            "Epoch 455/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3440 - accuracy: 0.8513 - val_loss: 0.7271 - val_accuracy: 0.7126\n",
            "Epoch 456/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3452 - accuracy: 0.8497 - val_loss: 0.7935 - val_accuracy: 0.6967\n",
            "Epoch 457/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3425 - accuracy: 0.8511 - val_loss: 0.7478 - val_accuracy: 0.7136\n",
            "Epoch 458/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3499 - accuracy: 0.8483 - val_loss: 0.7097 - val_accuracy: 0.7219\n",
            "Epoch 459/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3410 - accuracy: 0.8540 - val_loss: 0.7287 - val_accuracy: 0.7174\n",
            "Epoch 460/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3413 - accuracy: 0.8515 - val_loss: 0.7032 - val_accuracy: 0.7296\n",
            "Epoch 461/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3420 - accuracy: 0.8510 - val_loss: 0.7855 - val_accuracy: 0.7029\n",
            "Epoch 462/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3426 - accuracy: 0.8514 - val_loss: 0.7485 - val_accuracy: 0.7131\n",
            "Epoch 463/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3419 - accuracy: 0.8530 - val_loss: 0.7099 - val_accuracy: 0.7239\n",
            "Epoch 464/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3407 - accuracy: 0.8539 - val_loss: 0.7795 - val_accuracy: 0.7049\n",
            "Epoch 465/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3413 - accuracy: 0.8510 - val_loss: 0.7164 - val_accuracy: 0.7221\n",
            "Epoch 466/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3437 - accuracy: 0.8518 - val_loss: 0.7363 - val_accuracy: 0.7136\n",
            "Epoch 467/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3493 - accuracy: 0.8495 - val_loss: 0.7862 - val_accuracy: 0.7019\n",
            "Epoch 468/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3453 - accuracy: 0.8516 - val_loss: 0.7413 - val_accuracy: 0.7141\n",
            "Epoch 469/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3402 - accuracy: 0.8540 - val_loss: 0.7690 - val_accuracy: 0.7049\n",
            "Epoch 470/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3402 - accuracy: 0.8549 - val_loss: 0.7701 - val_accuracy: 0.7064\n",
            "Epoch 471/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3427 - accuracy: 0.8523 - val_loss: 0.7321 - val_accuracy: 0.7169\n",
            "Epoch 472/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3398 - accuracy: 0.8536 - val_loss: 0.6885 - val_accuracy: 0.7279\n",
            "Epoch 473/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3455 - accuracy: 0.8508 - val_loss: 0.7345 - val_accuracy: 0.7164\n",
            "Epoch 474/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3462 - accuracy: 0.8502 - val_loss: 0.7466 - val_accuracy: 0.7144\n",
            "Epoch 475/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3464 - accuracy: 0.8480 - val_loss: 0.7815 - val_accuracy: 0.7011\n",
            "Epoch 476/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3426 - accuracy: 0.8523 - val_loss: 0.7521 - val_accuracy: 0.7141\n",
            "Epoch 477/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3415 - accuracy: 0.8550 - val_loss: 0.7403 - val_accuracy: 0.7144\n",
            "Epoch 478/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3428 - accuracy: 0.8521 - val_loss: 0.7161 - val_accuracy: 0.7219\n",
            "Epoch 479/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3420 - accuracy: 0.8536 - val_loss: 0.7768 - val_accuracy: 0.6994\n",
            "Epoch 480/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3490 - accuracy: 0.8485 - val_loss: 0.7414 - val_accuracy: 0.7181\n",
            "Epoch 481/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3412 - accuracy: 0.8524 - val_loss: 0.7366 - val_accuracy: 0.7091\n",
            "Epoch 482/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3401 - accuracy: 0.8558 - val_loss: 0.7379 - val_accuracy: 0.7126\n",
            "Epoch 483/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3445 - accuracy: 0.8508 - val_loss: 0.7711 - val_accuracy: 0.7061\n",
            "Epoch 484/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3452 - accuracy: 0.8505 - val_loss: 0.7090 - val_accuracy: 0.7269\n",
            "Epoch 485/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3411 - accuracy: 0.8525 - val_loss: 0.7805 - val_accuracy: 0.6997\n",
            "Epoch 486/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3402 - accuracy: 0.8545 - val_loss: 0.7325 - val_accuracy: 0.7149\n",
            "Epoch 487/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3493 - accuracy: 0.8476 - val_loss: 0.7843 - val_accuracy: 0.7041\n",
            "Epoch 488/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3430 - accuracy: 0.8552 - val_loss: 0.7658 - val_accuracy: 0.7031\n",
            "Epoch 489/1000\n",
            "161/161 [==============================] - 11s 69ms/step - loss: 0.3416 - accuracy: 0.8539 - val_loss: 0.7252 - val_accuracy: 0.7196\n",
            "Epoch 490/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3420 - accuracy: 0.8523 - val_loss: 0.7879 - val_accuracy: 0.6999\n",
            "Epoch 491/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3417 - accuracy: 0.8537 - val_loss: 0.7142 - val_accuracy: 0.7211\n",
            "Epoch 492/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3455 - accuracy: 0.8506 - val_loss: 0.7582 - val_accuracy: 0.7119\n",
            "Epoch 493/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3480 - accuracy: 0.8496 - val_loss: 0.8274 - val_accuracy: 0.6932\n",
            "Epoch 494/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3547 - accuracy: 0.8470 - val_loss: 0.7464 - val_accuracy: 0.7094\n",
            "Epoch 495/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3408 - accuracy: 0.8540 - val_loss: 0.7088 - val_accuracy: 0.7214\n",
            "Epoch 496/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3409 - accuracy: 0.8537 - val_loss: 0.7023 - val_accuracy: 0.7276\n",
            "Epoch 497/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3408 - accuracy: 0.8565 - val_loss: 0.7411 - val_accuracy: 0.7104\n",
            "Epoch 498/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3405 - accuracy: 0.8526 - val_loss: 0.7224 - val_accuracy: 0.7196\n",
            "Epoch 499/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3417 - accuracy: 0.8560 - val_loss: 0.7626 - val_accuracy: 0.7049\n",
            "Epoch 500/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3412 - accuracy: 0.8536 - val_loss: 0.7284 - val_accuracy: 0.7149\n",
            "Epoch 501/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3411 - accuracy: 0.8543 - val_loss: 0.7195 - val_accuracy: 0.7169\n",
            "Epoch 502/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3414 - accuracy: 0.8530 - val_loss: 0.7530 - val_accuracy: 0.7059\n",
            "Epoch 503/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3427 - accuracy: 0.8516 - val_loss: 0.7464 - val_accuracy: 0.7139\n",
            "Epoch 504/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3471 - accuracy: 0.8485 - val_loss: 0.7804 - val_accuracy: 0.7044\n",
            "Epoch 505/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3427 - accuracy: 0.8526 - val_loss: 0.6797 - val_accuracy: 0.7306\n",
            "Epoch 506/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3420 - accuracy: 0.8532 - val_loss: 0.7523 - val_accuracy: 0.7081\n",
            "Epoch 507/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3452 - accuracy: 0.8516 - val_loss: 0.7482 - val_accuracy: 0.7111\n",
            "Epoch 508/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3432 - accuracy: 0.8519 - val_loss: 0.7352 - val_accuracy: 0.7126\n",
            "Epoch 509/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3401 - accuracy: 0.8546 - val_loss: 0.7451 - val_accuracy: 0.7136\n",
            "Epoch 510/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3418 - accuracy: 0.8528 - val_loss: 0.7350 - val_accuracy: 0.7159\n",
            "Epoch 511/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3403 - accuracy: 0.8550 - val_loss: 0.7237 - val_accuracy: 0.7179\n",
            "Epoch 512/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3429 - accuracy: 0.8505 - val_loss: 0.7437 - val_accuracy: 0.7129\n",
            "Epoch 513/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3452 - accuracy: 0.8520 - val_loss: 0.7173 - val_accuracy: 0.7229\n",
            "Epoch 514/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3532 - accuracy: 0.8470 - val_loss: 0.7633 - val_accuracy: 0.7089\n",
            "Epoch 515/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3422 - accuracy: 0.8530 - val_loss: 0.7490 - val_accuracy: 0.7109\n",
            "Epoch 516/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3438 - accuracy: 0.8521 - val_loss: 0.7583 - val_accuracy: 0.7064\n",
            "Epoch 517/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3455 - accuracy: 0.8526 - val_loss: 0.7277 - val_accuracy: 0.7154\n",
            "Epoch 518/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3414 - accuracy: 0.8535 - val_loss: 0.7678 - val_accuracy: 0.7026\n",
            "Epoch 519/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3416 - accuracy: 0.8521 - val_loss: 0.7605 - val_accuracy: 0.7041\n",
            "Epoch 520/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3514 - accuracy: 0.8487 - val_loss: 0.7573 - val_accuracy: 0.7099\n",
            "Epoch 521/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3448 - accuracy: 0.8522 - val_loss: 0.7258 - val_accuracy: 0.7176\n",
            "Epoch 522/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3411 - accuracy: 0.8540 - val_loss: 0.7381 - val_accuracy: 0.7151\n",
            "Epoch 523/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3421 - accuracy: 0.8523 - val_loss: 0.7128 - val_accuracy: 0.7269\n",
            "Epoch 524/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3419 - accuracy: 0.8546 - val_loss: 0.7482 - val_accuracy: 0.7101\n",
            "Epoch 525/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3444 - accuracy: 0.8498 - val_loss: 0.7571 - val_accuracy: 0.7084\n",
            "Epoch 526/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3403 - accuracy: 0.8565 - val_loss: 0.7526 - val_accuracy: 0.7144\n",
            "Epoch 527/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3437 - accuracy: 0.8503 - val_loss: 0.7901 - val_accuracy: 0.6994\n",
            "Epoch 528/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3448 - accuracy: 0.8521 - val_loss: 0.7164 - val_accuracy: 0.7239\n",
            "Epoch 529/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3414 - accuracy: 0.8523 - val_loss: 0.7383 - val_accuracy: 0.7174\n",
            "Epoch 530/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3417 - accuracy: 0.8520 - val_loss: 0.7292 - val_accuracy: 0.7154\n",
            "Epoch 531/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3450 - accuracy: 0.8528 - val_loss: 0.7517 - val_accuracy: 0.7101\n",
            "Epoch 532/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3399 - accuracy: 0.8541 - val_loss: 0.7823 - val_accuracy: 0.7084\n",
            "Epoch 533/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3577 - accuracy: 0.8419 - val_loss: 0.7517 - val_accuracy: 0.7061\n",
            "Epoch 534/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3398 - accuracy: 0.8538 - val_loss: 0.7625 - val_accuracy: 0.7051\n",
            "Epoch 535/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3428 - accuracy: 0.8516 - val_loss: 0.7435 - val_accuracy: 0.7116\n",
            "Epoch 536/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3398 - accuracy: 0.8569 - val_loss: 0.7679 - val_accuracy: 0.7064\n",
            "Epoch 537/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3464 - accuracy: 0.8511 - val_loss: 0.7724 - val_accuracy: 0.7029\n",
            "Epoch 538/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3425 - accuracy: 0.8541 - val_loss: 0.7520 - val_accuracy: 0.7081\n",
            "Epoch 539/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3393 - accuracy: 0.8543 - val_loss: 0.7663 - val_accuracy: 0.7069\n",
            "Epoch 540/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3405 - accuracy: 0.8548 - val_loss: 0.7801 - val_accuracy: 0.6964\n",
            "Epoch 541/1000\n",
            "161/161 [==============================] - 10s 65ms/step - loss: 0.3414 - accuracy: 0.8536 - val_loss: 0.7462 - val_accuracy: 0.7086\n",
            "Epoch 542/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3405 - accuracy: 0.8550 - val_loss: 0.7247 - val_accuracy: 0.7139\n",
            "Epoch 543/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3412 - accuracy: 0.8523 - val_loss: 0.7676 - val_accuracy: 0.7036\n",
            "Epoch 544/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3427 - accuracy: 0.8505 - val_loss: 0.7847 - val_accuracy: 0.6974\n",
            "Epoch 545/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3459 - accuracy: 0.8510 - val_loss: 0.7840 - val_accuracy: 0.6962\n",
            "Epoch 546/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3510 - accuracy: 0.8491 - val_loss: 0.7515 - val_accuracy: 0.7119\n",
            "Epoch 547/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3428 - accuracy: 0.8514 - val_loss: 0.7392 - val_accuracy: 0.7171\n",
            "Epoch 548/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3438 - accuracy: 0.8498 - val_loss: 0.7444 - val_accuracy: 0.7146\n",
            "Epoch 549/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3423 - accuracy: 0.8541 - val_loss: 0.7994 - val_accuracy: 0.6907\n",
            "Epoch 550/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3443 - accuracy: 0.8509 - val_loss: 0.7476 - val_accuracy: 0.7081\n",
            "Epoch 551/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3415 - accuracy: 0.8530 - val_loss: 0.7585 - val_accuracy: 0.7089\n",
            "Epoch 552/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3428 - accuracy: 0.8530 - val_loss: 0.7928 - val_accuracy: 0.7044\n",
            "Epoch 553/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3516 - accuracy: 0.8451 - val_loss: 0.7428 - val_accuracy: 0.7096\n",
            "Epoch 554/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3442 - accuracy: 0.8510 - val_loss: 0.7643 - val_accuracy: 0.7076\n",
            "Epoch 555/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3493 - accuracy: 0.8498 - val_loss: 0.7504 - val_accuracy: 0.7101\n",
            "Epoch 556/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3440 - accuracy: 0.8521 - val_loss: 0.7287 - val_accuracy: 0.7144\n",
            "Epoch 557/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3394 - accuracy: 0.8554 - val_loss: 0.7234 - val_accuracy: 0.7189\n",
            "Epoch 558/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3412 - accuracy: 0.8524 - val_loss: 0.7669 - val_accuracy: 0.7074\n",
            "Epoch 559/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3413 - accuracy: 0.8543 - val_loss: 0.7521 - val_accuracy: 0.7124\n",
            "Epoch 560/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3425 - accuracy: 0.8523 - val_loss: 0.7437 - val_accuracy: 0.7101\n",
            "Epoch 561/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3438 - accuracy: 0.8523 - val_loss: 0.7514 - val_accuracy: 0.7124\n",
            "Epoch 562/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3465 - accuracy: 0.8517 - val_loss: 0.7437 - val_accuracy: 0.7139\n",
            "Epoch 563/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3464 - accuracy: 0.8490 - val_loss: 0.7444 - val_accuracy: 0.7089\n",
            "Epoch 564/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3420 - accuracy: 0.8537 - val_loss: 0.7509 - val_accuracy: 0.7094\n",
            "Epoch 565/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3419 - accuracy: 0.8539 - val_loss: 0.7534 - val_accuracy: 0.7099\n",
            "Epoch 566/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3392 - accuracy: 0.8555 - val_loss: 0.7542 - val_accuracy: 0.7099\n",
            "Epoch 567/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3506 - accuracy: 0.8501 - val_loss: 0.8152 - val_accuracy: 0.6972\n",
            "Epoch 568/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3590 - accuracy: 0.8436 - val_loss: 0.7430 - val_accuracy: 0.7134\n",
            "Epoch 569/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3466 - accuracy: 0.8498 - val_loss: 0.7432 - val_accuracy: 0.7139\n",
            "Epoch 570/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3410 - accuracy: 0.8534 - val_loss: 0.6878 - val_accuracy: 0.7266\n",
            "Epoch 571/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3434 - accuracy: 0.8511 - val_loss: 0.7109 - val_accuracy: 0.7266\n",
            "Epoch 572/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3411 - accuracy: 0.8544 - val_loss: 0.7752 - val_accuracy: 0.7071\n",
            "Epoch 573/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3481 - accuracy: 0.8525 - val_loss: 0.7574 - val_accuracy: 0.7054\n",
            "Epoch 574/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3413 - accuracy: 0.8522 - val_loss: 0.7432 - val_accuracy: 0.7136\n",
            "Epoch 575/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3403 - accuracy: 0.8540 - val_loss: 0.7569 - val_accuracy: 0.7076\n",
            "Epoch 576/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3442 - accuracy: 0.8522 - val_loss: 0.7034 - val_accuracy: 0.7239\n",
            "Epoch 577/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3404 - accuracy: 0.8538 - val_loss: 0.7346 - val_accuracy: 0.7146\n",
            "Epoch 578/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3405 - accuracy: 0.8507 - val_loss: 0.7425 - val_accuracy: 0.7151\n",
            "Epoch 579/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3440 - accuracy: 0.8524 - val_loss: 0.7282 - val_accuracy: 0.7139\n",
            "Epoch 580/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3428 - accuracy: 0.8530 - val_loss: 0.7429 - val_accuracy: 0.7081\n",
            "Epoch 581/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3427 - accuracy: 0.8521 - val_loss: 0.7441 - val_accuracy: 0.7121\n",
            "Epoch 582/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3402 - accuracy: 0.8525 - val_loss: 0.7159 - val_accuracy: 0.7181\n",
            "Epoch 583/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3450 - accuracy: 0.8510 - val_loss: 0.7080 - val_accuracy: 0.7186\n",
            "Epoch 584/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3418 - accuracy: 0.8528 - val_loss: 0.7396 - val_accuracy: 0.7171\n",
            "Epoch 585/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3469 - accuracy: 0.8486 - val_loss: 0.7519 - val_accuracy: 0.7079\n",
            "Epoch 586/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3442 - accuracy: 0.8510 - val_loss: 0.7718 - val_accuracy: 0.7044\n",
            "Epoch 587/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3424 - accuracy: 0.8518 - val_loss: 0.7702 - val_accuracy: 0.7049\n",
            "Epoch 588/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3423 - accuracy: 0.8520 - val_loss: 0.7133 - val_accuracy: 0.7249\n",
            "Epoch 589/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3433 - accuracy: 0.8513 - val_loss: 0.7499 - val_accuracy: 0.7116\n",
            "Epoch 590/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3403 - accuracy: 0.8531 - val_loss: 0.7244 - val_accuracy: 0.7181\n",
            "Epoch 591/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3433 - accuracy: 0.8516 - val_loss: 0.7426 - val_accuracy: 0.7071\n",
            "Epoch 592/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3423 - accuracy: 0.8525 - val_loss: 0.7480 - val_accuracy: 0.7074\n",
            "Epoch 593/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3397 - accuracy: 0.8528 - val_loss: 0.7370 - val_accuracy: 0.7196\n",
            "Epoch 594/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3473 - accuracy: 0.8481 - val_loss: 0.7315 - val_accuracy: 0.7209\n",
            "Epoch 595/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3579 - accuracy: 0.8457 - val_loss: 0.8041 - val_accuracy: 0.6944\n",
            "Epoch 596/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3421 - accuracy: 0.8524 - val_loss: 0.7144 - val_accuracy: 0.7179\n",
            "Epoch 597/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3439 - accuracy: 0.8538 - val_loss: 0.7173 - val_accuracy: 0.7209\n",
            "Epoch 598/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3414 - accuracy: 0.8535 - val_loss: 0.7567 - val_accuracy: 0.7101\n",
            "Epoch 599/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3405 - accuracy: 0.8534 - val_loss: 0.7365 - val_accuracy: 0.7099\n",
            "Epoch 600/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3415 - accuracy: 0.8512 - val_loss: 0.7340 - val_accuracy: 0.7156\n",
            "Epoch 601/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3411 - accuracy: 0.8545 - val_loss: 0.7175 - val_accuracy: 0.7194\n",
            "Epoch 602/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3421 - accuracy: 0.8525 - val_loss: 0.7390 - val_accuracy: 0.7156\n",
            "Epoch 603/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3427 - accuracy: 0.8534 - val_loss: 0.7329 - val_accuracy: 0.7211\n",
            "Epoch 604/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3411 - accuracy: 0.8523 - val_loss: 0.7330 - val_accuracy: 0.7144\n",
            "Epoch 605/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3410 - accuracy: 0.8542 - val_loss: 0.7628 - val_accuracy: 0.7059\n",
            "Epoch 606/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3416 - accuracy: 0.8523 - val_loss: 0.7221 - val_accuracy: 0.7174\n",
            "Epoch 607/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3407 - accuracy: 0.8528 - val_loss: 0.7442 - val_accuracy: 0.7149\n",
            "Epoch 608/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3426 - accuracy: 0.8533 - val_loss: 0.7466 - val_accuracy: 0.7134\n",
            "Epoch 609/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3455 - accuracy: 0.8498 - val_loss: 0.7855 - val_accuracy: 0.6987\n",
            "Epoch 610/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3472 - accuracy: 0.8492 - val_loss: 0.7402 - val_accuracy: 0.7129\n",
            "Epoch 611/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3422 - accuracy: 0.8528 - val_loss: 0.7315 - val_accuracy: 0.7161\n",
            "Epoch 612/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3417 - accuracy: 0.8513 - val_loss: 0.7382 - val_accuracy: 0.7169\n",
            "Epoch 613/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3421 - accuracy: 0.8538 - val_loss: 0.7791 - val_accuracy: 0.7031\n",
            "Epoch 614/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3466 - accuracy: 0.8501 - val_loss: 0.7576 - val_accuracy: 0.7086\n",
            "Epoch 615/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3417 - accuracy: 0.8555 - val_loss: 0.7544 - val_accuracy: 0.7094\n",
            "Epoch 616/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3412 - accuracy: 0.8526 - val_loss: 0.6894 - val_accuracy: 0.7364\n",
            "Epoch 617/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3417 - accuracy: 0.8528 - val_loss: 0.7735 - val_accuracy: 0.7046\n",
            "Epoch 618/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3436 - accuracy: 0.8521 - val_loss: 0.7428 - val_accuracy: 0.7116\n",
            "Epoch 619/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3399 - accuracy: 0.8563 - val_loss: 0.7441 - val_accuracy: 0.7096\n",
            "Epoch 620/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3410 - accuracy: 0.8551 - val_loss: 0.7247 - val_accuracy: 0.7166\n",
            "Epoch 621/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3418 - accuracy: 0.8543 - val_loss: 0.6991 - val_accuracy: 0.7324\n",
            "Epoch 622/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3471 - accuracy: 0.8496 - val_loss: 0.7617 - val_accuracy: 0.7106\n",
            "Epoch 623/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3413 - accuracy: 0.8530 - val_loss: 0.7869 - val_accuracy: 0.6939\n",
            "Epoch 624/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3418 - accuracy: 0.8525 - val_loss: 0.7540 - val_accuracy: 0.7114\n",
            "Epoch 625/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3450 - accuracy: 0.8520 - val_loss: 0.7544 - val_accuracy: 0.7086\n",
            "Epoch 626/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3452 - accuracy: 0.8505 - val_loss: 0.7948 - val_accuracy: 0.6992\n",
            "Epoch 627/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3402 - accuracy: 0.8531 - val_loss: 0.7160 - val_accuracy: 0.7286\n",
            "Epoch 628/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3491 - accuracy: 0.8495 - val_loss: 0.7908 - val_accuracy: 0.6972\n",
            "Epoch 629/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3436 - accuracy: 0.8521 - val_loss: 0.7705 - val_accuracy: 0.7081\n",
            "Epoch 630/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3440 - accuracy: 0.8523 - val_loss: 0.7582 - val_accuracy: 0.7051\n",
            "Epoch 631/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3420 - accuracy: 0.8524 - val_loss: 0.7284 - val_accuracy: 0.7136\n",
            "Epoch 632/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3405 - accuracy: 0.8531 - val_loss: 0.7396 - val_accuracy: 0.7151\n",
            "Epoch 633/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3400 - accuracy: 0.8551 - val_loss: 0.7357 - val_accuracy: 0.7121\n",
            "Epoch 634/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3419 - accuracy: 0.8544 - val_loss: 0.7395 - val_accuracy: 0.7156\n",
            "Epoch 635/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3421 - accuracy: 0.8538 - val_loss: 0.7208 - val_accuracy: 0.7176\n",
            "Epoch 636/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3425 - accuracy: 0.8546 - val_loss: 0.7163 - val_accuracy: 0.7211\n",
            "Epoch 637/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3453 - accuracy: 0.8495 - val_loss: 0.7218 - val_accuracy: 0.7204\n",
            "Epoch 638/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3482 - accuracy: 0.8497 - val_loss: 0.7401 - val_accuracy: 0.7106\n",
            "Epoch 639/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3421 - accuracy: 0.8560 - val_loss: 0.7507 - val_accuracy: 0.7139\n",
            "Epoch 640/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3483 - accuracy: 0.8500 - val_loss: 0.7462 - val_accuracy: 0.7124\n",
            "Epoch 641/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3422 - accuracy: 0.8540 - val_loss: 0.7386 - val_accuracy: 0.7161\n",
            "Epoch 642/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3397 - accuracy: 0.8551 - val_loss: 0.7359 - val_accuracy: 0.7139\n",
            "Epoch 643/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3415 - accuracy: 0.8525 - val_loss: 0.7816 - val_accuracy: 0.7076\n",
            "Epoch 644/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3484 - accuracy: 0.8491 - val_loss: 0.7191 - val_accuracy: 0.7234\n",
            "Epoch 645/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3409 - accuracy: 0.8531 - val_loss: 0.7563 - val_accuracy: 0.7101\n",
            "Epoch 646/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3435 - accuracy: 0.8510 - val_loss: 0.7530 - val_accuracy: 0.7061\n",
            "Epoch 647/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3415 - accuracy: 0.8545 - val_loss: 0.7342 - val_accuracy: 0.7134\n",
            "Epoch 648/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3402 - accuracy: 0.8564 - val_loss: 0.7712 - val_accuracy: 0.7011\n",
            "Epoch 649/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3589 - accuracy: 0.8438 - val_loss: 0.7079 - val_accuracy: 0.7284\n",
            "Epoch 650/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3405 - accuracy: 0.8538 - val_loss: 0.7147 - val_accuracy: 0.7204\n",
            "Epoch 651/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3413 - accuracy: 0.8542 - val_loss: 0.7518 - val_accuracy: 0.7036\n",
            "Epoch 652/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3416 - accuracy: 0.8537 - val_loss: 0.7114 - val_accuracy: 0.7154\n",
            "Epoch 653/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3441 - accuracy: 0.8503 - val_loss: 0.7546 - val_accuracy: 0.7071\n",
            "Epoch 654/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3431 - accuracy: 0.8518 - val_loss: 0.7694 - val_accuracy: 0.7046\n",
            "Epoch 655/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3427 - accuracy: 0.8543 - val_loss: 0.7701 - val_accuracy: 0.6992\n",
            "Epoch 656/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3434 - accuracy: 0.8514 - val_loss: 0.7638 - val_accuracy: 0.7089\n",
            "Epoch 657/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3422 - accuracy: 0.8551 - val_loss: 0.7113 - val_accuracy: 0.7189\n",
            "Epoch 658/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3438 - accuracy: 0.8514 - val_loss: 0.7493 - val_accuracy: 0.7136\n",
            "Epoch 659/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3457 - accuracy: 0.8540 - val_loss: 0.7527 - val_accuracy: 0.7041\n",
            "Epoch 660/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3406 - accuracy: 0.8539 - val_loss: 0.7507 - val_accuracy: 0.7041\n",
            "Epoch 661/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3503 - accuracy: 0.8486 - val_loss: 0.7466 - val_accuracy: 0.7131\n",
            "Epoch 662/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3475 - accuracy: 0.8486 - val_loss: 0.7558 - val_accuracy: 0.7081\n",
            "Epoch 663/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3390 - accuracy: 0.8540 - val_loss: 0.7372 - val_accuracy: 0.7134\n",
            "Epoch 664/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3450 - accuracy: 0.8500 - val_loss: 0.7438 - val_accuracy: 0.7134\n",
            "Epoch 665/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3421 - accuracy: 0.8540 - val_loss: 0.7516 - val_accuracy: 0.7154\n",
            "Epoch 666/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3429 - accuracy: 0.8518 - val_loss: 0.7381 - val_accuracy: 0.7136\n",
            "Epoch 667/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3412 - accuracy: 0.8530 - val_loss: 0.7741 - val_accuracy: 0.7051\n",
            "Epoch 668/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3433 - accuracy: 0.8533 - val_loss: 0.7253 - val_accuracy: 0.7196\n",
            "Epoch 669/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3417 - accuracy: 0.8542 - val_loss: 0.7588 - val_accuracy: 0.7096\n",
            "Epoch 670/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3413 - accuracy: 0.8543 - val_loss: 0.7479 - val_accuracy: 0.7101\n",
            "Epoch 671/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3425 - accuracy: 0.8523 - val_loss: 0.7384 - val_accuracy: 0.7136\n",
            "Epoch 672/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3469 - accuracy: 0.8496 - val_loss: 0.7215 - val_accuracy: 0.7234\n",
            "Epoch 673/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3408 - accuracy: 0.8530 - val_loss: 0.7195 - val_accuracy: 0.7186\n",
            "Epoch 674/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3407 - accuracy: 0.8516 - val_loss: 0.7670 - val_accuracy: 0.7089\n",
            "Epoch 675/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3405 - accuracy: 0.8547 - val_loss: 0.7383 - val_accuracy: 0.7096\n",
            "Epoch 676/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3415 - accuracy: 0.8525 - val_loss: 0.7747 - val_accuracy: 0.7026\n",
            "Epoch 677/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3420 - accuracy: 0.8528 - val_loss: 0.7763 - val_accuracy: 0.7036\n",
            "Epoch 678/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3549 - accuracy: 0.8460 - val_loss: 0.7356 - val_accuracy: 0.7171\n",
            "Epoch 679/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3437 - accuracy: 0.8520 - val_loss: 0.7171 - val_accuracy: 0.7179\n",
            "Epoch 680/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3440 - accuracy: 0.8513 - val_loss: 0.7081 - val_accuracy: 0.7229\n",
            "Epoch 681/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3392 - accuracy: 0.8558 - val_loss: 0.7524 - val_accuracy: 0.7094\n",
            "Epoch 682/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3467 - accuracy: 0.8491 - val_loss: 0.7858 - val_accuracy: 0.7031\n",
            "Epoch 683/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3479 - accuracy: 0.8483 - val_loss: 0.7154 - val_accuracy: 0.7131\n",
            "Epoch 684/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3414 - accuracy: 0.8528 - val_loss: 0.7494 - val_accuracy: 0.7136\n",
            "Epoch 685/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3402 - accuracy: 0.8547 - val_loss: 0.7941 - val_accuracy: 0.6997\n",
            "Epoch 686/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3420 - accuracy: 0.8535 - val_loss: 0.7376 - val_accuracy: 0.7161\n",
            "Epoch 687/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3407 - accuracy: 0.8516 - val_loss: 0.7372 - val_accuracy: 0.7161\n",
            "Epoch 688/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3445 - accuracy: 0.8513 - val_loss: 0.7373 - val_accuracy: 0.7144\n",
            "Epoch 689/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3447 - accuracy: 0.8498 - val_loss: 0.7192 - val_accuracy: 0.7139\n",
            "Epoch 690/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3431 - accuracy: 0.8503 - val_loss: 0.7430 - val_accuracy: 0.7149\n",
            "Epoch 691/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3403 - accuracy: 0.8533 - val_loss: 0.7504 - val_accuracy: 0.7111\n",
            "Epoch 692/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3399 - accuracy: 0.8542 - val_loss: 0.7159 - val_accuracy: 0.7204\n",
            "Epoch 693/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3418 - accuracy: 0.8530 - val_loss: 0.7169 - val_accuracy: 0.7171\n",
            "Epoch 694/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3434 - accuracy: 0.8519 - val_loss: 0.7102 - val_accuracy: 0.7241\n",
            "Epoch 695/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3396 - accuracy: 0.8552 - val_loss: 0.7018 - val_accuracy: 0.7281\n",
            "Epoch 696/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3441 - accuracy: 0.8520 - val_loss: 0.7263 - val_accuracy: 0.7166\n",
            "Epoch 697/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3403 - accuracy: 0.8558 - val_loss: 0.7590 - val_accuracy: 0.7106\n",
            "Epoch 698/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3566 - accuracy: 0.8487 - val_loss: 0.7229 - val_accuracy: 0.7149\n",
            "Epoch 699/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3420 - accuracy: 0.8517 - val_loss: 0.7483 - val_accuracy: 0.7084\n",
            "Epoch 700/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3444 - accuracy: 0.8518 - val_loss: 0.6976 - val_accuracy: 0.7271\n",
            "Epoch 701/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3442 - accuracy: 0.8500 - val_loss: 0.7345 - val_accuracy: 0.7111\n",
            "Epoch 702/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3405 - accuracy: 0.8528 - val_loss: 0.7573 - val_accuracy: 0.7064\n",
            "Epoch 703/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3428 - accuracy: 0.8505 - val_loss: 0.7912 - val_accuracy: 0.6997\n",
            "Epoch 704/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3462 - accuracy: 0.8500 - val_loss: 0.7471 - val_accuracy: 0.7081\n",
            "Epoch 705/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3385 - accuracy: 0.8553 - val_loss: 0.7179 - val_accuracy: 0.7174\n",
            "Epoch 706/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3474 - accuracy: 0.8503 - val_loss: 0.7322 - val_accuracy: 0.7196\n",
            "Epoch 707/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3469 - accuracy: 0.8495 - val_loss: 0.7619 - val_accuracy: 0.7064\n",
            "Epoch 708/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3456 - accuracy: 0.8504 - val_loss: 0.7437 - val_accuracy: 0.7121\n",
            "Epoch 709/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3473 - accuracy: 0.8491 - val_loss: 0.7300 - val_accuracy: 0.7139\n",
            "Epoch 710/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3412 - accuracy: 0.8535 - val_loss: 0.7538 - val_accuracy: 0.7084\n",
            "Epoch 711/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3417 - accuracy: 0.8538 - val_loss: 0.7390 - val_accuracy: 0.7121\n",
            "Epoch 712/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3482 - accuracy: 0.8497 - val_loss: 0.7389 - val_accuracy: 0.7139\n",
            "Epoch 713/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3411 - accuracy: 0.8535 - val_loss: 0.7748 - val_accuracy: 0.7041\n",
            "Epoch 714/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3492 - accuracy: 0.8513 - val_loss: 0.7302 - val_accuracy: 0.7131\n",
            "Epoch 715/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3493 - accuracy: 0.8483 - val_loss: 0.7425 - val_accuracy: 0.7149\n",
            "Epoch 716/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3398 - accuracy: 0.8538 - val_loss: 0.7212 - val_accuracy: 0.7191\n",
            "Epoch 717/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3434 - accuracy: 0.8528 - val_loss: 0.7488 - val_accuracy: 0.7086\n",
            "Epoch 718/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3408 - accuracy: 0.8548 - val_loss: 0.7039 - val_accuracy: 0.7256\n",
            "Epoch 719/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3427 - accuracy: 0.8536 - val_loss: 0.7811 - val_accuracy: 0.7011\n",
            "Epoch 720/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3405 - accuracy: 0.8533 - val_loss: 0.7533 - val_accuracy: 0.7106\n",
            "Epoch 721/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3520 - accuracy: 0.8476 - val_loss: 0.7584 - val_accuracy: 0.7094\n",
            "Epoch 722/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3418 - accuracy: 0.8560 - val_loss: 0.7252 - val_accuracy: 0.7149\n",
            "Epoch 723/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3423 - accuracy: 0.8538 - val_loss: 0.7364 - val_accuracy: 0.7164\n",
            "Epoch 724/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3442 - accuracy: 0.8518 - val_loss: 0.7651 - val_accuracy: 0.7094\n",
            "Epoch 725/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3413 - accuracy: 0.8537 - val_loss: 0.7733 - val_accuracy: 0.7034\n",
            "Epoch 726/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3413 - accuracy: 0.8530 - val_loss: 0.7586 - val_accuracy: 0.7059\n",
            "Epoch 727/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3402 - accuracy: 0.8567 - val_loss: 0.7164 - val_accuracy: 0.7169\n",
            "Epoch 728/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3500 - accuracy: 0.8498 - val_loss: 0.7932 - val_accuracy: 0.7014\n",
            "Epoch 729/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3441 - accuracy: 0.8520 - val_loss: 0.7422 - val_accuracy: 0.7116\n",
            "Epoch 730/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3434 - accuracy: 0.8502 - val_loss: 0.7020 - val_accuracy: 0.7269\n",
            "Epoch 731/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3410 - accuracy: 0.8508 - val_loss: 0.7286 - val_accuracy: 0.7151\n",
            "Epoch 732/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3434 - accuracy: 0.8521 - val_loss: 0.7850 - val_accuracy: 0.7004\n",
            "Epoch 733/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3473 - accuracy: 0.8502 - val_loss: 0.7478 - val_accuracy: 0.7096\n",
            "Epoch 734/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3440 - accuracy: 0.8515 - val_loss: 0.7983 - val_accuracy: 0.6984\n",
            "Epoch 735/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3429 - accuracy: 0.8533 - val_loss: 0.7590 - val_accuracy: 0.7096\n",
            "Epoch 736/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3436 - accuracy: 0.8525 - val_loss: 0.7659 - val_accuracy: 0.7044\n",
            "Epoch 737/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3406 - accuracy: 0.8525 - val_loss: 0.7582 - val_accuracy: 0.7089\n",
            "Epoch 738/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3403 - accuracy: 0.8541 - val_loss: 0.7720 - val_accuracy: 0.6997\n",
            "Epoch 739/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3414 - accuracy: 0.8546 - val_loss: 0.7404 - val_accuracy: 0.7129\n",
            "Epoch 740/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3435 - accuracy: 0.8511 - val_loss: 0.7679 - val_accuracy: 0.7024\n",
            "Epoch 741/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3405 - accuracy: 0.8540 - val_loss: 0.7087 - val_accuracy: 0.7216\n",
            "Epoch 742/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3390 - accuracy: 0.8538 - val_loss: 0.7554 - val_accuracy: 0.7106\n",
            "Epoch 743/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3408 - accuracy: 0.8543 - val_loss: 0.7664 - val_accuracy: 0.7041\n",
            "Epoch 744/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3410 - accuracy: 0.8551 - val_loss: 0.7133 - val_accuracy: 0.7241\n",
            "Epoch 745/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3431 - accuracy: 0.8490 - val_loss: 0.7367 - val_accuracy: 0.7176\n",
            "Epoch 746/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3431 - accuracy: 0.8506 - val_loss: 0.7578 - val_accuracy: 0.7089\n",
            "Epoch 747/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3453 - accuracy: 0.8493 - val_loss: 0.7709 - val_accuracy: 0.7046\n",
            "Epoch 748/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3445 - accuracy: 0.8513 - val_loss: 0.7514 - val_accuracy: 0.7096\n",
            "Epoch 749/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3412 - accuracy: 0.8525 - val_loss: 0.7609 - val_accuracy: 0.7076\n",
            "Epoch 750/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3473 - accuracy: 0.8523 - val_loss: 0.7266 - val_accuracy: 0.7191\n",
            "Epoch 751/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3423 - accuracy: 0.8523 - val_loss: 0.7388 - val_accuracy: 0.7126\n",
            "Epoch 752/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3409 - accuracy: 0.8532 - val_loss: 0.7775 - val_accuracy: 0.7009\n",
            "Epoch 753/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3486 - accuracy: 0.8507 - val_loss: 0.7264 - val_accuracy: 0.7184\n",
            "Epoch 754/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3410 - accuracy: 0.8544 - val_loss: 0.7598 - val_accuracy: 0.7051\n",
            "Epoch 755/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3469 - accuracy: 0.8503 - val_loss: 0.7543 - val_accuracy: 0.7106\n",
            "Epoch 756/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3410 - accuracy: 0.8532 - val_loss: 0.7715 - val_accuracy: 0.6994\n",
            "Epoch 757/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3393 - accuracy: 0.8549 - val_loss: 0.7594 - val_accuracy: 0.7064\n",
            "Epoch 758/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3417 - accuracy: 0.8539 - val_loss: 0.8003 - val_accuracy: 0.6939\n",
            "Epoch 759/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3427 - accuracy: 0.8533 - val_loss: 0.7530 - val_accuracy: 0.7059\n",
            "Epoch 760/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3425 - accuracy: 0.8516 - val_loss: 0.7408 - val_accuracy: 0.7149\n",
            "Epoch 761/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3396 - accuracy: 0.8522 - val_loss: 0.7554 - val_accuracy: 0.7106\n",
            "Epoch 762/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3400 - accuracy: 0.8533 - val_loss: 0.7135 - val_accuracy: 0.7241\n",
            "Epoch 763/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3436 - accuracy: 0.8526 - val_loss: 0.8246 - val_accuracy: 0.6889\n",
            "Epoch 764/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3450 - accuracy: 0.8539 - val_loss: 0.7566 - val_accuracy: 0.7071\n",
            "Epoch 765/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3433 - accuracy: 0.8533 - val_loss: 0.7621 - val_accuracy: 0.7066\n",
            "Epoch 766/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3436 - accuracy: 0.8509 - val_loss: 0.7571 - val_accuracy: 0.7091\n",
            "Epoch 767/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3394 - accuracy: 0.8545 - val_loss: 0.7510 - val_accuracy: 0.7084\n",
            "Epoch 768/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3418 - accuracy: 0.8528 - val_loss: 0.7312 - val_accuracy: 0.7179\n",
            "Epoch 769/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3415 - accuracy: 0.8531 - val_loss: 0.7389 - val_accuracy: 0.7134\n",
            "Epoch 770/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3393 - accuracy: 0.8539 - val_loss: 0.7566 - val_accuracy: 0.7086\n",
            "Epoch 771/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3412 - accuracy: 0.8537 - val_loss: 0.7780 - val_accuracy: 0.7014\n",
            "Epoch 772/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3445 - accuracy: 0.8498 - val_loss: 0.6807 - val_accuracy: 0.7329\n",
            "Epoch 773/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3452 - accuracy: 0.8513 - val_loss: 0.7702 - val_accuracy: 0.7106\n",
            "Epoch 774/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3507 - accuracy: 0.8470 - val_loss: 0.7465 - val_accuracy: 0.7149\n",
            "Epoch 775/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3423 - accuracy: 0.8542 - val_loss: 0.7404 - val_accuracy: 0.7139\n",
            "Epoch 776/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3417 - accuracy: 0.8528 - val_loss: 0.7361 - val_accuracy: 0.7146\n",
            "Epoch 777/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3411 - accuracy: 0.8556 - val_loss: 0.7279 - val_accuracy: 0.7189\n",
            "Epoch 778/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3454 - accuracy: 0.8519 - val_loss: 0.7399 - val_accuracy: 0.7106\n",
            "Epoch 779/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3420 - accuracy: 0.8524 - val_loss: 0.7125 - val_accuracy: 0.7224\n",
            "Epoch 780/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3398 - accuracy: 0.8540 - val_loss: 0.7715 - val_accuracy: 0.7066\n",
            "Epoch 781/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3415 - accuracy: 0.8547 - val_loss: 0.7614 - val_accuracy: 0.7101\n",
            "Epoch 782/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3455 - accuracy: 0.8521 - val_loss: 0.7616 - val_accuracy: 0.7069\n",
            "Epoch 783/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3415 - accuracy: 0.8538 - val_loss: 0.7841 - val_accuracy: 0.6982\n",
            "Epoch 784/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3396 - accuracy: 0.8552 - val_loss: 0.7210 - val_accuracy: 0.7191\n",
            "Epoch 785/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3408 - accuracy: 0.8548 - val_loss: 0.7577 - val_accuracy: 0.7051\n",
            "Epoch 786/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3478 - accuracy: 0.8493 - val_loss: 0.7445 - val_accuracy: 0.7114\n",
            "Epoch 787/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3449 - accuracy: 0.8530 - val_loss: 0.6986 - val_accuracy: 0.7284\n",
            "Epoch 788/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3406 - accuracy: 0.8529 - val_loss: 0.7225 - val_accuracy: 0.7184\n",
            "Epoch 789/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3422 - accuracy: 0.8542 - val_loss: 0.7513 - val_accuracy: 0.7101\n",
            "Epoch 790/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3392 - accuracy: 0.8530 - val_loss: 0.7279 - val_accuracy: 0.7141\n",
            "Epoch 791/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3441 - accuracy: 0.8531 - val_loss: 0.7377 - val_accuracy: 0.7179\n",
            "Epoch 792/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3430 - accuracy: 0.8520 - val_loss: 0.7813 - val_accuracy: 0.7019\n",
            "Epoch 793/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3479 - accuracy: 0.8488 - val_loss: 0.8075 - val_accuracy: 0.6957\n",
            "Epoch 794/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3424 - accuracy: 0.8526 - val_loss: 0.7523 - val_accuracy: 0.7079\n",
            "Epoch 795/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3457 - accuracy: 0.8527 - val_loss: 0.7673 - val_accuracy: 0.7049\n",
            "Epoch 796/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3457 - accuracy: 0.8506 - val_loss: 0.7674 - val_accuracy: 0.7089\n",
            "Epoch 797/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3440 - accuracy: 0.8510 - val_loss: 0.7513 - val_accuracy: 0.7096\n",
            "Epoch 798/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3422 - accuracy: 0.8539 - val_loss: 0.7703 - val_accuracy: 0.7071\n",
            "Epoch 799/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3419 - accuracy: 0.8513 - val_loss: 0.7447 - val_accuracy: 0.7121\n",
            "Epoch 800/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3398 - accuracy: 0.8545 - val_loss: 0.7931 - val_accuracy: 0.6974\n",
            "Epoch 801/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3479 - accuracy: 0.8510 - val_loss: 0.7719 - val_accuracy: 0.7024\n",
            "Epoch 802/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3433 - accuracy: 0.8531 - val_loss: 0.7269 - val_accuracy: 0.7151\n",
            "Epoch 803/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3425 - accuracy: 0.8511 - val_loss: 0.7984 - val_accuracy: 0.7011\n",
            "Epoch 804/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3414 - accuracy: 0.8545 - val_loss: 0.7704 - val_accuracy: 0.7021\n",
            "Epoch 805/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3455 - accuracy: 0.8513 - val_loss: 0.7784 - val_accuracy: 0.7071\n",
            "Epoch 806/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3411 - accuracy: 0.8535 - val_loss: 0.7434 - val_accuracy: 0.7116\n",
            "Epoch 807/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3396 - accuracy: 0.8528 - val_loss: 0.7516 - val_accuracy: 0.7056\n",
            "Epoch 808/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3445 - accuracy: 0.8494 - val_loss: 0.7731 - val_accuracy: 0.7034\n",
            "Epoch 809/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3417 - accuracy: 0.8510 - val_loss: 0.7497 - val_accuracy: 0.7131\n",
            "Epoch 810/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3432 - accuracy: 0.8530 - val_loss: 0.7427 - val_accuracy: 0.7141\n",
            "Epoch 811/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3438 - accuracy: 0.8530 - val_loss: 0.7403 - val_accuracy: 0.7154\n",
            "Epoch 812/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3402 - accuracy: 0.8533 - val_loss: 0.7268 - val_accuracy: 0.7159\n",
            "Epoch 813/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3397 - accuracy: 0.8553 - val_loss: 0.7626 - val_accuracy: 0.7031\n",
            "Epoch 814/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3407 - accuracy: 0.8535 - val_loss: 0.7578 - val_accuracy: 0.7096\n",
            "Epoch 815/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3421 - accuracy: 0.8528 - val_loss: 0.7289 - val_accuracy: 0.7211\n",
            "Epoch 816/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3462 - accuracy: 0.8484 - val_loss: 0.7292 - val_accuracy: 0.7161\n",
            "Epoch 817/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3423 - accuracy: 0.8527 - val_loss: 0.7548 - val_accuracy: 0.7071\n",
            "Epoch 818/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3433 - accuracy: 0.8526 - val_loss: 0.7916 - val_accuracy: 0.6977\n",
            "Epoch 819/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3422 - accuracy: 0.8528 - val_loss: 0.7121 - val_accuracy: 0.7219\n",
            "Epoch 820/1000\n",
            "161/161 [==============================] - 11s 66ms/step - loss: 0.3439 - accuracy: 0.8525 - val_loss: 0.7328 - val_accuracy: 0.7094\n",
            "Epoch 821/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3393 - accuracy: 0.8538 - val_loss: 0.7605 - val_accuracy: 0.7089\n",
            "Epoch 822/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3481 - accuracy: 0.8518 - val_loss: 0.8170 - val_accuracy: 0.6899\n",
            "Epoch 823/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3494 - accuracy: 0.8508 - val_loss: 0.7477 - val_accuracy: 0.7056\n",
            "Epoch 824/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3448 - accuracy: 0.8514 - val_loss: 0.7797 - val_accuracy: 0.7016\n",
            "Epoch 825/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3410 - accuracy: 0.8530 - val_loss: 0.7763 - val_accuracy: 0.7064\n",
            "Epoch 826/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3481 - accuracy: 0.8523 - val_loss: 0.7752 - val_accuracy: 0.7019\n",
            "Epoch 827/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3449 - accuracy: 0.8546 - val_loss: 0.7651 - val_accuracy: 0.7059\n",
            "Epoch 828/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3423 - accuracy: 0.8534 - val_loss: 0.7483 - val_accuracy: 0.7084\n",
            "Epoch 829/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3395 - accuracy: 0.8529 - val_loss: 0.7470 - val_accuracy: 0.7086\n",
            "Epoch 830/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3428 - accuracy: 0.8536 - val_loss: 0.7536 - val_accuracy: 0.7124\n",
            "Epoch 831/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3438 - accuracy: 0.8533 - val_loss: 0.7646 - val_accuracy: 0.7081\n",
            "Epoch 832/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3443 - accuracy: 0.8513 - val_loss: 0.7320 - val_accuracy: 0.7144\n",
            "Epoch 833/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3447 - accuracy: 0.8536 - val_loss: 0.7483 - val_accuracy: 0.7096\n",
            "Epoch 834/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3399 - accuracy: 0.8535 - val_loss: 0.7646 - val_accuracy: 0.7024\n",
            "Epoch 835/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3399 - accuracy: 0.8534 - val_loss: 0.7471 - val_accuracy: 0.7109\n",
            "Epoch 836/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3412 - accuracy: 0.8538 - val_loss: 0.7657 - val_accuracy: 0.7066\n",
            "Epoch 837/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3444 - accuracy: 0.8522 - val_loss: 0.7722 - val_accuracy: 0.7109\n",
            "Epoch 838/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3602 - accuracy: 0.8441 - val_loss: 0.7279 - val_accuracy: 0.7206\n",
            "Epoch 839/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3433 - accuracy: 0.8525 - val_loss: 0.7514 - val_accuracy: 0.7086\n",
            "Epoch 840/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3477 - accuracy: 0.8502 - val_loss: 0.7463 - val_accuracy: 0.7151\n",
            "Epoch 841/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3608 - accuracy: 0.8449 - val_loss: 0.7687 - val_accuracy: 0.7049\n",
            "Epoch 842/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3401 - accuracy: 0.8536 - val_loss: 0.7745 - val_accuracy: 0.7041\n",
            "Epoch 843/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3418 - accuracy: 0.8531 - val_loss: 0.7772 - val_accuracy: 0.7001\n",
            "Epoch 844/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3391 - accuracy: 0.8546 - val_loss: 0.7135 - val_accuracy: 0.7206\n",
            "Epoch 845/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3410 - accuracy: 0.8532 - val_loss: 0.7652 - val_accuracy: 0.7076\n",
            "Epoch 846/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3512 - accuracy: 0.8470 - val_loss: 0.7540 - val_accuracy: 0.7106\n",
            "Epoch 847/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3397 - accuracy: 0.8540 - val_loss: 0.7497 - val_accuracy: 0.7106\n",
            "Epoch 848/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3440 - accuracy: 0.8527 - val_loss: 0.7509 - val_accuracy: 0.7079\n",
            "Epoch 849/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3401 - accuracy: 0.8554 - val_loss: 0.7910 - val_accuracy: 0.7041\n",
            "Epoch 850/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3537 - accuracy: 0.8454 - val_loss: 0.7479 - val_accuracy: 0.7104\n",
            "Epoch 851/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3389 - accuracy: 0.8552 - val_loss: 0.7419 - val_accuracy: 0.7116\n",
            "Epoch 852/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3414 - accuracy: 0.8533 - val_loss: 0.7623 - val_accuracy: 0.7104\n",
            "Epoch 853/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3461 - accuracy: 0.8506 - val_loss: 0.7459 - val_accuracy: 0.7134\n",
            "Epoch 854/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3444 - accuracy: 0.8493 - val_loss: 0.7331 - val_accuracy: 0.7171\n",
            "Epoch 855/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3437 - accuracy: 0.8502 - val_loss: 0.7675 - val_accuracy: 0.7016\n",
            "Epoch 856/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3429 - accuracy: 0.8523 - val_loss: 0.7664 - val_accuracy: 0.7031\n",
            "Epoch 857/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3435 - accuracy: 0.8521 - val_loss: 0.7461 - val_accuracy: 0.7139\n",
            "Epoch 858/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3407 - accuracy: 0.8528 - val_loss: 0.7694 - val_accuracy: 0.7049\n",
            "Epoch 859/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3469 - accuracy: 0.8519 - val_loss: 0.7516 - val_accuracy: 0.7096\n",
            "Epoch 860/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3472 - accuracy: 0.8488 - val_loss: 0.7575 - val_accuracy: 0.7101\n",
            "Epoch 861/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3421 - accuracy: 0.8533 - val_loss: 0.7895 - val_accuracy: 0.6979\n",
            "Epoch 862/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3400 - accuracy: 0.8530 - val_loss: 0.7745 - val_accuracy: 0.7031\n",
            "Epoch 863/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3401 - accuracy: 0.8535 - val_loss: 0.7492 - val_accuracy: 0.7106\n",
            "Epoch 864/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3416 - accuracy: 0.8521 - val_loss: 0.7745 - val_accuracy: 0.7086\n",
            "Epoch 865/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3416 - accuracy: 0.8528 - val_loss: 0.7300 - val_accuracy: 0.7169\n",
            "Epoch 866/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3406 - accuracy: 0.8534 - val_loss: 0.7503 - val_accuracy: 0.7119\n",
            "Epoch 867/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3407 - accuracy: 0.8545 - val_loss: 0.7403 - val_accuracy: 0.7154\n",
            "Epoch 868/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3397 - accuracy: 0.8545 - val_loss: 0.7490 - val_accuracy: 0.7081\n",
            "Epoch 869/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3415 - accuracy: 0.8528 - val_loss: 0.7321 - val_accuracy: 0.7131\n",
            "Epoch 870/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3424 - accuracy: 0.8543 - val_loss: 0.7511 - val_accuracy: 0.7076\n",
            "Epoch 871/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3406 - accuracy: 0.8537 - val_loss: 0.7070 - val_accuracy: 0.7254\n",
            "Epoch 872/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3404 - accuracy: 0.8560 - val_loss: 0.7334 - val_accuracy: 0.7171\n",
            "Epoch 873/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3401 - accuracy: 0.8551 - val_loss: 0.7441 - val_accuracy: 0.7166\n",
            "Epoch 874/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3436 - accuracy: 0.8516 - val_loss: 0.7531 - val_accuracy: 0.7061\n",
            "Epoch 875/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3403 - accuracy: 0.8534 - val_loss: 0.7787 - val_accuracy: 0.6997\n",
            "Epoch 876/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3438 - accuracy: 0.8528 - val_loss: 0.7609 - val_accuracy: 0.7141\n",
            "Epoch 877/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3518 - accuracy: 0.8466 - val_loss: 0.7297 - val_accuracy: 0.7211\n",
            "Epoch 878/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3506 - accuracy: 0.8488 - val_loss: 0.7670 - val_accuracy: 0.7094\n",
            "Epoch 879/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3430 - accuracy: 0.8523 - val_loss: 0.7376 - val_accuracy: 0.7101\n",
            "Epoch 880/1000\n",
            "161/161 [==============================] - 11s 69ms/step - loss: 0.3408 - accuracy: 0.8529 - val_loss: 0.7709 - val_accuracy: 0.7049\n",
            "Epoch 881/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3455 - accuracy: 0.8489 - val_loss: 0.7654 - val_accuracy: 0.7056\n",
            "Epoch 882/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3395 - accuracy: 0.8548 - val_loss: 0.7635 - val_accuracy: 0.7056\n",
            "Epoch 883/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3398 - accuracy: 0.8530 - val_loss: 0.7545 - val_accuracy: 0.7091\n",
            "Epoch 884/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3409 - accuracy: 0.8519 - val_loss: 0.7603 - val_accuracy: 0.7051\n",
            "Epoch 885/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3448 - accuracy: 0.8519 - val_loss: 0.7402 - val_accuracy: 0.7164\n",
            "Epoch 886/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3419 - accuracy: 0.8522 - val_loss: 0.7295 - val_accuracy: 0.7169\n",
            "Epoch 887/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3400 - accuracy: 0.8555 - val_loss: 0.7323 - val_accuracy: 0.7166\n",
            "Epoch 888/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3404 - accuracy: 0.8521 - val_loss: 0.7835 - val_accuracy: 0.6984\n",
            "Epoch 889/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3421 - accuracy: 0.8530 - val_loss: 0.7430 - val_accuracy: 0.7139\n",
            "Epoch 890/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3423 - accuracy: 0.8513 - val_loss: 0.7609 - val_accuracy: 0.7081\n",
            "Epoch 891/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3408 - accuracy: 0.8539 - val_loss: 0.7704 - val_accuracy: 0.6992\n",
            "Epoch 892/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3450 - accuracy: 0.8528 - val_loss: 0.7218 - val_accuracy: 0.7219\n",
            "Epoch 893/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3425 - accuracy: 0.8524 - val_loss: 0.7611 - val_accuracy: 0.7054\n",
            "Epoch 894/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3418 - accuracy: 0.8535 - val_loss: 0.7610 - val_accuracy: 0.7119\n",
            "Epoch 895/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3482 - accuracy: 0.8508 - val_loss: 0.7911 - val_accuracy: 0.6962\n",
            "Epoch 896/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3443 - accuracy: 0.8524 - val_loss: 0.7426 - val_accuracy: 0.7104\n",
            "Epoch 897/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3438 - accuracy: 0.8511 - val_loss: 0.7731 - val_accuracy: 0.7064\n",
            "Epoch 898/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3449 - accuracy: 0.8531 - val_loss: 0.7986 - val_accuracy: 0.6929\n",
            "Epoch 899/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3487 - accuracy: 0.8471 - val_loss: 0.7284 - val_accuracy: 0.7131\n",
            "Epoch 900/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3469 - accuracy: 0.8501 - val_loss: 0.7730 - val_accuracy: 0.6992\n",
            "Epoch 901/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3471 - accuracy: 0.8495 - val_loss: 0.7798 - val_accuracy: 0.7006\n",
            "Epoch 902/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3407 - accuracy: 0.8530 - val_loss: 0.7771 - val_accuracy: 0.6984\n",
            "Epoch 903/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3397 - accuracy: 0.8541 - val_loss: 0.7136 - val_accuracy: 0.7186\n",
            "Epoch 904/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3408 - accuracy: 0.8519 - val_loss: 0.7515 - val_accuracy: 0.7094\n",
            "Epoch 905/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3410 - accuracy: 0.8514 - val_loss: 0.7613 - val_accuracy: 0.7084\n",
            "Epoch 906/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3481 - accuracy: 0.8494 - val_loss: 0.7368 - val_accuracy: 0.7186\n",
            "Epoch 907/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3417 - accuracy: 0.8516 - val_loss: 0.7350 - val_accuracy: 0.7174\n",
            "Epoch 908/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3421 - accuracy: 0.8525 - val_loss: 0.7497 - val_accuracy: 0.7106\n",
            "Epoch 909/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3419 - accuracy: 0.8548 - val_loss: 0.8065 - val_accuracy: 0.6942\n",
            "Epoch 910/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3495 - accuracy: 0.8451 - val_loss: 0.7181 - val_accuracy: 0.7191\n",
            "Epoch 911/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3423 - accuracy: 0.8539 - val_loss: 0.7650 - val_accuracy: 0.7049\n",
            "Epoch 912/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3410 - accuracy: 0.8527 - val_loss: 0.7477 - val_accuracy: 0.7124\n",
            "Epoch 913/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3391 - accuracy: 0.8535 - val_loss: 0.7446 - val_accuracy: 0.7141\n",
            "Epoch 914/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3394 - accuracy: 0.8553 - val_loss: 0.7984 - val_accuracy: 0.7009\n",
            "Epoch 915/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3494 - accuracy: 0.8513 - val_loss: 0.7325 - val_accuracy: 0.7219\n",
            "Epoch 916/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3432 - accuracy: 0.8499 - val_loss: 0.7469 - val_accuracy: 0.7169\n",
            "Epoch 917/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3459 - accuracy: 0.8524 - val_loss: 0.7312 - val_accuracy: 0.7179\n",
            "Epoch 918/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3398 - accuracy: 0.8553 - val_loss: 0.7595 - val_accuracy: 0.7056\n",
            "Epoch 919/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3428 - accuracy: 0.8550 - val_loss: 0.7195 - val_accuracy: 0.7214\n",
            "Epoch 920/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3401 - accuracy: 0.8539 - val_loss: 0.7792 - val_accuracy: 0.6999\n",
            "Epoch 921/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3444 - accuracy: 0.8511 - val_loss: 0.7500 - val_accuracy: 0.7101\n",
            "Epoch 922/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3402 - accuracy: 0.8553 - val_loss: 0.7459 - val_accuracy: 0.7144\n",
            "Epoch 923/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3401 - accuracy: 0.8533 - val_loss: 0.7555 - val_accuracy: 0.7106\n",
            "Epoch 924/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3411 - accuracy: 0.8536 - val_loss: 0.7684 - val_accuracy: 0.7011\n",
            "Epoch 925/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3425 - accuracy: 0.8533 - val_loss: 0.7155 - val_accuracy: 0.7196\n",
            "Epoch 926/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3444 - accuracy: 0.8490 - val_loss: 0.7603 - val_accuracy: 0.7106\n",
            "Epoch 927/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3423 - accuracy: 0.8532 - val_loss: 0.7616 - val_accuracy: 0.7099\n",
            "Epoch 928/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3433 - accuracy: 0.8525 - val_loss: 0.7931 - val_accuracy: 0.6969\n",
            "Epoch 929/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3411 - accuracy: 0.8525 - val_loss: 0.7430 - val_accuracy: 0.7144\n",
            "Epoch 930/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3443 - accuracy: 0.8531 - val_loss: 0.7333 - val_accuracy: 0.7141\n",
            "Epoch 931/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3410 - accuracy: 0.8535 - val_loss: 0.7352 - val_accuracy: 0.7164\n",
            "Epoch 932/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3449 - accuracy: 0.8500 - val_loss: 0.7441 - val_accuracy: 0.7141\n",
            "Epoch 933/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3404 - accuracy: 0.8519 - val_loss: 0.7278 - val_accuracy: 0.7189\n",
            "Epoch 934/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3444 - accuracy: 0.8508 - val_loss: 0.7557 - val_accuracy: 0.7126\n",
            "Epoch 935/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3414 - accuracy: 0.8543 - val_loss: 0.7462 - val_accuracy: 0.7139\n",
            "Epoch 936/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3430 - accuracy: 0.8531 - val_loss: 0.7339 - val_accuracy: 0.7154\n",
            "Epoch 937/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3432 - accuracy: 0.8539 - val_loss: 0.7830 - val_accuracy: 0.7041\n",
            "Epoch 938/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3418 - accuracy: 0.8530 - val_loss: 0.7013 - val_accuracy: 0.7261\n",
            "Epoch 939/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3428 - accuracy: 0.8535 - val_loss: 0.7294 - val_accuracy: 0.7134\n",
            "Epoch 940/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3504 - accuracy: 0.8483 - val_loss: 0.7615 - val_accuracy: 0.7119\n",
            "Epoch 941/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3430 - accuracy: 0.8534 - val_loss: 0.7425 - val_accuracy: 0.7144\n",
            "Epoch 942/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3458 - accuracy: 0.8511 - val_loss: 0.7897 - val_accuracy: 0.7044\n",
            "Epoch 943/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3470 - accuracy: 0.8488 - val_loss: 0.7571 - val_accuracy: 0.7116\n",
            "Epoch 944/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3434 - accuracy: 0.8525 - val_loss: 0.7245 - val_accuracy: 0.7171\n",
            "Epoch 945/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3399 - accuracy: 0.8534 - val_loss: 0.7503 - val_accuracy: 0.7121\n",
            "Epoch 946/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3401 - accuracy: 0.8533 - val_loss: 0.7670 - val_accuracy: 0.7066\n",
            "Epoch 947/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3418 - accuracy: 0.8552 - val_loss: 0.7135 - val_accuracy: 0.7199\n",
            "Epoch 948/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3437 - accuracy: 0.8540 - val_loss: 0.7970 - val_accuracy: 0.6954\n",
            "Epoch 949/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3417 - accuracy: 0.8555 - val_loss: 0.7469 - val_accuracy: 0.7096\n",
            "Epoch 950/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3435 - accuracy: 0.8535 - val_loss: 0.7446 - val_accuracy: 0.7164\n",
            "Epoch 951/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3452 - accuracy: 0.8513 - val_loss: 0.7780 - val_accuracy: 0.7029\n",
            "Epoch 952/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3436 - accuracy: 0.8510 - val_loss: 0.7418 - val_accuracy: 0.7121\n",
            "Epoch 953/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3470 - accuracy: 0.8508 - val_loss: 0.7567 - val_accuracy: 0.7136\n",
            "Epoch 954/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3448 - accuracy: 0.8531 - val_loss: 0.7729 - val_accuracy: 0.7056\n",
            "Epoch 955/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3450 - accuracy: 0.8516 - val_loss: 0.7661 - val_accuracy: 0.7069\n",
            "Epoch 956/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3395 - accuracy: 0.8526 - val_loss: 0.7592 - val_accuracy: 0.7114\n",
            "Epoch 957/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3397 - accuracy: 0.8549 - val_loss: 0.7360 - val_accuracy: 0.7229\n",
            "Epoch 958/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3431 - accuracy: 0.8540 - val_loss: 0.7477 - val_accuracy: 0.7106\n",
            "Epoch 959/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3523 - accuracy: 0.8468 - val_loss: 0.7442 - val_accuracy: 0.7169\n",
            "Epoch 960/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3487 - accuracy: 0.8523 - val_loss: 0.7280 - val_accuracy: 0.7179\n",
            "Epoch 961/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3412 - accuracy: 0.8539 - val_loss: 0.7830 - val_accuracy: 0.7024\n",
            "Epoch 962/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3423 - accuracy: 0.8530 - val_loss: 0.7773 - val_accuracy: 0.7009\n",
            "Epoch 963/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3392 - accuracy: 0.8543 - val_loss: 0.7289 - val_accuracy: 0.7159\n",
            "Epoch 964/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3418 - accuracy: 0.8531 - val_loss: 0.7708 - val_accuracy: 0.7046\n",
            "Epoch 965/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3419 - accuracy: 0.8516 - val_loss: 0.7094 - val_accuracy: 0.7246\n",
            "Epoch 966/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3414 - accuracy: 0.8536 - val_loss: 0.7673 - val_accuracy: 0.7049\n",
            "Epoch 967/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3402 - accuracy: 0.8554 - val_loss: 0.7083 - val_accuracy: 0.7284\n",
            "Epoch 968/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3515 - accuracy: 0.8496 - val_loss: 0.7525 - val_accuracy: 0.7144\n",
            "Epoch 969/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3434 - accuracy: 0.8525 - val_loss: 0.7587 - val_accuracy: 0.7121\n",
            "Epoch 970/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3390 - accuracy: 0.8537 - val_loss: 0.7483 - val_accuracy: 0.7079\n",
            "Epoch 971/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3395 - accuracy: 0.8546 - val_loss: 0.7669 - val_accuracy: 0.7049\n",
            "Epoch 972/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3418 - accuracy: 0.8538 - val_loss: 0.7713 - val_accuracy: 0.7049\n",
            "Epoch 973/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3401 - accuracy: 0.8565 - val_loss: 0.7271 - val_accuracy: 0.7189\n",
            "Epoch 974/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3469 - accuracy: 0.8512 - val_loss: 0.7234 - val_accuracy: 0.7176\n",
            "Epoch 975/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3401 - accuracy: 0.8528 - val_loss: 0.7537 - val_accuracy: 0.7076\n",
            "Epoch 976/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3408 - accuracy: 0.8531 - val_loss: 0.7548 - val_accuracy: 0.7096\n",
            "Epoch 977/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3428 - accuracy: 0.8530 - val_loss: 0.7630 - val_accuracy: 0.7069\n",
            "Epoch 978/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3455 - accuracy: 0.8518 - val_loss: 0.7902 - val_accuracy: 0.7016\n",
            "Epoch 979/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3402 - accuracy: 0.8535 - val_loss: 0.7573 - val_accuracy: 0.7081\n",
            "Epoch 980/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3477 - accuracy: 0.8501 - val_loss: 0.8058 - val_accuracy: 0.6942\n",
            "Epoch 981/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3401 - accuracy: 0.8535 - val_loss: 0.7394 - val_accuracy: 0.7149\n",
            "Epoch 982/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3415 - accuracy: 0.8533 - val_loss: 0.7282 - val_accuracy: 0.7136\n",
            "Epoch 983/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3465 - accuracy: 0.8518 - val_loss: 0.8199 - val_accuracy: 0.6969\n",
            "Epoch 984/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3461 - accuracy: 0.8512 - val_loss: 0.7666 - val_accuracy: 0.7071\n",
            "Epoch 985/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3402 - accuracy: 0.8544 - val_loss: 0.7555 - val_accuracy: 0.7166\n",
            "Epoch 986/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3446 - accuracy: 0.8519 - val_loss: 0.7355 - val_accuracy: 0.7136\n",
            "Epoch 987/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3406 - accuracy: 0.8535 - val_loss: 0.7808 - val_accuracy: 0.7006\n",
            "Epoch 988/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3506 - accuracy: 0.8463 - val_loss: 0.7748 - val_accuracy: 0.7061\n",
            "Epoch 989/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3403 - accuracy: 0.8558 - val_loss: 0.7482 - val_accuracy: 0.7109\n",
            "Epoch 990/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3411 - accuracy: 0.8555 - val_loss: 0.7543 - val_accuracy: 0.7149\n",
            "Epoch 991/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3391 - accuracy: 0.8535 - val_loss: 0.7855 - val_accuracy: 0.7009\n",
            "Epoch 992/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3399 - accuracy: 0.8531 - val_loss: 0.7791 - val_accuracy: 0.7034\n",
            "Epoch 993/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3483 - accuracy: 0.8528 - val_loss: 0.7896 - val_accuracy: 0.6989\n",
            "Epoch 994/1000\n",
            "161/161 [==============================] - 10s 63ms/step - loss: 0.3492 - accuracy: 0.8511 - val_loss: 0.7699 - val_accuracy: 0.7004\n",
            "Epoch 995/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3419 - accuracy: 0.8547 - val_loss: 0.7775 - val_accuracy: 0.6997\n",
            "Epoch 996/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3412 - accuracy: 0.8531 - val_loss: 0.6958 - val_accuracy: 0.7256\n",
            "Epoch 997/1000\n",
            "161/161 [==============================] - 11s 68ms/step - loss: 0.3437 - accuracy: 0.8508 - val_loss: 0.7767 - val_accuracy: 0.7049\n",
            "Epoch 998/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3429 - accuracy: 0.8522 - val_loss: 0.7549 - val_accuracy: 0.7131\n",
            "Epoch 999/1000\n",
            "161/161 [==============================] - 11s 67ms/step - loss: 0.3419 - accuracy: 0.8531 - val_loss: 0.7153 - val_accuracy: 0.7226\n",
            "Epoch 1000/1000\n",
            "161/161 [==============================] - 10s 64ms/step - loss: 0.3454 - accuracy: 0.8492 - val_loss: 0.7884 - val_accuracy: 0.6977\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f40816afa00>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiyjZU57i3-C",
        "outputId": "8b94efbb-be8a-40e6-9d7c-d3b35aeb5374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126/126 [==============================] - 3s 18ms/step - loss: 0.7884 - accuracy: 0.6977\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7884448766708374, 0.6976511478424072]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/PFE_Oumaima/Adience/VGG19_Adience_Data_Aug1_Gender_Recognition.h5')"
      ],
      "metadata": {
        "id": "RXGtL3wQ6UaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XN8mw7Jicho",
        "outputId": "84f45ae9-0565-48d4-83f6-670ad250206a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keract\n",
            "  Downloading keract-4.5.1-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: keract\n",
            "Successfully installed keract-4.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "model=keras.models.load_model('/content/drive/MyDrive/PFE_Oumaima/Adience/VGG19_Adience_Data_Aug1_Gender_Recognition.h5')"
      ],
      "metadata": {
        "id": "DbtrI0SvjlKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keract import get_activations\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZ46Jlz_jzqF",
        "outputId": "01c0db94-aafe-43fe-b929-85cea5797d9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 64, 64, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 64, 64, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 32, 32, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 32, 32, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 16, 16, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 8, 8, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 2049      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,026,433\n",
            "Trainable params: 2,049\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "activations1 = get_activations(model,X_train[:1000],layer_names='flatten')"
      ],
      "metadata": {
        "id": "RCXxhlJnj0JS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "activations2 = get_activations(model,X_train[1000:2000],layer_names='flatten')\n",
        "activations3 = get_activations(model,X_train[2000:3000],layer_names='flatten')\n",
        "activations4 = get_activations(model,X_train[3000:4000],layer_names='flatten')\n",
        "activations5 = get_activations(model,X_train[4000:5000],layer_names='flatten')\n",
        "activations6 = get_activations(model,X_train[5000:6000],layer_names='flatten')\n",
        "activations7 = get_activations(model,X_train[6000:7000],layer_names='flatten')\n",
        "activations8 = get_activations(model,X_train[7000:8000],layer_names='flatten')\n",
        "activations9 = get_activations(model,X_train[8000:9000],layer_names='flatten')\n",
        "activations10 = get_activations(model,X_train[9000:10000],layer_names='flatten')\n",
        "activations11= get_activations(model,X_train[10000:11000],layer_names='flatten')\n",
        "activations12= get_activations(model,X_train[11000:12000],layer_names='flatten')\n",
        "activations13= get_activations(model,X_train[12000:13000],layer_names='flatten')\n",
        "activations14= get_activations(model,X_train[13000:14000],layer_names='flatten')\n",
        "activations15= get_activations(model,X_train[14000:15000],layer_names='flatten')\n",
        "activations16= get_activations(model,X_train[15000:],layer_names='flatten')\n"
      ],
      "metadata": {
        "id": "MpuqlZZHkPB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train1= activations1\n",
        "X_train1= X_train1[\"flatten\"]\n",
        "X_train2= activations2\n",
        "X_train2= X_train2[\"flatten\"]\n",
        "X_train3= activations3\n",
        "X_train3= X_train3[\"flatten\"]\n",
        "X_train4= activations4\n",
        "X_train4= X_train4[\"flatten\"]\n",
        "X_train5= activations5\n",
        "X_train5= X_train5[\"flatten\"]\n",
        "X_train6= activations6\n",
        "X_train6= X_train6[\"flatten\"]\n",
        "X_train7= activations7\n",
        "X_train7= X_train7[\"flatten\"]\n",
        "X_train8= activations8\n",
        "X_train8= X_train8[\"flatten\"]\n",
        "X_train9= activations9\n",
        "X_train9= X_train9[\"flatten\"]\n",
        "X_train10= activations10\n",
        "X_train10= X_train10[\"flatten\"]\n",
        "X_train11= activations11\n",
        "X_train11= X_train11[\"flatten\"]\n",
        "X_train12= activations12\n",
        "X_train12= X_train12[\"flatten\"]\n",
        "X_train13= activations13\n",
        "X_train13= X_train13[\"flatten\"]\n",
        "X_train14= activations14\n",
        "X_train14= X_train14[\"flatten\"]\n",
        "X_train15= activations15\n",
        "X_train15= X_train15[\"flatten\"]\n",
        "X_train16= activations16\n",
        "X_train16= X_train16[\"flatten\"]\n"
      ],
      "metadata": {
        "id": "efwivlPMksiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train =np.concatenate((X_train1,X_train2,X_train3,X_train4,X_train5,X_train6,X_train7,X_train8,X_train9,X_train10,X_train11,X_train12,X_train13,X_train14,X_train15,X_train16), axis=0)\n"
      ],
      "metadata": {
        "id": "CBL3ht0TkvKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "activations17 = get_activations(model,X_test[:1000],layer_names='flatten')\n",
        "activations18 = get_activations(model,X_test[1000:2000],layer_names='flatten')\n",
        "activations19 = get_activations(model,X_test[2000:3000],layer_names='flatten')\n",
        "activations20 = get_activations(model,X_test[3000:],layer_names='flatten')"
      ],
      "metadata": {
        "id": "S71BJkftkxhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test1= activations17\n",
        "X_test1= X_test1['flatten']\n",
        "X_test2= activations18\n",
        "X_test2= X_test2['flatten']\n",
        "X_test3= activations19\n",
        "X_test3= X_test3['flatten']\n",
        "X_test4= activations20\n",
        "X_test4= X_test4['flatten']\n"
      ],
      "metadata": {
        "id": "7gAijA03kz1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test =np.concatenate((X_test1,X_test2,X_test3,X_test4), axis=0)\n"
      ],
      "metadata": {
        "id": "MWsVFyenk12a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "qyZ6tbLIk41p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = SVC(kernel='rbf',probability=True, C=10000)"
      ],
      "metadata": {
        "id": "VJK5qStzk65E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "BUIcLrDIk92k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions1 = model1.predict(X_train)"
      ],
      "metadata": {
        "id": "AD3V-obik_rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions2 = model1.predict(X_test)"
      ],
      "metadata": {
        "id": "CTyflc6ZlCJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percentage = model1.score(X_test,Y_test)"
      ],
      "metadata": {
        "id": "8D6vlqA3lFXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Dataset: train=%d, test=%d\" % (X_train.shape[0], Y_test.shape[0]))\n",
        "score_train = accuracy_score(Y_train, predictions1)\n",
        "score_test = accuracy_score(Y_test, predictions2)\n",
        "\n",
        "print('Accuracy: train=%.3f, test=%.3f' % (score_train*100, score_test*100))\n"
      ],
      "metadata": {
        "id": "94XcoSqXlHbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "res = confusion_matrix(Y_test, predictions2)\n",
        "for i in range(0,len(res)):\n",
        "  print(res[i])\n",
        "print(\"Confusion Matrix\")\n",
        "print(res)\n",
        "print(f\"Test Set: {len(X_test)}\")\n",
        "print(f\"Accuracy = {score_test*100} %\")\n",
        "print(classification_report(Y_test, predictions2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFeniCwrlJT5",
        "outputId": "5d18bf52-38f5-4267-c103-e921ff61480c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1496  523]\n",
            "[ 600 1383]\n",
            "Confusion Matrix\n",
            "[[1496  523]\n",
            " [ 600 1383]]\n",
            "Test Set: 4002\n",
            "Accuracy = 71.93903048475762 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.74      0.73      2019\n",
            "           1       0.73      0.70      0.71      1983\n",
            "\n",
            "    accuracy                           0.72      4002\n",
            "   macro avg       0.72      0.72      0.72      4002\n",
            "weighted avg       0.72      0.72      0.72      4002\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r721B-ullLip"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}